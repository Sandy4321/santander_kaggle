{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain = pd.read_csv('data/train.csv.gz', index_col='ID')\n",
    "xtest = pd.read_csv('data/test.csv.gz', index_col='ID')\n",
    "train_st = pd.read_csv('data/train_stack_c.csv', index_col='ID')\n",
    "test_st = pd.read_csv('data/test_stack_c.csv', index_col='ID')\n",
    "target = xtrain.TARGET.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(target, n_folds=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_ost = pd.read_csv('clfs.csv.gz', index_col=0)\n",
    "test_ost = pd.read_csv('clfs_test.csv.gz', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf</th>\n",
       "      <th>et</th>\n",
       "      <th>xgb1</th>\n",
       "      <th>xgb2</th>\n",
       "      <th>nb</th>\n",
       "      <th>lr</th>\n",
       "      <th>fm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.005369</td>\n",
       "      <td>0.035706</td>\n",
       "      <td>0.034775</td>\n",
       "      <td>9.999198e-01</td>\n",
       "      <td>0.074125</td>\n",
       "      <td>0.002992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>0.016863</td>\n",
       "      <td>0.016494</td>\n",
       "      <td>3.315556e-14</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>0.001164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.002895</td>\n",
       "      <td>0.002797</td>\n",
       "      <td>6.695680e-06</td>\n",
       "      <td>0.010315</td>\n",
       "      <td>0.002368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.019236</td>\n",
       "      <td>0.026826</td>\n",
       "      <td>0.022162</td>\n",
       "      <td>5.045517e-06</td>\n",
       "      <td>0.032081</td>\n",
       "      <td>0.005366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.010493</td>\n",
       "      <td>0.008460</td>\n",
       "      <td>4.656722e-13</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.001048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rf        et      xgb1      xgb2            nb        lr        fm\n",
       "0  0.0000  0.005369  0.035706  0.034775  9.999198e-01  0.074125  0.002992\n",
       "1  0.0142  0.000612  0.016863  0.016494  3.315556e-14  0.001936  0.001164\n",
       "2  0.0000  0.001746  0.002895  0.002797  6.695680e-06  0.010315  0.002368\n",
       "3  0.0114  0.019236  0.026826  0.022162  5.045517e-06  0.032081  0.005366\n",
       "4  0.0106  0.001200  0.010493  0.008460  4.656722e-13  0.001408  0.001048"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ost.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ntrain_st = np.hstack((train_st.values, train_ost.loc[:, ['rf', 'et', 'nb', 'lr', 'fm']].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "ntrain_sc = sc.fit_transform(ntrain_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.81116037,  0.80120019,  0.7883417 ,  0.81307116,  0.82222865,\n",
       "        0.82577365,  0.82611948,  0.82777151,  0.83435945,  0.7996432 ])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(RandomForestClassifier(n_estimators=500, n_jobs=12), train_sc, target, scoring='roc_auc', cv=skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tk = train_st.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xtest = xtrain\n",
    "tk.ix[(xtest['var15'] < 23).values, :] = 0\n",
    "tk.ix[(xtest['saldo_medio_var5_hace2'] > 160000).values, :] = 0\n",
    "tk.ix[(xtest['saldo_var33'] > 0).values, :] = 0\n",
    "var38 = xtest['var38']\n",
    "V21 = xtest['var21']\n",
    "NV=xtest['num_var33']+xtest['saldo_medio_var33_ult3']+xtest['saldo_medio_var44_hace2']+\\\n",
    "xtest['saldo_medio_var44_hace3']+xtest['saldo_medio_var33_ult1']+xtest['saldo_medio_var44_ult1']\n",
    "tk.ix[var38 > 3988596, :]=0\n",
    "tk.ix[NV>0, :]=0\n",
    "tk.ix[V21>7500, :]=0\n",
    "\n",
    "fbinfeats = ['ind_var6_0', 'ind_var6', 'ind_var13_medio_0', 'ind_var13_medio',\n",
    "       'ind_var18_0', 'ind_var18', 'ind_var20_0', 'ind_var20',\n",
    "       'ind_var29_0', 'ind_var29', 'ind_var33_0', 'ind_var33',\n",
    "       'ind_var34_0', 'ind_var34', 'num_var6_0', 'num_var6',\n",
    "       'num_var13_medio_0', 'num_var13_medio', 'num_var18_0', 'num_var18',\n",
    "       'num_var20_0', 'num_var20', 'num_op_var40_hace3', 'num_var29_0',\n",
    "       'num_var29', 'num_var33_0', 'num_var33', 'num_var34_0', 'num_var34',\n",
    "       'saldo_var6', 'saldo_var13_medio', 'saldo_var18', 'saldo_var20',\n",
    "       'saldo_var29', 'saldo_var33', 'saldo_var34',\n",
    "       'delta_imp_amort_var18_1y3', 'delta_imp_amort_var34_1y3',\n",
    "       'delta_imp_aport_var33_1y3', 'delta_imp_reemb_var33_1y3',\n",
    "       'delta_imp_trasp_var17_in_1y3', 'delta_imp_trasp_var17_out_1y3',\n",
    "       'delta_imp_trasp_var33_in_1y3', 'delta_imp_trasp_var33_out_1y3',\n",
    "       'delta_imp_venta_var44_1y3', 'delta_num_aport_var33_1y3',\n",
    "       'delta_num_reemb_var33_1y3', 'delta_num_trasp_var17_in_1y3',\n",
    "       'delta_num_trasp_var17_out_1y3', 'delta_num_trasp_var33_in_1y3',\n",
    "       'delta_num_trasp_var33_out_1y3', 'delta_num_venta_var44_1y3',\n",
    "       'imp_amort_var18_ult1', 'imp_amort_var34_ult1',\n",
    "       'imp_aport_var17_hace3', 'imp_aport_var33_hace3',\n",
    "       'imp_aport_var33_ult1', 'imp_var7_emit_ult1',\n",
    "       'imp_compra_var44_hace3', 'imp_reemb_var17_hace3',\n",
    "       'imp_reemb_var33_ult1', 'imp_trasp_var17_in_hace3',\n",
    "       'imp_trasp_var17_in_ult1', 'imp_trasp_var17_out_ult1',\n",
    "       'imp_trasp_var33_in_hace3', 'imp_trasp_var33_in_ult1',\n",
    "       'imp_trasp_var33_out_ult1', 'imp_venta_var44_hace3',\n",
    "       'imp_venta_var44_ult1', 'ind_var7_emit_ult1',\n",
    "       'num_aport_var17_hace3', 'num_aport_var33_hace3',\n",
    "       'num_aport_var33_ult1', 'num_var7_emit_ult1',\n",
    "       'num_compra_var44_hace3', 'num_meses_var13_largo_ult3',\n",
    "       'num_meses_var13_medio_ult3', 'num_meses_var29_ult3',\n",
    "       'num_meses_var33_ult3', 'num_reemb_var17_hace3',\n",
    "       'num_reemb_var33_ult1', 'num_trasp_var17_in_hace3',\n",
    "       'num_trasp_var17_in_ult1', 'num_trasp_var17_out_ult1',\n",
    "       'num_trasp_var33_in_hace3', 'num_trasp_var33_in_ult1',\n",
    "       'num_trasp_var33_out_ult1', 'num_venta_var44_hace3',\n",
    "       'num_venta_var44_ult1', 'saldo_medio_var13_largo_hace2',\n",
    "       'saldo_medio_var13_largo_hace3', 'saldo_medio_var13_largo_ult1',\n",
    "       'saldo_medio_var13_largo_ult3', 'saldo_medio_var13_medio_hace2',\n",
    "       'saldo_medio_var13_medio_ult1', 'saldo_medio_var13_medio_ult3',\n",
    "       'saldo_medio_var17_hace2', 'saldo_medio_var17_hace3',\n",
    "       'saldo_medio_var29_hace2', 'saldo_medio_var29_hace3',\n",
    "       'saldo_medio_var29_ult1', 'saldo_medio_var29_ult3',\n",
    "       'saldo_medio_var33_hace2', 'saldo_medio_var33_hace3',\n",
    "       'saldo_medio_var33_ult1', 'saldo_medio_var33_ult3',\n",
    "       'saldo_medio_var44_hace2', 'saldo_medio_var44_hace3']\n",
    "\n",
    "for f in fbinfeats:\n",
    "    tk.ix[(xtest[f] != 0).values, :] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.83160373,  0.84215425,  0.8055814 ,  0.83126305,  0.83314919,\n",
       "        0.83550745,  0.83783362,  0.8319356 ,  0.83751815,  0.82045907])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(LogisticRegression(C=1e20), tk, target, scoring='roc_auc', cv=skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 980 Ti (CNMeM is disabled, cuDNN Version is too old. Update to v5, was 3007.)\n"
     ]
    }
   ],
   "source": [
    "import lasagne\n",
    "from lasagne.layers import InputLayer, DenseLayer, DropoutLayer\n",
    "from lasagne.utils import floatX\n",
    "import theano\n",
    "\n",
    "import theano.tensor as T\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 446 of 1000 took 0.043s \t train loss: 0.556629 val loss: 0.512675 train auc: 0.842537 val auc:0.838494"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-29d19ad474f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     68\u001b[0m         train_err += train_fn(X_train_sc.astype('float32').reshape(-1, 6, 1), \n\u001b[0;32m     69\u001b[0m                               \u001b[0mtrain_w\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m                               y_train.astype('int32'))\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[0mtrain_batches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         val_err, val_acc = val_fn(X_test_sc.astype('float32').reshape(-1, 6, 1),\n",
      "\u001b[1;32m/home/libfun/vrt/lib/python3.4/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = train_st.iloc[train_index], train_st.iloc[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    X_train_sc = sc.fit_transform(X_train)\n",
    "    X_test_sc = sc.transform(X_test)\n",
    "    \n",
    "    train_w = np.ones(y_train.shape)\n",
    "    train_w[y_train == 1] = 25.\n",
    "    test_w = np.ones(y_test.shape)\n",
    "    test_w[y_test == 1] = 25.\n",
    "    \n",
    "    input_var = T.tensor3('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "    weight_var = T.vector('weights')\n",
    "\n",
    "    net = {}\n",
    "    prob = .5\n",
    "    net['input'] = InputLayer((None, 6, 1),input_var=input_var)\n",
    "    net['fc1'] = DenseLayer(net['input'], num_units=10,\n",
    "                            nonlinearity = lasagne.nonlinearities.tanh,\n",
    "                            W = lasagne.init.GlorotUniform(gain = 'relu'))\n",
    "    net['drop1'] = DropoutLayer(net['fc1'], p=prob)\n",
    "    net['fc2'] = DenseLayer(net['drop1'], num_units=10,\n",
    "                            nonlinearity = lasagne.nonlinearities.tanh,\n",
    "                            W = lasagne.init.GlorotUniform(gain = 'relu'))\n",
    "    net['drop2'] = DropoutLayer(net['fc2'], p=prob)\n",
    "    net['fc3'] = DenseLayer(net['drop2'], num_units=10,\n",
    "                            nonlinearity = lasagne.nonlinearities.tanh,\n",
    "                            W = lasagne.init.GlorotUniform(gain = 'relu'))\n",
    "    net['drop3'] = DropoutLayer(net['fc3'], p=prob)\n",
    "    net['fc4'] = DenseLayer(net['drop3'], num_units=2, nonlinearity=lasagne.nonlinearities.softmax)\n",
    "    output_layer = net['fc4']\n",
    "\n",
    "    prediction = lasagne.layers.get_output(output_layer)\n",
    "    loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "    loss = loss.dot(weight_var) / weight_var.sum()\n",
    "\n",
    "    params = lasagne.layers.get_all_params(output_layer, trainable=True)\n",
    "    updates = lasagne.updates.adam(loss, params)\n",
    "\n",
    "    test_prediction = lasagne.layers.get_output(output_layer, deterministic=True)\n",
    "    test_loss = lasagne.objectives.categorical_crossentropy(test_prediction,\n",
    "                                                            target_var)\n",
    "    test_loss = test_loss.dot(weight_var)  / weight_var.sum()\n",
    "    test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var),\n",
    "                      dtype=theano.config.floatX)\n",
    "\n",
    "    train_fn = theano.function([input_var, weight_var, target_var], loss, updates=updates)\n",
    "\n",
    "    val_fn = theano.function([input_var, weight_var, target_var], [test_loss, test_acc])\n",
    "\n",
    "    test_fn = theano.function([input_var], test_prediction)\n",
    "\n",
    "    #print(\"Starting training...\")\n",
    "    # We iterate over epochs:\n",
    "    nepochs = 1000\n",
    "    for epoch in range(nepochs):\n",
    "        # In each epoch, we do a full pass over the training data:\n",
    "        train_err = 0\n",
    "        train_batches = 0\n",
    "        start_time = time.time()\n",
    "        #for batch in iterate_minibatches(X_train_sc.astype('float32').reshape(-1, 2630, 1), \n",
    "        #                                 train_w.astype('float32'),\n",
    "        #                                 y_train.astype('int32'), 15000, shuffle=True):\n",
    "        #    inputs, weights, targets = batch\n",
    "        train_err += train_fn(X_train_sc.astype('float32').reshape(-1, 6, 1), \n",
    "                              train_w.astype('float32'),\n",
    "                              y_train.astype('int32'))\n",
    "        train_batches += 1\n",
    "        val_err, val_acc = val_fn(X_test_sc.astype('float32').reshape(-1, 6, 1),\n",
    "                                  test_w.astype('float32'), y_test.astype('int32'))\n",
    "        train_err = float(train_err / train_batches)\n",
    "        val_err = float(val_err)\n",
    "        train_preds = test_fn(X_train_sc.astype('float32').reshape(-1, 6, 1))\n",
    "        val_preds = test_fn(X_test_sc.astype('float32').reshape(-1, 6, 1))\n",
    "        train_auc = float(roc_auc_score(y_train, train_preds[:, 1]))\n",
    "        val_auc = float(roc_auc_score(y_test, val_preds[:, 1]))\n",
    "        #print(train_err, val_err, train_auc, val_auc)\n",
    "        # Then we print the results for this epoch:\n",
    "        sys.stdout.write(\"\"\"\\rEpoch {} of {} took {:.3f}s \\t train loss: {:.6f} val loss: {:.6f} train auc: {:.6f} val auc:{:.6f}\"\"\".format(epoch + 1, nepochs, time.time() - start_time, \n",
    "                           train_err, val_err, train_auc, val_auc))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_var = T.tensor3('inputs')\n",
    "target_var = T.ivector('targets')\n",
    "weight_var = T.vector('weights')\n",
    "\n",
    "net = {}\n",
    "prob = .5\n",
    "net['input'] = InputLayer((None, 6, 1),input_var=input_var)\n",
    "net['fc1'] = DenseLayer(net['input'], num_units=10,\n",
    "                        nonlinearity = lasagne.nonlinearities.tanh,\n",
    "                        W = lasagne.init.GlorotUniform(gain = 'relu'))\n",
    "net['drop1'] = DropoutLayer(net['fc1'], p=prob)\n",
    "net['fc2'] = DenseLayer(net['drop1'], num_units=10,\n",
    "                        nonlinearity = lasagne.nonlinearities.tanh,\n",
    "                        W = lasagne.init.GlorotUniform(gain = 'relu'))\n",
    "net['drop2'] = DropoutLayer(net['fc2'], p=prob)\n",
    "net['fc3'] = DenseLayer(net['drop2'], num_units=10,\n",
    "                        nonlinearity = lasagne.nonlinearities.tanh,\n",
    "                        W = lasagne.init.GlorotUniform(gain = 'relu'))\n",
    "net['drop3'] = DropoutLayer(net['fc3'], p=prob)\n",
    "net['fc4'] = DenseLayer(net['drop3'], num_units=2, nonlinearity=lasagne.nonlinearities.softmax)\n",
    "output_layer = net['fc4']\n",
    "\n",
    "prediction = lasagne.layers.get_output(output_layer)\n",
    "loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "loss = loss.dot(weight_var) / weight_var.sum()\n",
    "\n",
    "params = lasagne.layers.get_all_params(output_layer, trainable=True)\n",
    "updates = lasagne.updates.adam(loss, params)\n",
    "\n",
    "test_prediction = lasagne.layers.get_output(output_layer, deterministic=True)\n",
    "test_loss = lasagne.objectives.categorical_crossentropy(test_prediction,\n",
    "                                                        target_var)\n",
    "test_loss = test_loss.dot(weight_var)  / weight_var.sum()\n",
    "test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var),\n",
    "                  dtype=theano.config.floatX)\n",
    "\n",
    "train_fn = theano.function([input_var, weight_var, target_var], loss, updates=updates)\n",
    "\n",
    "val_fn = theano.function([input_var, weight_var, target_var], [test_loss, test_acc])\n",
    "\n",
    "test_fn = theano.function([input_var], test_prediction)\n",
    "\n",
    "#print(\"Starting training...\")\n",
    "# We iterate over epochs:\n",
    "nepochs = 250\n",
    "for epoch in range(nepochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    #for batch in iterate_minibatches(X_train_sc.astype('float32').reshape(-1, 2630, 1), \n",
    "    #                                 train_w.astype('float32'),\n",
    "    #                                 y_train.astype('int32'), 15000, shuffle=True):\n",
    "    #    inputs, weights, targets = batch\n",
    "    train_err += train_fn(X_train_sc.astype('float32').reshape(-1, 6, 1), \n",
    "                          train_w.astype('float32'),\n",
    "                          y_train.astype('int32'))\n",
    "    train_batches += 1\n",
    "    val_err, val_acc = val_fn(X_test_sc.astype('float32').reshape(-1, 6, 1),\n",
    "                              test_w.astype('float32'), y_test.astype('int32'))\n",
    "    train_err = float(train_err / train_batches)\n",
    "    val_err = float(val_err)\n",
    "    train_preds = test_fn(X_train_sc.astype('float32').reshape(-1, 6, 1))\n",
    "    val_preds = test_fn(X_test_sc.astype('float32').reshape(-1, 6, 1))\n",
    "    train_auc = float(roc_auc_score(y_train, train_preds[:, 1]))\n",
    "    val_auc = float(roc_auc_score(y_test, val_preds[:, 1]))\n",
    "    #print(train_err, val_err, train_auc, val_auc)\n",
    "    # Then we print the results for this epoch:\n",
    "    sys.stdout.write(\"\"\"\\rEpoch {} of {} took {:.3f}s \\t train loss: {:.6f} val loss: {:.6f} train auc: {:.6f} val auc:{:.6f}\"\"\".format(epoch + 1, nepochs, time.time() - start_time, \n",
    "                       train_err, val_err, train_auc, val_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_sc = sc.fit_transform(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.83957451,  0.8382048 ,  0.81839287,  0.84335259,  0.8489917 ,\n",
       "        0.84539095,  0.84902787,  0.86284203,  0.84995069,  0.82994247])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(LogisticRegression(), tr_sc, target, scoring='roc_auc', cv=skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'objective': 'binary:logistic', \n",
    "          'eval_metric': 'auc',\n",
    "          'eta': 0.0202048,\n",
    "          'max_depth': 3,\n",
    "          'subsample': 1.,\n",
    "          'colsample_bytree': 1.,\n",
    "          'silent': 1,\n",
    "          'seed': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr = train_st.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(train_st.shape[1]):\n",
    "    for j in range(i+1, train_st.shape[1]):\n",
    "        tr.loc[:, tr.columns[i]+'@+'+tr.columns[j]] = tr.ix[:, i] + tr.ix[:, j]\n",
    "        tr.loc[:, tr.columns[i]+'@-'+tr.columns[j]] = tr.ix[:, i] - tr.ix[:, j]\n",
    "        tr.loc[:, tr.columns[i]+'@*'+tr.columns[j]] = tr.ix[:, i] * tr.ix[:, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(tr, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 50 rounds.\n",
      "[0]\tcv-test-auc:0.8274614+0.012570806825339405\tcv-train-auc:0.8329066999999999+0.0019384900850920059\n",
      "[1]\tcv-test-auc:0.8290517+0.010619086081673883\tcv-train-auc:0.8345454999999999+0.0022914787910866723\n",
      "[2]\tcv-test-auc:0.8302396999999999+0.01059618112387665\tcv-train-auc:0.8357139+0.0023592666000263763\n",
      "[3]\tcv-test-auc:0.8308674999999999+0.011014938758340892\tcv-train-auc:0.8362289+0.002129622006366377\n",
      "[4]\tcv-test-auc:0.8320705+0.012190050855103099\tcv-train-auc:0.8370823+0.0017545401135340263\n",
      "[5]\tcv-test-auc:0.8320707+0.012123790925696465\tcv-train-auc:0.8372341999999999+0.0018671996036846333\n",
      "[6]\tcv-test-auc:0.8323855+0.012277212715026145\tcv-train-auc:0.8375412000000001+0.0017159119324720632\n",
      "[7]\tcv-test-auc:0.8326256000000001+0.012204564705060147\tcv-train-auc:0.8378525+0.0017064984764130241\n",
      "[8]\tcv-test-auc:0.8329008+0.01202497253052997\tcv-train-auc:0.8380186000000001+0.0017758964609458474\n",
      "[9]\tcv-test-auc:0.8331742+0.01190861645028506\tcv-train-auc:0.8383953999999999+0.0019092920258567156\n",
      "[10]\tcv-test-auc:0.8332705+0.011864522116377039\tcv-train-auc:0.8386859+0.001758504617565735\n",
      "[11]\tcv-test-auc:0.8340674+0.011982119805777257\tcv-train-auc:0.8393724+0.002118847620759935\n",
      "[12]\tcv-test-auc:0.8340881+0.011974540537740892\tcv-train-auc:0.8393944+0.0021305273619458493\n",
      "[13]\tcv-test-auc:0.8345073000000001+0.011887152619950658\tcv-train-auc:0.8395574+0.0020798290891320768\n",
      "[14]\tcv-test-auc:0.8344527999999999+0.011859877603078382\tcv-train-auc:0.8397382+0.0021634191364597083\n",
      "[15]\tcv-test-auc:0.8346121+0.011945211328812903\tcv-train-auc:0.8401569999999999+0.001884313031319368\n",
      "[16]\tcv-test-auc:0.8346719+0.011884310030035395\tcv-train-auc:0.8401662999999999+0.001861667964487751\n",
      "[17]\tcv-test-auc:0.8350118999999999+0.01191803130932287\tcv-train-auc:0.8404365+0.0019616038463461504\n",
      "[18]\tcv-test-auc:0.8350548+0.012071169925073545\tcv-train-auc:0.8405443+0.0019046033209043766\n",
      "[19]\tcv-test-auc:0.8350383999999998+0.012054256644024139\tcv-train-auc:0.8405967999999999+0.0019058968912299622\n",
      "[20]\tcv-test-auc:0.8352923999999999+0.012351497878395153\tcv-train-auc:0.8409146+0.0014711196552286156\n",
      "[21]\tcv-test-auc:0.8352914+0.012358140751747406\tcv-train-auc:0.8409432000000001+0.0014648992320292818\n",
      "[22]\tcv-test-auc:0.8353196+0.012368880419827798\tcv-train-auc:0.8409468+0.0014598782003989118\n",
      "[23]\tcv-test-auc:0.8354823000000001+0.012270888990207698\tcv-train-auc:0.8412057000000001+0.0016850778053253026\n",
      "[24]\tcv-test-auc:0.8354103+0.01232427258745927\tcv-train-auc:0.8412281+0.0016730398351503693\n",
      "[25]\tcv-test-auc:0.8354204000000001+0.012303664723975533\tcv-train-auc:0.8412592+0.001673643378978916\n",
      "[26]\tcv-test-auc:0.8355354+0.012457889012188224\tcv-train-auc:0.8413029+0.0016548177815095067\n",
      "[27]\tcv-test-auc:0.8355792000000001+0.01249137674397823\tcv-train-auc:0.841342+0.0016556977985127694\n",
      "[28]\tcv-test-auc:0.835561+0.012482307847509626\tcv-train-auc:0.8414092999999999+0.0016505607562280096\n",
      "[29]\tcv-test-auc:0.8355585+0.012447926737011273\tcv-train-auc:0.8413963000000001+0.0016483148394648278\n",
      "[30]\tcv-test-auc:0.835699+0.012500977337792455\tcv-train-auc:0.8414508999999999+0.0015495116295142703\n",
      "[31]\tcv-test-auc:0.8359922000000001+0.012312266329153195\tcv-train-auc:0.8416965+0.0019702706539965484\n",
      "[32]\tcv-test-auc:0.8359835+0.012275269832064796\tcv-train-auc:0.8417245+0.001944521084997537\n",
      "[33]\tcv-test-auc:0.8359840000000001+0.012309581576966773\tcv-train-auc:0.84175+0.0019511305440692715\n",
      "[34]\tcv-test-auc:0.8359375+0.012326888774139259\tcv-train-auc:0.8417626+0.0019493946342390473\n",
      "[35]\tcv-test-auc:0.8361556+0.012295151639569162\tcv-train-auc:0.8420648+0.0020307247376244687\n",
      "[36]\tcv-test-auc:0.8360697000000001+0.012332783571035379\tcv-train-auc:0.8420824+0.002034470112830363\n",
      "[37]\tcv-test-auc:0.8365447999999999+0.01242463860882882\tcv-train-auc:0.8425692999999999+0.0021415199765587264\n",
      "[38]\tcv-test-auc:0.8367886999999999+0.012764609614477037\tcv-train-auc:0.8428941+0.0020240403874428967\n",
      "[39]\tcv-test-auc:0.8369509+0.012815474743059647\tcv-train-auc:0.8430519999999999+0.002077522514920121\n",
      "[40]\tcv-test-auc:0.8372994000000002+0.012722961465004911\tcv-train-auc:0.84335+0.002293669766989131\n",
      "[41]\tcv-test-auc:0.8373322+0.01272458937490714\tcv-train-auc:0.8433539+0.0022834976877588527\n",
      "[42]\tcv-test-auc:0.8373573999999999+0.01274664269680452\tcv-train-auc:0.8433635+0.00231746077636712\n",
      "[43]\tcv-test-auc:0.8374147000000001+0.01277267648576445\tcv-train-auc:0.8433887+0.0023200247434025357\n",
      "[44]\tcv-test-auc:0.8383433+0.011876364343097594\tcv-train-auc:0.8441304000000001+0.002568483412444012\n",
      "[45]\tcv-test-auc:0.8382591000000001+0.011888016877932176\tcv-train-auc:0.8441373999999999+0.0025701450231455833\n",
      "[46]\tcv-test-auc:0.8388009000000001+0.011338854002499532\tcv-train-auc:0.8446459999999998+0.002421850573425215\n",
      "[47]\tcv-test-auc:0.8394078+0.011689732570080448\tcv-train-auc:0.8450475000000001+0.0016517146999406476\n",
      "[48]\tcv-test-auc:0.8397003999999999+0.01183381341918149\tcv-train-auc:0.8452327000000001+0.0015919557186052638\n",
      "[49]\tcv-test-auc:0.839971+0.011866090417656508\tcv-train-auc:0.8455458+0.0014055395974500078\n",
      "[50]\tcv-test-auc:0.8400530999999999+0.011881828541516674\tcv-train-auc:0.8455821+0.0014180654745109614\n",
      "[51]\tcv-test-auc:0.8400526000000001+0.011878518596188666\tcv-train-auc:0.8455794000000001+0.0014060395584762084\n",
      "[52]\tcv-test-auc:0.8400485+0.011914107354309011\tcv-train-auc:0.8455838999999999+0.0014032779803018374\n",
      "[53]\tcv-test-auc:0.8400371999999999+0.011889477673977095\tcv-train-auc:0.8456133999999998+0.001410998525867415\n",
      "[54]\tcv-test-auc:0.8400332+0.011953981652989101\tcv-train-auc:0.8456411999999999+0.001437761023258048\n",
      "[55]\tcv-test-auc:0.8400767+0.011968454804610324\tcv-train-auc:0.8456749+0.0014083279057094742\n",
      "[56]\tcv-test-auc:0.8400874999999999+0.011984238968328363\tcv-train-auc:0.8456742+0.001405200896669239\n",
      "[57]\tcv-test-auc:0.8400890000000001+0.012015227113958363\tcv-train-auc:0.8456913+0.0014120494361034026\n",
      "[58]\tcv-test-auc:0.8400957+0.012034014542537351\tcv-train-auc:0.8457724000000001+0.0012915860946913057\n",
      "[59]\tcv-test-auc:0.8400989999999998+0.011980573734174833\tcv-train-auc:0.8457834+0.0012881472897149518\n",
      "[60]\tcv-test-auc:0.8401191000000001+0.011981390240285139\tcv-train-auc:0.8457845+0.0012924951257161424\n",
      "[61]\tcv-test-auc:0.8401050999999999+0.011983358706556355\tcv-train-auc:0.8457806999999999+0.0013176613411647027\n",
      "[62]\tcv-test-auc:0.8400969999999999+0.012007129665328006\tcv-train-auc:0.8458166+0.0012930689231436933\n",
      "[63]\tcv-test-auc:0.8401392999999999+0.011994632099818643\tcv-train-auc:0.8458712+0.0012606575109838588\n",
      "[64]\tcv-test-auc:0.8401623+0.01200090359972949\tcv-train-auc:0.8459039+0.0012612707441306814\n",
      "[65]\tcv-test-auc:0.8401721+0.011988629983863873\tcv-train-auc:0.8459075+0.001277401444339251\n",
      "[66]\tcv-test-auc:0.8401938+0.01197632954456414\tcv-train-auc:0.8459204+0.0012731216124157328\n",
      "[67]\tcv-test-auc:0.8402006999999999+0.01197403090066164\tcv-train-auc:0.8459263+0.0012670819271065354\n",
      "[68]\tcv-test-auc:0.8402107000000001+0.012010067269170477\tcv-train-auc:0.8459439000000002+0.0012565654340303916\n",
      "[69]\tcv-test-auc:0.8402212+0.011985847953315604\tcv-train-auc:0.8459685+0.0012394007624654836\n",
      "[70]\tcv-test-auc:0.8402356000000001+0.011992173015763241\tcv-train-auc:0.8459770000000001+0.0012327806779796693\n",
      "[71]\tcv-test-auc:0.8402362+0.011983385054315832\tcv-train-auc:0.8459856+0.001242379185273156\n",
      "[72]\tcv-test-auc:0.8402526+0.011978792737166786\tcv-train-auc:0.8459863999999999+0.0012438758941309045\n",
      "[73]\tcv-test-auc:0.8402828+0.011933216102962363\tcv-train-auc:0.8460163000000002+0.0012463650388228947\n",
      "[74]\tcv-test-auc:0.8402967+0.011923173000925534\tcv-train-auc:0.8460312+0.001242382614173258\n",
      "[75]\tcv-test-auc:0.8402797+0.011951078428744417\tcv-train-auc:0.8460732999999999+0.0012502165452432754\n",
      "[76]\tcv-test-auc:0.8403103+0.011962666341999197\tcv-train-auc:0.8460842+0.0012631465314839848\n",
      "[77]\tcv-test-auc:0.8403314999999999+0.011995485486215221\tcv-train-auc:0.8461076000000001+0.0012569856960204485\n",
      "[78]\tcv-test-auc:0.8403224+0.01199681409541717\tcv-train-auc:0.8461126999999999+0.0012663570626012307\n",
      "[79]\tcv-test-auc:0.8404025+0.011954559274603156\tcv-train-auc:0.8462106+0.0013271277406489515\n",
      "[80]\tcv-test-auc:0.8403653999999999+0.011921568707179418\tcv-train-auc:0.8462278999999999+0.0013210761862965997\n",
      "[81]\tcv-test-auc:0.8404208000000001+0.011985965724963509\tcv-train-auc:0.8462533000000001+0.001307344793847453\n",
      "[82]\tcv-test-auc:0.8404256+0.011981961785951416\tcv-train-auc:0.8462771+0.001299641369763209\n",
      "[83]\tcv-test-auc:0.8404317000000001+0.011987833190781392\tcv-train-auc:0.8463046000000001+0.001298824714886517\n",
      "[84]\tcv-test-auc:0.8404215+0.011976960476264434\tcv-train-auc:0.8463360999999999+0.0012911808897284674\n",
      "[85]\tcv-test-auc:0.8405521+0.011932818941473982\tcv-train-auc:0.8464079999999999+0.0012962923281420594\n",
      "[86]\tcv-test-auc:0.8405369+0.011910182823533809\tcv-train-auc:0.846425+0.0013008199721713935\n",
      "[87]\tcv-test-auc:0.8405315+0.011892513361354697\tcv-train-auc:0.8464661000000001+0.0012886684949978571\n",
      "[88]\tcv-test-auc:0.8405667000000001+0.011923974044336073\tcv-train-auc:0.8464933+0.0012721975514832667\n",
      "[89]\tcv-test-auc:0.8405839+0.011931265561121358\tcv-train-auc:0.8465133+0.001274663724281838\n",
      "[90]\tcv-test-auc:0.8405604+0.011919724419633196\tcv-train-auc:0.8465284000000001+0.0012775773322973216\n",
      "[91]\tcv-test-auc:0.8405539000000001+0.011937178749185248\tcv-train-auc:0.8465408999999999+0.001280111592791819\n",
      "[92]\tcv-test-auc:0.8405626999999999+0.011933069362490103\tcv-train-auc:0.8465588000000001+0.001280528390938671\n",
      "[93]\tcv-test-auc:0.8405682000000001+0.011894011760545725\tcv-train-auc:0.8465871+0.0012786163185256238\n",
      "[94]\tcv-test-auc:0.8405322+0.011859917628719002\tcv-train-auc:0.8466111+0.0012794223266771841\n",
      "[95]\tcv-test-auc:0.8405728000000001+0.011896207738603077\tcv-train-auc:0.8466209999999998+0.0012762085252810218\n",
      "[96]\tcv-test-auc:0.8405873999999999+0.011877500125868226\tcv-train-auc:0.8466313+0.001277169060852942\n",
      "[97]\tcv-test-auc:0.840588+0.011862983182994044\tcv-train-auc:0.8466438999999999+0.001275303528576632\n",
      "[98]\tcv-test-auc:0.8405704+0.011866058209869017\tcv-train-auc:0.8466673+0.0012681011040133968\n",
      "[99]\tcv-test-auc:0.8405977+0.011821121402388203\tcv-train-auc:0.8466704+0.0012646650307492535\n",
      "[100]\tcv-test-auc:0.8406106999999998+0.0118684773838096\tcv-train-auc:0.8466913999999999+0.0012604521569659164\n",
      "[101]\tcv-test-auc:0.8406143+0.011875310918455992\tcv-train-auc:0.8467076+0.0012630538547504482\n",
      "[102]\tcv-test-auc:0.8405973000000001+0.011877417548019437\tcv-train-auc:0.8467180000000001+0.0012532029364791743\n",
      "[103]\tcv-test-auc:0.8406081000000001+0.011903122266447567\tcv-train-auc:0.8467397+0.0012557084096238328\n",
      "[104]\tcv-test-auc:0.8406276+0.011885555672327642\tcv-train-auc:0.8467591999999999+0.0012522868521229592\n",
      "[105]\tcv-test-auc:0.8406189+0.011895095757916356\tcv-train-auc:0.8467638000000001+0.001251136986904323\n",
      "[106]\tcv-test-auc:0.8405910999999999+0.01187879156690612\tcv-train-auc:0.8467717+0.0012493011686539083\n",
      "[107]\tcv-test-auc:0.8405847+0.011894330347270495\tcv-train-auc:0.8467872+0.0012533830858919453\n",
      "[108]\tcv-test-auc:0.8405744+0.011932264723848516\tcv-train-auc:0.846789+0.0012502694909498633\n",
      "[109]\tcv-test-auc:0.8405779000000001+0.011906040495899542\tcv-train-auc:0.8467886+0.0012580137678101972\n",
      "[110]\tcv-test-auc:0.8406878000000001+0.011970105703793938\tcv-train-auc:0.8468673000000001+0.0012462507813437891\n",
      "[111]\tcv-test-auc:0.8406781000000001+0.011973257480318378\tcv-train-auc:0.8468742+0.0012511872601653064\n",
      "[112]\tcv-test-auc:0.840884+0.01163850526485251\tcv-train-auc:0.8469211+0.001330355926058902\n",
      "[113]\tcv-test-auc:0.8408738+0.011641757812289343\tcv-train-auc:0.8469331999999999+0.0013274488163390746\n",
      "[114]\tcv-test-auc:0.8408578999999999+0.011654330443659147\tcv-train-auc:0.8469506000000001+0.001327845186759355\n",
      "[115]\tcv-test-auc:0.8408652+0.011653805891639009\tcv-train-auc:0.8469626+0.0013309544094370885\n",
      "[116]\tcv-test-auc:0.8408521+0.011666985792825853\tcv-train-auc:0.8469687+0.0013320701220281095\n",
      "[117]\tcv-test-auc:0.840897+0.011728639170850111\tcv-train-auc:0.8470080999999998+0.001320438824785172\n",
      "[118]\tcv-test-auc:0.8408975+0.01173561262354889\tcv-train-auc:0.8470206999999998+0.0013237693190280605\n",
      "[119]\tcv-test-auc:0.8408927+0.011734447409656741\tcv-train-auc:0.8470341999999998+0.0013198367929407116\n",
      "[120]\tcv-test-auc:0.8408799+0.011718806854368753\tcv-train-auc:0.8470482+0.001313676428958039\n",
      "[121]\tcv-test-auc:0.8408849+0.011701851506919752\tcv-train-auc:0.8470622999999999+0.0013093647352819715\n",
      "[122]\tcv-test-auc:0.8408884999999999+0.011688645971625625\tcv-train-auc:0.8470993+0.0013174891308849628\n",
      "[123]\tcv-test-auc:0.8409042+0.011656599425218322\tcv-train-auc:0.8471152+0.0013193881005981497\n",
      "[124]\tcv-test-auc:0.8409278+0.011651786316269286\tcv-train-auc:0.847145+0.0012944856893762923\n",
      "[125]\tcv-test-auc:0.8409190000000001+0.011631782597693277\tcv-train-auc:0.8471605+0.0012964300405343867\n",
      "[126]\tcv-test-auc:0.8409384000000001+0.011668798645961806\tcv-train-auc:0.8471787+0.0012728457919166888\n",
      "[127]\tcv-test-auc:0.8409072+0.0116161853445957\tcv-train-auc:0.8471976+0.0012734445570970014\n",
      "[128]\tcv-test-auc:0.8408985+0.01158843287291255\tcv-train-auc:0.8472299+0.0012788731328790986\n",
      "[129]\tcv-test-auc:0.8408774000000001+0.011549455954286345\tcv-train-auc:0.8472611000000001+0.001257521327850949\n",
      "[130]\tcv-test-auc:0.8408880999999999+0.011539794308825435\tcv-train-auc:0.8473025+0.001270713362643194\n",
      "[131]\tcv-test-auc:0.8409084+0.011543597205377523\tcv-train-auc:0.8473281+0.001259237026933372\n",
      "[132]\tcv-test-auc:0.8408659999999999+0.011556416823566036\tcv-train-auc:0.8473743+0.001293894899132069\n",
      "[133]\tcv-test-auc:0.8408747999999999+0.01154659137408093\tcv-train-auc:0.8474031+0.0012805663942178104\n",
      "[134]\tcv-test-auc:0.8408912+0.011579084970756527\tcv-train-auc:0.8474223999999999+0.0012791904627536925\n",
      "[135]\tcv-test-auc:0.8409112000000001+0.011595635237450327\tcv-train-auc:0.8474627+0.0012824359672123998\n",
      "[136]\tcv-test-auc:0.8409074999999999+0.011619365053650734\tcv-train-auc:0.8474964+0.001291200697025853\n",
      "[137]\tcv-test-auc:0.8408957000000001+0.011612402568374891\tcv-train-auc:0.8475128+0.0012946424834679399\n",
      "[138]\tcv-test-auc:0.8408871+0.011611456794476746\tcv-train-auc:0.8475499000000001+0.0012882715901548043\n",
      "[139]\tcv-test-auc:0.8409379000000001+0.011537235938039923\tcv-train-auc:0.8475908000000001+0.0013009526355713167\n",
      "[140]\tcv-test-auc:0.8409641999999999+0.011553947964224166\tcv-train-auc:0.8476244000000002+0.0012951402395107517\n",
      "[141]\tcv-test-auc:0.8409507000000002+0.01154258050914094\tcv-train-auc:0.8476614999999998+0.001278024275982252\n",
      "[142]\tcv-test-auc:0.8409495+0.011532019218246214\tcv-train-auc:0.8476892000000001+0.0012890805870852274\n",
      "[143]\tcv-test-auc:0.8409185000000001+0.011523113721993722\tcv-train-auc:0.8477028000000001+0.0012906159614695602\n",
      "[144]\tcv-test-auc:0.8409317999999999+0.01154745939849975\tcv-train-auc:0.8477282+0.0012946449551904137\n",
      "[145]\tcv-test-auc:0.8408863999999999+0.01153690489862859\tcv-train-auc:0.8477549+0.0013046502558157268\n",
      "[146]\tcv-test-auc:0.8408757000000001+0.01152485311012682\tcv-train-auc:0.8477789+0.0013095899701815053\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-64867645914d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnfold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstratified\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/libfun/vrt/lib/python3.4/site-packages/xgboost-0.4-py3.4.egg/xgboost/training.py\u001b[0m in \u001b[0;36mcv\u001b[1;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 456\u001b[1;33m             \u001b[0mfold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    457\u001b[0m         res = aggcv([f.eval(i, feval) for f in cvfolds],\n\u001b[0;32m    458\u001b[0m                     \u001b[0mshow_stdv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_stdv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose_eval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/libfun/vrt/lib/python3.4/site-packages/xgboost-0.4-py3.4.egg/xgboost/training.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, iteration, fobj)\u001b[0m\n\u001b[0;32m    251\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[1;34m\"\"\"\"Update the boosters for one iteration\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/libfun/vrt/lib/python3.4/site-packages/xgboost-0.4-py3.4.egg/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m    748\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 750\u001b[1;33m             \u001b[0m_check_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    751\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgb.cv(params, dtrain, num_boost_round=500, nfold=10, stratified=True, early_stopping_rounds=50, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts = test_st.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(test_st.shape[1]):\n",
    "    for j in range(i+1, test_st.shape[1]):\n",
    "        ts.loc[:, ts.columns[i]+'@+'+ts.columns[j]] = ts.ix[:, i] + ts.ix[:, j]\n",
    "        ts.loc[:, ts.columns[i]+'@-'+ts.columns[j]] = ts.ix[:, i] - ts.ix[:, j]\n",
    "        ts.loc[:, ts.columns[i]+'@*'+ts.columns[j]] = ts.ix[:, i] * ts.ix[:, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_sc = sc.fit_transform(tr)\n",
    "ts_sc = sc.transform(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(tr_sc, target)\n",
    "preds = lr.predict_proba(ts_sc)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv('data/sample_submission.csv', index_col='ID')\n",
    "sample.TARGET = preds\n",
    "sample.to_csv('submission/xgb_lrst_nopost.csv', index_label='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/libfun/vrt/lib/python3.4/site-packages/ipykernel/__main__.py:7: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n",
      "/home/libfun/vrt/lib/python3.4/site-packages/ipykernel/__main__.py:8: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n",
      "/home/libfun/vrt/lib/python3.4/site-packages/ipykernel/__main__.py:9: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n"
     ]
    }
   ],
   "source": [
    "preds[(xtest['var15'] < 23).values] = 0\n",
    "preds[(xtest['saldo_medio_var5_hace2'] > 160000).values] = 0\n",
    "preds[(xtest['saldo_var33'] > 0).values] = 0\n",
    "var38 = xtest['var38']\n",
    "V21 = xtest['var21']\n",
    "NV=xtest['num_var33']+xtest['saldo_medio_var33_ult3']+xtest['saldo_medio_var44_hace2']+\\\n",
    "xtest['saldo_medio_var44_hace3']+xtest['saldo_medio_var33_ult1']+xtest['saldo_medio_var44_ult1']\n",
    "preds[var38 > 3988596]=0\n",
    "preds[NV>0]=0\n",
    "preds[V21>7500]=0\n",
    "\n",
    "fbinfeats = ['ind_var6_0', 'ind_var6', 'ind_var13_medio_0', 'ind_var13_medio',\n",
    "       'ind_var18_0', 'ind_var18', 'ind_var20_0', 'ind_var20',\n",
    "       'ind_var29_0', 'ind_var29', 'ind_var33_0', 'ind_var33',\n",
    "       'ind_var34_0', 'ind_var34', 'num_var6_0', 'num_var6',\n",
    "       'num_var13_medio_0', 'num_var13_medio', 'num_var18_0', 'num_var18',\n",
    "       'num_var20_0', 'num_var20', 'num_op_var40_hace3', 'num_var29_0',\n",
    "       'num_var29', 'num_var33_0', 'num_var33', 'num_var34_0', 'num_var34',\n",
    "       'saldo_var6', 'saldo_var13_medio', 'saldo_var18', 'saldo_var20',\n",
    "       'saldo_var29', 'saldo_var33', 'saldo_var34',\n",
    "       'delta_imp_amort_var18_1y3', 'delta_imp_amort_var34_1y3',\n",
    "       'delta_imp_aport_var33_1y3', 'delta_imp_reemb_var33_1y3',\n",
    "       'delta_imp_trasp_var17_in_1y3', 'delta_imp_trasp_var17_out_1y3',\n",
    "       'delta_imp_trasp_var33_in_1y3', 'delta_imp_trasp_var33_out_1y3',\n",
    "       'delta_imp_venta_var44_1y3', 'delta_num_aport_var33_1y3',\n",
    "       'delta_num_reemb_var33_1y3', 'delta_num_trasp_var17_in_1y3',\n",
    "       'delta_num_trasp_var17_out_1y3', 'delta_num_trasp_var33_in_1y3',\n",
    "       'delta_num_trasp_var33_out_1y3', 'delta_num_venta_var44_1y3',\n",
    "       'imp_amort_var18_ult1', 'imp_amort_var34_ult1',\n",
    "       'imp_aport_var17_hace3', 'imp_aport_var33_hace3',\n",
    "       'imp_aport_var33_ult1', 'imp_var7_emit_ult1',\n",
    "       'imp_compra_var44_hace3', 'imp_reemb_var17_hace3',\n",
    "       'imp_reemb_var33_ult1', 'imp_trasp_var17_in_hace3',\n",
    "       'imp_trasp_var17_in_ult1', 'imp_trasp_var17_out_ult1',\n",
    "       'imp_trasp_var33_in_hace3', 'imp_trasp_var33_in_ult1',\n",
    "       'imp_trasp_var33_out_ult1', 'imp_venta_var44_hace3',\n",
    "       'imp_venta_var44_ult1', 'ind_var7_emit_ult1',\n",
    "       'num_aport_var17_hace3', 'num_aport_var33_hace3',\n",
    "       'num_aport_var33_ult1', 'num_var7_emit_ult1',\n",
    "       'num_compra_var44_hace3', 'num_meses_var13_largo_ult3',\n",
    "       'num_meses_var13_medio_ult3', 'num_meses_var29_ult3',\n",
    "       'num_meses_var33_ult3', 'num_reemb_var17_hace3',\n",
    "       'num_reemb_var33_ult1', 'num_trasp_var17_in_hace3',\n",
    "       'num_trasp_var17_in_ult1', 'num_trasp_var17_out_ult1',\n",
    "       'num_trasp_var33_in_hace3', 'num_trasp_var33_in_ult1',\n",
    "       'num_trasp_var33_out_ult1', 'num_venta_var44_hace3',\n",
    "       'num_venta_var44_ult1', 'saldo_medio_var13_largo_hace2',\n",
    "       'saldo_medio_var13_largo_hace3', 'saldo_medio_var13_largo_ult1',\n",
    "       'saldo_medio_var13_largo_ult3', 'saldo_medio_var13_medio_hace2',\n",
    "       'saldo_medio_var13_medio_ult1', 'saldo_medio_var13_medio_ult3',\n",
    "       'saldo_medio_var17_hace2', 'saldo_medio_var17_hace3',\n",
    "       'saldo_medio_var29_hace2', 'saldo_medio_var29_hace3',\n",
    "       'saldo_medio_var29_ult1', 'saldo_medio_var29_ult3',\n",
    "       'saldo_medio_var33_hace2', 'saldo_medio_var33_hace3',\n",
    "       'saldo_medio_var33_ult1', 'saldo_medio_var33_ult3',\n",
    "       'saldo_medio_var44_hace2', 'saldo_medio_var44_hace3']\n",
    "\n",
    "for f in fbinfeats:\n",
    "    preds[(xtest[f] != 0).values] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv('data/sample_submission.csv', index_col='ID')\n",
    "sample.TARGET = preds\n",
    "sample.to_csv('submission/xgb_lrst.csv', index_label='ID')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
