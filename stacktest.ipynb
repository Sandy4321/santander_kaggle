{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.cross_validation import cross_val_score, StratifiedKFold\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from fastFM import mcmc\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "import xgboost as xgb\n",
    "from tqdm import *\n",
    "from libtelepot import sendMessage\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('stm_train.csv.gz', index_col=0)\n",
    "target = pd.read_csv('target.csv', index_col=0)\n",
    "test = pd.read_csv('stm_test.csv.gz', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = target.loc[:, '0'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "strain = train.ix[:, :292]\n",
    "stest = test.ix[:, :292]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(target, n_folds=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_clfs = np.zeros((strain.shape[0], 7))\n",
    "test_clfs = np.zeros((stest.shape[0], 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'objective': 'binary:logistic', \n",
    "          'eval_metric': 'auc',\n",
    "          'eta': 0.0202048,\n",
    "          'max_depth': 5,\n",
    "          'subsample': 0.6815,\n",
    "          'colsample_bytree': 0.701,\n",
    "          'silent': 1,\n",
    "          'seed': 0,\n",
    "          'nthreads': 12\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fold = 1\n",
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = strain.iloc[train_index].copy(), strain.iloc[test_index].copy()\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    \n",
    "    sendMessage('Going through fold {:}'.format(fold))\n",
    "    rfres = np.zeros((X_test.shape[0], 10))\n",
    "    for st in range(10):\n",
    "        rf = RandomForestClassifier(n_estimators=5000, max_depth=50, max_features=50,\n",
    "                                    random_state=st, n_jobs=-1)\n",
    "        rf.fit(X_train, y_train)\n",
    "        #train_clfs[test_index, 0] = rf.predict_proba(X_test)[:, 1]\n",
    "        rfres[:, st] = rf.predict_proba(X_test)[:, 1]\n",
    "        sendMessage('Finished fitting RandomForest {:}'.format(st))\n",
    "        del(rf)\n",
    "        gc.collect()\n",
    "    train_clfs[test_index, 0] = rfres.mean(axis=0)\n",
    "    \n",
    "    et = ExtraTreesClassifier(n_estimators=5000, max_depth=50, max_features=50,\n",
    "                              random_state=42, n_jobs=-1)\n",
    "    et.fit(X_train, y_train)\n",
    "    train_clfs[test_index, 1] = et.predict_proba(X_test)[:, 1]\n",
    "    sendMessage('Finished fitting ExtraTrees')\n",
    "    del(et)\n",
    "    gc.collect()\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train, y_train)\n",
    "    dtest = xgb.DMatrix(X_test)\n",
    "    fxgb = xgb.train(params, dtrain, num_boost_round=500, verbose_eval=False)\n",
    "    train_clfs[test_index, 2] = fxgb.predict(dtest)\n",
    "    sendMessage('Finished fitting XGB1')\n",
    "    del(fxgb)\n",
    "    gc.collect()\n",
    "    \n",
    "    dtrains = xgb.DMatrix(X_train, y_train, missing=0)\n",
    "    dtests = xgb.DMatrix(X_test, missing=0)\n",
    "    sxgb = xgb.train(params, dtrains, num_boost_round=500, verbose_eval=False)\n",
    "    train_clfs[test_index, 3] = sxgb.predict(dtests)\n",
    "    sendMessage('Finished fitting XGB2')\n",
    "    del(sxgb)\n",
    "    gc.collect()\n",
    "    \n",
    "    nb = BernoulliNB()\n",
    "    nb.fit(X_train, y_train)\n",
    "    train_clfs[test_index, 4] = nb.predict_proba(X_test)[:, 1]\n",
    "    sendMessage('Finished fitting NaiveBayes')\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    X_train_sc = sc.fit_transform(X_train)\n",
    "    X_test_sc = sc.transform(X_test)\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    train_clfs[test_index, 5] = lr.predict_proba(X_test)[:, 1]\n",
    "    sendMessage('Finished fitting LogisticRegression')\n",
    "    \n",
    "#     fm = mcmc.FMClassification(n_iter=150, rank=20)\n",
    "#     cn = []\n",
    "#     for c in X_train.columns:\n",
    "#         cn.append((c, len(X_train[c].unique())))\n",
    "#     mask = X_train.columns[list(map(lambda x: x[1] < 500, cn))]\n",
    "#     for i in range(len(mask)):\n",
    "#         fct, ind = pd.factorize(X_train[mask[i]])\n",
    "#         X_train.loc[:, mask[i]] = fct\n",
    "#         X_test.loc[:, mask[i]] = ind.get_indexer(X_test[mask[i]])\n",
    "#         X_test.loc[X_test[mask[i]] == -1, mask[i]] = X_test[mask[i]].max() + 1\n",
    "#     ohe = OneHotEncoder()\n",
    "#     ctrain = ohe.fit_transform(X_train[mask])\n",
    "#     ctest = ohe.transform(X_test[mask])\n",
    "#     preds = fm.fit_predict_proba(ctrain, y_train, ctest)\n",
    "#     train_clfs[test_index, 6] = preds\n",
    "#     sendMessage('Finished fitting FactorizationMachine')\n",
    "    \n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fold = 1\n",
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = strain.iloc[train_index].copy(), strain.iloc[test_index].copy()\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    \n",
    "    sendMessage('Going through fold {:}'.format(fold))\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    X_train_sc = sc.fit_transform(X_train)\n",
    "    X_test_sc = sc.transform(X_test)\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train_sc, y_train)\n",
    "    train_clfs[test_index, 5] = lr.predict_proba(X_test_sc)[:, 1]\n",
    "    sendMessage('Finished fitting LogisticRegression')\n",
    "    \n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices = list()\n",
    "for train_index, test_index in skf:\n",
    "    indices.append((train_index, test_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.779259148489\n",
      "0.758791670413\n",
      "0.840758789214\n",
      "0.840673318893\n",
      "0.694625395301\n",
      "0.792495086606\n",
      "0.751685827057\n"
     ]
    }
   ],
   "source": [
    "for i in range(7):\n",
    "    print(roc_auc_score(target, train_clfs[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfs = pd.DataFrame(data=train_clfs[:, :], columns=['rf', 'et', 'xgb1', 'xgb2', 'nb', 'lr', 'fm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clfs.to_csv('clfs.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 255/255 [00:36<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.745111019509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 255/255 [00:35<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76019995432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 255/255 [00:35<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.715652659423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 255/255 [00:35<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.746281740862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 255/255 [00:35<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.758830652152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 255/255 [00:35<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.758088706731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 255/255 [00:35<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.738303950535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 255/255 [00:35<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.782242545394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 255/255 [00:35<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.754537277998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 255/255 [00:35<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.760701730357\n"
     ]
    }
   ],
   "source": [
    "fold = 1\n",
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = strain.iloc[train_index].copy(), strain.iloc[test_index].copy()\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "\n",
    "    sendMessage('Going through fold {:}'.format(fold))\n",
    "\n",
    "    fm = mcmc.FMClassification(n_iter=150, rank=20)\n",
    "    cn = []\n",
    "    for c in X_train.columns:\n",
    "        cn.append((c, len(X_train[c].unique())))\n",
    "    mask = X_train.columns[list(map(lambda x: x[1] < 500, cn))]\n",
    "    for i in range(len(mask)):\n",
    "        fct, ind = pd.factorize(X_train[mask[i]])\n",
    "        X_train.loc[:, mask[i]] = fct\n",
    "        X_test.loc[:, mask[i]] = ind.get_indexer(X_test[mask[i]])\n",
    "        X_test.loc[X_test[mask[i]] == -1, mask[i]] = X_test[mask[i]].max() + 1\n",
    "    ntr = pd.get_dummies(X_train[mask[0]])\n",
    "    nts = pd.get_dummies(X_test[mask[0]])\n",
    "    ctrain = csr_matrix(ntr.values)\n",
    "    ctest = csr_matrix(nts.loc[:, ntr.columns].fillna(0).values)\n",
    "    for i in tqdm(range(1, len(mask))):\n",
    "        ntr = pd.get_dummies(X_train[mask[i]])\n",
    "        nts = pd.get_dummies(X_test[mask[i]])\n",
    "        ctrain = hstack((ctrain, csr_matrix(ntr.values)))\n",
    "        ctest = hstack((ctest, csr_matrix(nts.loc[:, ntr.columns].fillna(0).values)))\n",
    "    sendMessage('Fitting FactorizationMachine')\n",
    "    preds = fm.fit_predict_proba(ctrain, y_train, ctest)\n",
    "    train_clfs[test_index, 6] = preds\n",
    "    print(roc_auc_score(y_test, preds))\n",
    "    sendMessage('Finished fitting FactorizationMachine')\n",
    "    \n",
    "    del(ctrain)\n",
    "    del(ctest)\n",
    "    gc.collect()\n",
    "\n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train_clfs, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nparams = {'objective': 'binary:logistic', \n",
    "          'eval_metric': 'auc',\n",
    "          'eta': 0.02,\n",
    "          'max_depth': 3,\n",
    "          'subsample': 0.8,\n",
    "          'colsample_bytree': 0.8,\n",
    "          'silent': 1,\n",
    "          'seed': 0,\n",
    "          'nthreads': 12\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 200 rounds.\n",
      "[0]\tcv-test-auc:0.8246032+0.013047990173202934\tcv-train-auc:0.8288169+0.0020369232901609113\n",
      "[1]\tcv-test-auc:0.8301375999999999+0.01342682929957776\tcv-train-auc:0.834414+0.002889435065890907\n",
      "[2]\tcv-test-auc:0.832822+0.014340203080849318\tcv-train-auc:0.8367583999999999+0.0018570525679150799\n",
      "[3]\tcv-test-auc:0.8341303999999999+0.014028769790683713\tcv-train-auc:0.8380061999999999+0.0017549056840753465\n",
      "[4]\tcv-test-auc:0.834737+0.013090446340747882\tcv-train-auc:0.8390051+0.0012099479699557384\n",
      "[5]\tcv-test-auc:0.8350085+0.013002831970382467\tcv-train-auc:0.8392628+0.0011741173535894838\n",
      "[6]\tcv-test-auc:0.8351268+0.012478111698490288\tcv-train-auc:0.8394450000000001+0.0010793801925179291\n",
      "[7]\tcv-test-auc:0.8354791+0.012685109076787646\tcv-train-auc:0.8395982+0.001060669675252393\n",
      "[8]\tcv-test-auc:0.8363313+0.012915923405238979\tcv-train-auc:0.8400584+0.0009999334177833942\n",
      "[9]\tcv-test-auc:0.8364755+0.01285342644783872\tcv-train-auc:0.8400974+0.001017666271426927\n",
      "[10]\tcv-test-auc:0.8367870999999999+0.01257979451700224\tcv-train-auc:0.8403984+0.000961775046463577\n",
      "[11]\tcv-test-auc:0.8368648000000001+0.012570960661779181\tcv-train-auc:0.8404768+0.0009184342981400439\n",
      "[12]\tcv-test-auc:0.8371727+0.012249241119759221\tcv-train-auc:0.8409502+0.0007602828157994941\n",
      "[13]\tcv-test-auc:0.8376294999999999+0.01205382997432764\tcv-train-auc:0.8412381+0.0009434234945134497\n",
      "[14]\tcv-test-auc:0.8380892+0.012191818049823399\tcv-train-auc:0.8414253+0.0010885260722646975\n",
      "[15]\tcv-test-auc:0.8381909000000001+0.012109813660416089\tcv-train-auc:0.8415937+0.0010823240780838286\n",
      "[16]\tcv-test-auc:0.8382064+0.012129356381935538\tcv-train-auc:0.8415889+0.0010785422059427978\n",
      "[17]\tcv-test-auc:0.8382792+0.01215639254713336\tcv-train-auc:0.8416482000000001+0.0010936660184900854\n",
      "[18]\tcv-test-auc:0.8386248000000001+0.0120874376507182\tcv-train-auc:0.8418125+0.0010912359277443105\n",
      "[19]\tcv-test-auc:0.8388583000000001+0.012128309387956743\tcv-train-auc:0.8419725+0.0011049212867892256\n",
      "[20]\tcv-test-auc:0.8388411000000001+0.01212884145703951\tcv-train-auc:0.8420581+0.0011862856696428722\n",
      "[21]\tcv-test-auc:0.8388404000000002+0.012119438445736682\tcv-train-auc:0.8420393+0.0011644875310624838\n",
      "[22]\tcv-test-auc:0.8388329000000001+0.012087856670642645\tcv-train-auc:0.8420755999999999+0.0011632129813580992\n",
      "[23]\tcv-test-auc:0.8389415+0.012164343025827586\tcv-train-auc:0.8421644+0.0011093894897645138\n",
      "[24]\tcv-test-auc:0.8393423+0.01205337374389426\tcv-train-auc:0.8424773999999999+0.0007771459579770168\n",
      "[25]\tcv-test-auc:0.8393885999999998+0.012114344738367002\tcv-train-auc:0.8426033+0.0007042131850512229\n",
      "[26]\tcv-test-auc:0.8392343999999999+0.012251109233044968\tcv-train-auc:0.8427165000000001+0.0007855493937366414\n",
      "[27]\tcv-test-auc:0.839221+0.012268610027219882\tcv-train-auc:0.8427464+0.0008331857175924149\n",
      "[28]\tcv-test-auc:0.8392816+0.012324641432512351\tcv-train-auc:0.8427870000000001+0.0008503037104470381\n",
      "[29]\tcv-test-auc:0.8393200999999999+0.012208501508784768\tcv-train-auc:0.8428902+0.0010002171564215323\n",
      "[30]\tcv-test-auc:0.8393765+0.012218330264401903\tcv-train-auc:0.8428939999999999+0.0010077895613668604\n",
      "[31]\tcv-test-auc:0.8394121+0.012197175520996653\tcv-train-auc:0.8429144+0.0010218753544341819\n",
      "[32]\tcv-test-auc:0.8393909+0.01225982143793293\tcv-train-auc:0.84296+0.0010445370266295114\n",
      "[33]\tcv-test-auc:0.8394159999999999+0.012259627049792337\tcv-train-auc:0.8429518999999999+0.0010398638805151528\n",
      "[34]\tcv-test-auc:0.8393531+0.012313155675536643\tcv-train-auc:0.8430724000000002+0.001116775017628872\n",
      "[35]\tcv-test-auc:0.8394041+0.012304163079624708\tcv-train-auc:0.8430958000000001+0.0010975565406848072\n",
      "[36]\tcv-test-auc:0.839603+0.012141739397631617\tcv-train-auc:0.8432486000000001+0.0011265910704421629\n",
      "[37]\tcv-test-auc:0.8397219999999999+0.011870990708445522\tcv-train-auc:0.8432682999999999+0.0011403877454620305\n",
      "[38]\tcv-test-auc:0.8397048+0.011885634966630941\tcv-train-auc:0.8433108+0.0011764204010471797\n",
      "[39]\tcv-test-auc:0.8397066000000001+0.011856236731779603\tcv-train-auc:0.8433987000000001+0.0012228804561362433\n",
      "[40]\tcv-test-auc:0.8397238999999999+0.011790908111337303\tcv-train-auc:0.843402+0.0011989791491097915\n",
      "[41]\tcv-test-auc:0.8397428000000001+0.011785758565319429\tcv-train-auc:0.8434128999999999+0.0012002888360723857\n",
      "[42]\tcv-test-auc:0.8397387000000001+0.01180263979836715\tcv-train-auc:0.8434031+0.0012065935065298404\n",
      "[43]\tcv-test-auc:0.8397772+0.011763047809135174\tcv-train-auc:0.8434122000000001+0.0012053624185281264\n",
      "[44]\tcv-test-auc:0.8397863999999998+0.011769748146838144\tcv-train-auc:0.8434267+0.0011893263681597344\n",
      "[45]\tcv-test-auc:0.8398215+0.01175919458338877\tcv-train-auc:0.8434900000000001+0.0012282713055347299\n",
      "[46]\tcv-test-auc:0.8398148000000001+0.01177808952929126\tcv-train-auc:0.8434922+0.0012129539809901987\n",
      "[47]\tcv-test-auc:0.8400163+0.0117091710812508\tcv-train-auc:0.843612+0.001176414382775063\n",
      "[48]\tcv-test-auc:0.8399903+0.011697884176636386\tcv-train-auc:0.8436313999999999+0.0011714813016006989\n",
      "[49]\tcv-test-auc:0.8399741000000001+0.011695404374796109\tcv-train-auc:0.8436402000000001+0.0011726449420007695\n",
      "[50]\tcv-test-auc:0.8400601+0.011528834203422307\tcv-train-auc:0.8436887000000001+0.00124812700074953\n",
      "[51]\tcv-test-auc:0.8400588000000001+0.01149697637468217\tcv-train-auc:0.8436973999999999+0.0012650890245354239\n",
      "[52]\tcv-test-auc:0.8400459999999998+0.011461553507269427\tcv-train-auc:0.8437214+0.0012841145743273618\n",
      "[53]\tcv-test-auc:0.8401617000000001+0.011394344167612282\tcv-train-auc:0.8437441999999999+0.00129563442374769\n",
      "[54]\tcv-test-auc:0.8400596+0.011405398451610534\tcv-train-auc:0.8437892+0.0012993904570990126\n",
      "[55]\tcv-test-auc:0.8400762+0.011404085994063689\tcv-train-auc:0.8438076000000001+0.0012990259581701926\n",
      "[56]\tcv-test-auc:0.8400183999999999+0.01148057162514133\tcv-train-auc:0.8438262+0.0013218884824371551\n",
      "[57]\tcv-test-auc:0.8400432999999999+0.011469953757971298\tcv-train-auc:0.8438279+0.0013250998792543815\n",
      "[58]\tcv-test-auc:0.8400466+0.0114797722120258\tcv-train-auc:0.8438435999999999+0.0013421285482397122\n",
      "[59]\tcv-test-auc:0.8400481+0.011457433817831986\tcv-train-auc:0.8438629000000001+0.0013553273737366962\n",
      "[60]\tcv-test-auc:0.8400740000000001+0.011418848470839783\tcv-train-auc:0.8438886999999999+0.0013685378365247982\n",
      "[61]\tcv-test-auc:0.8402814+0.011409829684969008\tcv-train-auc:0.8440289+0.0013170225092989116\n",
      "[62]\tcv-test-auc:0.8404479+0.01141942294032408\tcv-train-auc:0.8441101+0.0012146480519063813\n",
      "[63]\tcv-test-auc:0.8405279999999999+0.011341122528215624\tcv-train-auc:0.8441490999999999+0.0012600643197868996\n",
      "[64]\tcv-test-auc:0.8405448+0.01133942957824598\tcv-train-auc:0.8441683999999998+0.0012705669758025413\n",
      "[65]\tcv-test-auc:0.8405315999999999+0.011325129290211216\tcv-train-auc:0.8441687+0.001271744003327706\n",
      "[66]\tcv-test-auc:0.8405239+0.011332468843548587\tcv-train-auc:0.8441605000000001+0.0012715931935961106\n",
      "[67]\tcv-test-auc:0.8404887999999999+0.011340324358676868\tcv-train-auc:0.8441604999999999+0.0012693731720814243\n",
      "[68]\tcv-test-auc:0.8405275+0.011305757438137453\tcv-train-auc:0.844229+0.001262938399131176\n",
      "[69]\tcv-test-auc:0.8405095000000001+0.011306676870327558\tcv-train-auc:0.8442632999999999+0.001282010924290413\n",
      "[70]\tcv-test-auc:0.8405252000000001+0.011286828941735595\tcv-train-auc:0.8442557+0.0012743308086991963\n",
      "[71]\tcv-test-auc:0.8405876000000001+0.011197617793084381\tcv-train-auc:0.8442845+0.0013117755333897601\n",
      "[72]\tcv-test-auc:0.840606+0.0112041110490748\tcv-train-auc:0.8443033+0.0013013128025190451\n",
      "[73]\tcv-test-auc:0.8406174+0.011208048770414952\tcv-train-auc:0.8443195999999998+0.001293729662642064\n",
      "[74]\tcv-test-auc:0.8405605999999999+0.011224962692142895\tcv-train-auc:0.8443385999999998+0.0013173693635423335\n",
      "[75]\tcv-test-auc:0.8405781000000001+0.01121395155554009\tcv-train-auc:0.8443498+0.001318287131090945\n",
      "[76]\tcv-test-auc:0.8405796999999998+0.01122996619807915\tcv-train-auc:0.8443385000000001+0.0013084957967070322\n",
      "[77]\tcv-test-auc:0.8405733999999999+0.011231775337852877\tcv-train-auc:0.8443443+0.0013044865694977557\n",
      "[78]\tcv-test-auc:0.8406043000000001+0.011242847406684834\tcv-train-auc:0.8443409+0.0013131486168747165\n",
      "[79]\tcv-test-auc:0.8406038+0.011240224595620843\tcv-train-auc:0.8443505+0.0013121343109605854\n",
      "[80]\tcv-test-auc:0.8405862000000001+0.011226897672999425\tcv-train-auc:0.8443647999999999+0.0013026083678527238\n",
      "[81]\tcv-test-auc:0.840592+0.01124707736258624\tcv-train-auc:0.844364+0.0013043212794400098\n",
      "[82]\tcv-test-auc:0.8405913+0.011233762255362182\tcv-train-auc:0.8443831000000002+0.0012992368875612975\n",
      "[83]\tcv-test-auc:0.8405864+0.011235925686831507\tcv-train-auc:0.8443780999999999+0.0012940154906337163\n",
      "[84]\tcv-test-auc:0.8405674999999999+0.011243292891764409\tcv-train-auc:0.8443828+0.0012888609544865572\n",
      "[85]\tcv-test-auc:0.8405535000000001+0.011250208746952218\tcv-train-auc:0.8444210999999999+0.0012773850202660027\n",
      "[86]\tcv-test-auc:0.8405142000000001+0.011255327172499253\tcv-train-auc:0.8444421+0.001283608074920071\n",
      "[87]\tcv-test-auc:0.8405512999999999+0.011253423461773758\tcv-train-auc:0.8444766000000001+0.0012941864007939602\n",
      "[88]\tcv-test-auc:0.8406412999999999+0.011302453955225814\tcv-train-auc:0.8445039+0.001276227757886483\n",
      "[89]\tcv-test-auc:0.8406625999999999+0.011348168655778777\tcv-train-auc:0.8445110999999998+0.0012793970024976683\n",
      "[90]\tcv-test-auc:0.8406687999999999+0.011379589797527847\tcv-train-auc:0.8445443000000001+0.0012412576726852473\n",
      "[91]\tcv-test-auc:0.8406929+0.011395545730240389\tcv-train-auc:0.8445427000000001+0.0012353517758112525\n",
      "[92]\tcv-test-auc:0.8406454+0.011403048006563858\tcv-train-auc:0.8445808000000001+0.0012365169469117556\n",
      "[93]\tcv-test-auc:0.8407786999999999+0.01119781584997718\tcv-train-auc:0.8446279000000001+0.0012983734016068064\n",
      "[94]\tcv-test-auc:0.8407779000000002+0.011204796057492531\tcv-train-auc:0.8446522+0.0012885537474238398\n",
      "[95]\tcv-test-auc:0.8407864+0.011243290979068373\tcv-train-auc:0.8446709+0.0012700990866857625\n",
      "[96]\tcv-test-auc:0.8408481+0.011307622017471219\tcv-train-auc:0.8446918999999999+0.0012320060430046713\n",
      "[97]\tcv-test-auc:0.8408256999999999+0.011320788170882794\tcv-train-auc:0.844733+0.001219913111659996\n",
      "[98]\tcv-test-auc:0.8408188000000001+0.011312846801755948\tcv-train-auc:0.8447467+0.0012157494026319615\n",
      "[99]\tcv-test-auc:0.8407893+0.011335990579124522\tcv-train-auc:0.8447538+0.0012184692692062472\n",
      "[100]\tcv-test-auc:0.8407845999999999+0.011373059361491076\tcv-train-auc:0.8447715+0.001210545021880639\n",
      "[101]\tcv-test-auc:0.8407730000000001+0.0113578212171173\tcv-train-auc:0.8447733+0.0012217165014846846\n",
      "[102]\tcv-test-auc:0.8407883+0.011333646703951915\tcv-train-auc:0.8448063999999998+0.00123702750171528\n",
      "[103]\tcv-test-auc:0.8407641+0.011354229515471326\tcv-train-auc:0.8448133+0.0012420314851081524\n",
      "[104]\tcv-test-auc:0.8407795+0.011369150119951807\tcv-train-auc:0.8448318+0.001232111910501655\n",
      "[105]\tcv-test-auc:0.8407937999999999+0.011381520476632287\tcv-train-auc:0.8448271999999999+0.001233665578671968\n",
      "[106]\tcv-test-auc:0.8408006+0.011384195774845045\tcv-train-auc:0.8448283999999999+0.0012330112894860384\n",
      "[107]\tcv-test-auc:0.8408101+0.011344268248326987\tcv-train-auc:0.8448743000000001+0.001256189639345892\n",
      "[108]\tcv-test-auc:0.8408166999999999+0.011343023442186826\tcv-train-auc:0.8448983999999999+0.0012791717007501254\n",
      "[109]\tcv-test-auc:0.8408316000000001+0.01135276992808363\tcv-train-auc:0.8449160000000001+0.0012930673609677116\n",
      "[110]\tcv-test-auc:0.840798+0.01136786256074552\tcv-train-auc:0.8449517+0.0012863110082713292\n",
      "[111]\tcv-test-auc:0.840803+0.011355346996019085\tcv-train-auc:0.8449650999999999+0.001282436310309412\n",
      "[112]\tcv-test-auc:0.8408123999999999+0.011318485085911448\tcv-train-auc:0.8449908+0.0013041093359070538\n",
      "[113]\tcv-test-auc:0.8408115+0.01131695739366371\tcv-train-auc:0.8450086000000001+0.0012879177147628554\n",
      "[114]\tcv-test-auc:0.8407895999999999+0.011337511280699998\tcv-train-auc:0.8450354000000001+0.001282623810787872\n",
      "[115]\tcv-test-auc:0.8407874+0.011367062806195798\tcv-train-auc:0.8450445+0.0012827946250277037\n",
      "[116]\tcv-test-auc:0.8407545000000001+0.011360517472809062\tcv-train-auc:0.8450637999999999+0.0012890145693513252\n",
      "[117]\tcv-test-auc:0.8407180999999999+0.011380339155315201\tcv-train-auc:0.8451104+0.0013031396855287538\n",
      "[118]\tcv-test-auc:0.8407294999999999+0.01137081280516043\tcv-train-auc:0.8451138+0.001309619089659262\n",
      "[119]\tcv-test-auc:0.84073+0.011376118002200902\tcv-train-auc:0.8451304000000001+0.0012949161517256706\n",
      "[120]\tcv-test-auc:0.8407225+0.011385480062342575\tcv-train-auc:0.8451559+0.0013139463801845313\n",
      "[121]\tcv-test-auc:0.840708+0.01139857249834384\tcv-train-auc:0.8451858+0.0013334298481735107\n",
      "[122]\tcv-test-auc:0.8407039000000001+0.01140491544422843\tcv-train-auc:0.8452116000000001+0.0013261481968467942\n",
      "[123]\tcv-test-auc:0.8406915999999999+0.011397407338513426\tcv-train-auc:0.8452496+0.0013094135481199305\n",
      "[124]\tcv-test-auc:0.8406838999999999+0.011392064066270002\tcv-train-auc:0.845273+0.0012888440557336876\n",
      "[125]\tcv-test-auc:0.8406791+0.011405007886450573\tcv-train-auc:0.845281+0.0012896154465576284\n",
      "[126]\tcv-test-auc:0.8406830000000001+0.0113998934731865\tcv-train-auc:0.8453151+0.0012748168064471187\n",
      "[127]\tcv-test-auc:0.8406819999999999+0.011373336353067205\tcv-train-auc:0.8453288999999999+0.0012827802968552288\n",
      "[128]\tcv-test-auc:0.8406939999999998+0.01139858771076488\tcv-train-auc:0.8453493+0.001275929704176522\n",
      "[129]\tcv-test-auc:0.8406939+0.0113970785331154\tcv-train-auc:0.8453586000000002+0.0012871024201670874\n",
      "[130]\tcv-test-auc:0.8406950999999999+0.011407027916595995\tcv-train-auc:0.8453778999999999+0.0012796563171414356\n",
      "[131]\tcv-test-auc:0.8407285999999999+0.011396475728926023\tcv-train-auc:0.8454031000000001+0.0012800176131600902\n",
      "[132]\tcv-test-auc:0.8407553+0.011376414672909927\tcv-train-auc:0.8454349000000001+0.00127427300450098\n",
      "[133]\tcv-test-auc:0.840766+0.011352908296995973\tcv-train-auc:0.8454559999999999+0.001268846484016092\n",
      "[134]\tcv-test-auc:0.8407595999999999+0.011336711253269174\tcv-train-auc:0.8454766999999999+0.001267035599342013\n",
      "[135]\tcv-test-auc:0.8407566+0.01135770430324718\tcv-train-auc:0.845518+0.0012515121253907355\n",
      "[136]\tcv-test-auc:0.8407697000000001+0.011363817950407336\tcv-train-auc:0.8455378+0.001255079981515127\n",
      "[137]\tcv-test-auc:0.8408133000000001+0.011391963360632779\tcv-train-auc:0.845561+0.001250859704363355\n",
      "[138]\tcv-test-auc:0.8408390000000001+0.011407352471103891\tcv-train-auc:0.8455823+0.001252698531171798\n",
      "[139]\tcv-test-auc:0.840848+0.011403274529712936\tcv-train-auc:0.8456127999999999+0.0012529452342381036\n",
      "[140]\tcv-test-auc:0.8408734000000001+0.011436500760285033\tcv-train-auc:0.8456391+0.0012424530936820074\n",
      "[141]\tcv-test-auc:0.8408634000000001+0.011419655924764106\tcv-train-auc:0.8456647+0.0012411289256157069\n",
      "[142]\tcv-test-auc:0.840838+0.01144149287462086\tcv-train-auc:0.8456991+0.0012183088647793766\n",
      "[143]\tcv-test-auc:0.8408499+0.011440456620694829\tcv-train-auc:0.8457163000000001+0.0012185708883770316\n",
      "[144]\tcv-test-auc:0.8409053+0.011394503350738909\tcv-train-auc:0.8457604+0.001232677833012348\n",
      "[145]\tcv-test-auc:0.840887+0.01139349797033379\tcv-train-auc:0.8457822+0.0012259779606501942\n",
      "[146]\tcv-test-auc:0.8408936+0.011393815297783274\tcv-train-auc:0.8458141000000001+0.0012219673849984643\n",
      "[147]\tcv-test-auc:0.8409264999999999+0.01138879467942064\tcv-train-auc:0.8458355+0.0012221868310532643\n",
      "[148]\tcv-test-auc:0.8409155+0.011372584809532087\tcv-train-auc:0.8458685999999999+0.0012035988700559578\n",
      "[149]\tcv-test-auc:0.8409095000000001+0.011354971477286948\tcv-train-auc:0.8458887+0.0012011356334735875\n",
      "[150]\tcv-test-auc:0.8409195+0.011377810793382015\tcv-train-auc:0.8459215999999999+0.001218221506951826\n",
      "[151]\tcv-test-auc:0.8409082+0.011382936368090606\tcv-train-auc:0.8459436+0.0012224622857168485\n",
      "[152]\tcv-test-auc:0.8409027+0.0114111530271923\tcv-train-auc:0.8459707+0.0012203680633317213\n",
      "[153]\tcv-test-auc:0.8409354+0.011400116027479715\tcv-train-auc:0.8460075+0.0012281733794542176\n",
      "[154]\tcv-test-auc:0.8409415000000001+0.011414836163957864\tcv-train-auc:0.8460297999999999+0.001225076960847772\n",
      "[155]\tcv-test-auc:0.8409430999999999+0.011416929407244309\tcv-train-auc:0.8460455+0.0012268246207180558\n",
      "[156]\tcv-test-auc:0.8409408999999999+0.011400819913058895\tcv-train-auc:0.8460751999999999+0.0012169976828244173\n",
      "[157]\tcv-test-auc:0.8409484+0.011406196835054179\tcv-train-auc:0.8460946999999999+0.0012117229922717395\n",
      "[158]\tcv-test-auc:0.8409623999999999+0.011435747777911167\tcv-train-auc:0.8461130999999998+0.0012062419699214687\n",
      "[159]\tcv-test-auc:0.8409681000000001+0.011431176487571174\tcv-train-auc:0.8461481000000001+0.0012165043731939347\n",
      "[160]\tcv-test-auc:0.8409866000000001+0.011439502123781435\tcv-train-auc:0.8461759000000001+0.0012168340437381\n",
      "[161]\tcv-test-auc:0.8409919+0.011437720983220396\tcv-train-auc:0.8461956+0.0012175165871560062\n",
      "[162]\tcv-test-auc:0.8410093999999999+0.011442356114017766\tcv-train-auc:0.8462092+0.001214473449689222\n",
      "[163]\tcv-test-auc:0.8409739999999999+0.011435260338094626\tcv-train-auc:0.8462333+0.0012185351903002274\n",
      "[164]\tcv-test-auc:0.8409859+0.011440688776905003\tcv-train-auc:0.8462664+0.0012195359117303619\n",
      "[165]\tcv-test-auc:0.8409915+0.011447230191185973\tcv-train-auc:0.8462964000000002+0.0012184903118203092\n",
      "[166]\tcv-test-auc:0.8409831000000001+0.011442588478574245\tcv-train-auc:0.8463230999999999+0.001225851577475828\n",
      "[167]\tcv-test-auc:0.8410033+0.011422432543464638\tcv-train-auc:0.8463566+0.0012091024108817244\n",
      "[168]\tcv-test-auc:0.8409872+0.0114229690343623\tcv-train-auc:0.8463896999999999+0.001203104903988015\n",
      "[169]\tcv-test-auc:0.8410135999999999+0.011430531362976944\tcv-train-auc:0.8464064+0.0011968523885592483\n",
      "[170]\tcv-test-auc:0.8409846999999999+0.01141709317689927\tcv-train-auc:0.8464339000000001+0.00119287882452494\n",
      "[171]\tcv-test-auc:0.8409701+0.01143101489326299\tcv-train-auc:0.8464527000000001+0.0011914474432386814\n",
      "[172]\tcv-test-auc:0.8409742000000001+0.011423462450588262\tcv-train-auc:0.8464746+0.001199407120205643\n",
      "[173]\tcv-test-auc:0.8410084999999998+0.011391808532888889\tcv-train-auc:0.8465047+0.0012025044740041567\n",
      "[174]\tcv-test-auc:0.8410023000000001+0.011397431307535935\tcv-train-auc:0.8465257000000002+0.0012042043057554623\n",
      "[175]\tcv-test-auc:0.8410226999999999+0.011396567755688529\tcv-train-auc:0.8465472999999999+0.0012039061466742205\n",
      "[176]\tcv-test-auc:0.8410078999999999+0.011384311120572919\tcv-train-auc:0.84658+0.0011938632249969125\n",
      "[177]\tcv-test-auc:0.8410199+0.011380972088973774\tcv-train-auc:0.8466038000000001+0.0011887294730089006\n",
      "[178]\tcv-test-auc:0.8410238+0.011378425398973243\tcv-train-auc:0.8466349+0.0011814150371482382\n",
      "[179]\tcv-test-auc:0.8410412+0.011381038202202804\tcv-train-auc:0.8466600000000002+0.0011812265659051184\n",
      "[180]\tcv-test-auc:0.8410445+0.011377104493235526\tcv-train-auc:0.8467034+0.001188202272342553\n",
      "[181]\tcv-test-auc:0.8410402000000001+0.01137945305188259\tcv-train-auc:0.8467136+0.0011925856111827061\n",
      "[182]\tcv-test-auc:0.8410302000000002+0.011369882240375218\tcv-train-auc:0.8467304999999999+0.001188289211429607\n",
      "[183]\tcv-test-auc:0.8410360999999998+0.011386106704664228\tcv-train-auc:0.8467583000000001+0.001181844579460424\n",
      "[184]\tcv-test-auc:0.8410517000000001+0.011388739684881749\tcv-train-auc:0.8467817999999999+0.0011859247699580215\n",
      "[185]\tcv-test-auc:0.8410458000000001+0.01136979887069247\tcv-train-auc:0.8468173+0.0011856665678005795\n",
      "[186]\tcv-test-auc:0.8410331000000001+0.011368019655595245\tcv-train-auc:0.8468429000000001+0.0011828575104381744\n",
      "[187]\tcv-test-auc:0.8410477999999999+0.011354807808148917\tcv-train-auc:0.8468747000000001+0.0011783370527994339\n",
      "[188]\tcv-test-auc:0.8410428999999999+0.011357099792200455\tcv-train-auc:0.8469070000000001+0.001173152505005227\n",
      "[189]\tcv-test-auc:0.8410524+0.011363992372401512\tcv-train-auc:0.8469283000000001+0.0011708469626727435\n",
      "[190]\tcv-test-auc:0.8411012000000001+0.011336053623726373\tcv-train-auc:0.8469523999999999+0.001155039497160172\n",
      "[191]\tcv-test-auc:0.8410988999999999+0.011332308744911613\tcv-train-auc:0.8469821999999999+0.0011529318106462258\n",
      "[192]\tcv-test-auc:0.8411101000000001+0.011334680511156908\tcv-train-auc:0.8470074000000001+0.001155047721957835\n",
      "[193]\tcv-test-auc:0.8411035+0.011329725462251935\tcv-train-auc:0.8470378999999999+0.0011512762005704818\n",
      "[194]\tcv-test-auc:0.8410928+0.011342393281843118\tcv-train-auc:0.8470767+0.0011483336666666254\n",
      "[195]\tcv-test-auc:0.8410854999999999+0.011336154958803277\tcv-train-auc:0.8470997+0.0011532803692077685\n",
      "[196]\tcv-test-auc:0.8410844+0.011347091823017925\tcv-train-auc:0.8471351+0.001160342574414983\n",
      "[197]\tcv-test-auc:0.8410964+0.011342296444724061\tcv-train-auc:0.8471622+0.0011587506893201993\n",
      "[198]\tcv-test-auc:0.841073+0.011344628737865337\tcv-train-auc:0.8471947+0.0011666166508326496\n",
      "[199]\tcv-test-auc:0.8410763000000001+0.011344211960731328\tcv-train-auc:0.8472324+0.0011749522713710558\n",
      "[200]\tcv-test-auc:0.8410686999999999+0.011352808516398043\tcv-train-auc:0.8472638+0.0011760521927193445\n",
      "[201]\tcv-test-auc:0.841073+0.011367146590063836\tcv-train-auc:0.8472886000000001+0.0011799286588603667\n",
      "[202]\tcv-test-auc:0.8411026999999999+0.011396120796569327\tcv-train-auc:0.8473259000000001+0.0011745080204068545\n",
      "[203]\tcv-test-auc:0.8410925+0.011390905971431765\tcv-train-auc:0.8473379+0.0011755241766973758\n",
      "[204]\tcv-test-auc:0.8410787000000001+0.011390967571282086\tcv-train-auc:0.8473658000000001+0.0011791795283161814\n",
      "[205]\tcv-test-auc:0.8410563+0.011390781597853592\tcv-train-auc:0.8473955+0.0011788037368451096\n",
      "[206]\tcv-test-auc:0.841062+0.011406805959601493\tcv-train-auc:0.8474305+0.0011743258704465438\n",
      "[207]\tcv-test-auc:0.8410778000000001+0.011379808959732146\tcv-train-auc:0.8474665+0.0011751480970499\n",
      "[208]\tcv-test-auc:0.8410677000000002+0.011380166167943241\tcv-train-auc:0.8475009+0.0011748787554467027\n",
      "[209]\tcv-test-auc:0.8410658999999999+0.011384689933854136\tcv-train-auc:0.8475276+0.0011852255650297125\n",
      "[210]\tcv-test-auc:0.841075+0.011392111489974096\tcv-train-auc:0.8475505999999999+0.0011878216364421123\n",
      "[211]\tcv-test-auc:0.8410719+0.011399597751236671\tcv-train-auc:0.8475913+0.0011760022151339551\n",
      "[212]\tcv-test-auc:0.841048+0.011409994522347497\tcv-train-auc:0.8476138000000001+0.0011778969224851593\n",
      "[213]\tcv-test-auc:0.8410380999999999+0.011393851310685077\tcv-train-auc:0.8476508+0.0011754681450384013\n",
      "[214]\tcv-test-auc:0.8410264+0.01140970559830534\tcv-train-auc:0.8476731000000001+0.0011734165884288497\n",
      "[215]\tcv-test-auc:0.8409991+0.011410881109274587\tcv-train-auc:0.8477115999999999+0.0011804212976729898\n",
      "[216]\tcv-test-auc:0.8410132000000001+0.011425456549302508\tcv-train-auc:0.8477410000000001+0.0011701167463120882\n",
      "[217]\tcv-test-auc:0.8410082000000001+0.011434263804897975\tcv-train-auc:0.8477752000000001+0.0011651042700119266\n",
      "[218]\tcv-test-auc:0.8409707+0.01145438096144876\tcv-train-auc:0.8478127000000001+0.0011595888107428392\n",
      "[219]\tcv-test-auc:0.8409546000000001+0.011465596322913173\tcv-train-auc:0.8478405999999999+0.001158432147344002\n",
      "[220]\tcv-test-auc:0.8409557+0.011467849179772109\tcv-train-auc:0.8478763+0.0011588189720573136\n",
      "[221]\tcv-test-auc:0.8409711+0.011457700907686484\tcv-train-auc:0.8479085+0.0011626843294721021\n",
      "[222]\tcv-test-auc:0.8409597000000002+0.011458628496028668\tcv-train-auc:0.847935+0.0011545639003537255\n",
      "[223]\tcv-test-auc:0.8409325000000001+0.011482550241562202\tcv-train-auc:0.8479698000000001+0.0011596410479109472\n",
      "[224]\tcv-test-auc:0.8409186999999999+0.011496122424974423\tcv-train-auc:0.8480003+0.0011583553038683621\n",
      "[225]\tcv-test-auc:0.8408901+0.011485671251172043\tcv-train-auc:0.8480239+0.0011591422216449675\n",
      "[226]\tcv-test-auc:0.8408742+0.011485568142673668\tcv-train-auc:0.8480561+0.001159177678356494\n",
      "[227]\tcv-test-auc:0.8408678+0.011492792409157996\tcv-train-auc:0.8480801999999998+0.001165598198351386\n",
      "[228]\tcv-test-auc:0.8408679999999998+0.011475246228295063\tcv-train-auc:0.848117+0.0011734505528568381\n",
      "[229]\tcv-test-auc:0.8408821999999999+0.01146942734228699\tcv-train-auc:0.8481572999999999+0.001179868980014324\n",
      "[230]\tcv-test-auc:0.8408804000000002+0.0114737964179255\tcv-train-auc:0.8481876999999999+0.0011867083929929844\n",
      "[231]\tcv-test-auc:0.84087+0.011472217911110295\tcv-train-auc:0.8482155+0.001187421092115178\n",
      "[232]\tcv-test-auc:0.8408806999999999+0.011482176135646054\tcv-train-auc:0.8482467999999999+0.0011815845124238807\n",
      "[233]\tcv-test-auc:0.8408846999999999+0.011473057038557763\tcv-train-auc:0.8482828+0.0011777705039607627\n",
      "[234]\tcv-test-auc:0.8408722+0.011454648836171272\tcv-train-auc:0.8483187000000001+0.0011805817252524336\n",
      "[235]\tcv-test-auc:0.8408758000000001+0.011446203395012677\tcv-train-auc:0.8483516+0.0011875899292264063\n",
      "[236]\tcv-test-auc:0.8408575+0.011453091261751118\tcv-train-auc:0.8483854+0.0011987619613584703\n",
      "[237]\tcv-test-auc:0.8408476+0.0114826079720593\tcv-train-auc:0.8484136+0.0011916315873624745\n",
      "[238]\tcv-test-auc:0.8408483999999999+0.011489539252728982\tcv-train-auc:0.8484414000000001+0.0011937742835226484\n",
      "[239]\tcv-test-auc:0.8408559+0.011447138336283002\tcv-train-auc:0.8484765000000001+0.0012117391014570887\n",
      "[240]\tcv-test-auc:0.8408722999999998+0.011448014037814593\tcv-train-auc:0.8485054+0.0012143661885938547\n",
      "[241]\tcv-test-auc:0.8408761+0.011430439776753992\tcv-train-auc:0.8485405+0.00121838296524533\n",
      "[242]\tcv-test-auc:0.8409001+0.011451602284833344\tcv-train-auc:0.8485859+0.0012254248610176067\n",
      "[243]\tcv-test-auc:0.8409143+0.011437383197654942\tcv-train-auc:0.8486305+0.001234236626421382\n",
      "[244]\tcv-test-auc:0.8408939+0.01144931784387176\tcv-train-auc:0.8486546+0.0012415682985643694\n",
      "[245]\tcv-test-auc:0.8408857+0.01142723989465522\tcv-train-auc:0.8486851+0.0012403897331080957\n",
      "[246]\tcv-test-auc:0.8408795+0.01144190175844907\tcv-train-auc:0.8487169+0.0012322211205786084\n",
      "[247]\tcv-test-auc:0.8408629999999999+0.011448998253122403\tcv-train-auc:0.848748+0.001234326699055019\n",
      "[248]\tcv-test-auc:0.8408709999999999+0.011455125403067399\tcv-train-auc:0.8487766000000001+0.0012222490089993817\n",
      "[249]\tcv-test-auc:0.8408660000000001+0.011460761972923065\tcv-train-auc:0.8487956999999999+0.0012232659604517802\n",
      "[250]\tcv-test-auc:0.8408597999999999+0.011480517399490325\tcv-train-auc:0.8488404+0.0012246577644386765\n",
      "[251]\tcv-test-auc:0.8408654999999999+0.011461582816086082\tcv-train-auc:0.848874+0.0012219705397430876\n",
      "[252]\tcv-test-auc:0.8408720000000001+0.01144872440929556\tcv-train-auc:0.8489072+0.0012163183629296894\n",
      "[253]\tcv-test-auc:0.8408849+0.011469025184818458\tcv-train-auc:0.8489456000000001+0.0012254337354585822\n",
      "[254]\tcv-test-auc:0.8408854+0.011477707891386685\tcv-train-auc:0.8489720000000001+0.0012219958265067858\n",
      "[255]\tcv-test-auc:0.8408806999999999+0.011465280215066704\tcv-train-auc:0.8489962+0.0012241054529737322\n",
      "[256]\tcv-test-auc:0.8408764+0.011457046060830868\tcv-train-auc:0.8490207+0.0012221519586369045\n",
      "[257]\tcv-test-auc:0.840888+0.011449177428968425\tcv-train-auc:0.8490499+0.0012169573903797885\n",
      "[258]\tcv-test-auc:0.8408789999999999+0.011430061242180635\tcv-train-auc:0.8490765999999998+0.0012156600018097246\n",
      "[259]\tcv-test-auc:0.8408725+0.011432171318257956\tcv-train-auc:0.8490963+0.00121709326265493\n",
      "[260]\tcv-test-auc:0.8408627+0.011419952390881496\tcv-train-auc:0.8491237+0.001218917146486997\n",
      "[261]\tcv-test-auc:0.8408637999999999+0.011419048575078413\tcv-train-auc:0.8491569999999999+0.001216688127664601\n",
      "[262]\tcv-test-auc:0.8408439+0.01142782569389294\tcv-train-auc:0.8491809+0.0012205056697942888\n",
      "[263]\tcv-test-auc:0.8408568000000001+0.011451564974273173\tcv-train-auc:0.8492097000000001+0.0012186638625970572\n",
      "[264]\tcv-test-auc:0.8408287+0.011438300416145727\tcv-train-auc:0.8492405000000002+0.001216013836269961\n",
      "[265]\tcv-test-auc:0.8408209+0.011425569416444863\tcv-train-auc:0.8492726999999999+0.001215436386652959\n",
      "[266]\tcv-test-auc:0.8408244+0.011409323250745422\tcv-train-auc:0.8492936+0.0012055942269271211\n",
      "[267]\tcv-test-auc:0.8408218999999999+0.011412499292004356\tcv-train-auc:0.849323+0.0011917098640189222\n",
      "[268]\tcv-test-auc:0.8408258999999999+0.011427360862858942\tcv-train-auc:0.8493635999999999+0.0012008543791817454\n",
      "[269]\tcv-test-auc:0.8408144+0.011429621701526253\tcv-train-auc:0.8493956+0.0011959467546676162\n",
      "[270]\tcv-test-auc:0.8408354000000001+0.01144409491571963\tcv-train-auc:0.8494206999999999+0.0011897565339177504\n",
      "[271]\tcv-test-auc:0.8408456999999998+0.011461933441178214\tcv-train-auc:0.8494524999999999+0.001182126917889931\n",
      "[272]\tcv-test-auc:0.8408288+0.011437658893322537\tcv-train-auc:0.849484+0.001178314389286683\n",
      "[273]\tcv-test-auc:0.8408324+0.011425170311203246\tcv-train-auc:0.8495194999999999+0.0011777000679290067\n",
      "[274]\tcv-test-auc:0.8408249+0.011427905840091613\tcv-train-auc:0.8495525+0.0011839623515973827\n",
      "[275]\tcv-test-auc:0.8408068+0.011422349108655366\tcv-train-auc:0.8495870999999999+0.0011875006905261048\n",
      "[276]\tcv-test-auc:0.8408154000000001+0.0114117392469334\tcv-train-auc:0.8496153+0.0011817329689908836\n",
      "[277]\tcv-test-auc:0.8408392000000001+0.01140580140805548\tcv-train-auc:0.8496586+0.0011811862850541512\n",
      "[278]\tcv-test-auc:0.8408529999999999+0.011401821301879805\tcv-train-auc:0.8496929+0.001177028924878233\n",
      "[279]\tcv-test-auc:0.8408629000000001+0.01140428242766726\tcv-train-auc:0.8497299+0.0011821457989605118\n",
      "[280]\tcv-test-auc:0.8408640000000001+0.011416521081310185\tcv-train-auc:0.8497512+0.0011694714874677318\n",
      "[281]\tcv-test-auc:0.8408447000000001+0.011415713758236913\tcv-train-auc:0.8497888+0.0011778813862184999\n",
      "[282]\tcv-test-auc:0.8408412999999999+0.011400762045144171\tcv-train-auc:0.8498153+0.0011740374823658761\n",
      "[283]\tcv-test-auc:0.8408526999999999+0.01142418082883843\tcv-train-auc:0.8498431+0.0011767377320371815\n",
      "[284]\tcv-test-auc:0.8408390000000001+0.011419747168829958\tcv-train-auc:0.849873+0.0011745729436693079\n",
      "[285]\tcv-test-auc:0.8408254+0.011430155512502873\tcv-train-auc:0.8498977999999999+0.0011788295720756082\n",
      "[286]\tcv-test-auc:0.8408378999999998+0.011420318668496071\tcv-train-auc:0.8499291+0.001181676389710807\n",
      "[287]\tcv-test-auc:0.8408129000000001+0.01140207634994609\tcv-train-auc:0.8499642+0.0011821096226661953\n",
      "[288]\tcv-test-auc:0.8408108999999999+0.011421859108306334\tcv-train-auc:0.8499964+0.0011762614675317733\n",
      "[289]\tcv-test-auc:0.8408243000000001+0.011438490031905448\tcv-train-auc:0.8500212000000001+0.0011780675532413194\n",
      "[290]\tcv-test-auc:0.8408367999999999+0.01145735739863255\tcv-train-auc:0.8500535000000001+0.0011826500116264291\n",
      "[291]\tcv-test-auc:0.8408376000000001+0.011468577306710701\tcv-train-auc:0.8500789+0.0011748027451448891\n",
      "[292]\tcv-test-auc:0.8408241000000001+0.011483622037057824\tcv-train-auc:0.8501092+0.00117210492704367\n",
      "[293]\tcv-test-auc:0.8408214+0.011475701514068765\tcv-train-auc:0.8501387999999999+0.001167404026033816\n",
      "[294]\tcv-test-auc:0.8408289+0.011471641874204411\tcv-train-auc:0.8501639000000001+0.001161511553967498\n",
      "[295]\tcv-test-auc:0.8408381+0.011465099724380949\tcv-train-auc:0.8501966000000001+0.0011729879112761493\n",
      "[296]\tcv-test-auc:0.8408371000000001+0.011457423553748897\tcv-train-auc:0.8502279000000001+0.0011719384326832304\n",
      "[297]\tcv-test-auc:0.8408460999999999+0.011462743000259576\tcv-train-auc:0.850258+0.0011602878953087528\n",
      "[298]\tcv-test-auc:0.8408500999999999+0.011471058778072757\tcv-train-auc:0.8502841+0.0011562889301554432\n",
      "[299]\tcv-test-auc:0.8408352000000001+0.01148117013026112\tcv-train-auc:0.8503132000000001+0.0011562202039403977\n",
      "[300]\tcv-test-auc:0.8408225999999999+0.0114597378172452\tcv-train-auc:0.8503396999999999+0.0011515433165973335\n",
      "[301]\tcv-test-auc:0.840837+0.011459719717340385\tcv-train-auc:0.8503665+0.0011561711162280375\n",
      "[302]\tcv-test-auc:0.8408272999999999+0.011465163366040617\tcv-train-auc:0.8503968000000001+0.00115152306099355\n",
      "[303]\tcv-test-auc:0.8408186000000001+0.011474685522488202\tcv-train-auc:0.8504304999999999+0.0011571714004416011\n",
      "[304]\tcv-test-auc:0.8408075+0.011491663223833189\tcv-train-auc:0.8504643+0.001154402707030785\n",
      "[305]\tcv-test-auc:0.8408009+0.011480425144131199\tcv-train-auc:0.8504932000000001+0.0011609911110770773\n",
      "[306]\tcv-test-auc:0.8408182+0.01147905584793454\tcv-train-auc:0.8505219+0.0011600555547041733\n",
      "[307]\tcv-test-auc:0.8408181000000001+0.011484268530907837\tcv-train-auc:0.8505474+0.0011611186158183924\n",
      "[308]\tcv-test-auc:0.840795+0.011496995016090077\tcv-train-auc:0.8505837000000002+0.0011589506503730134\n",
      "[309]\tcv-test-auc:0.8408129000000001+0.011500521096454715\tcv-train-auc:0.8506155+0.0011522328974647384\n",
      "[310]\tcv-test-auc:0.8408069999999999+0.011498168323693991\tcv-train-auc:0.8506419000000001+0.0011480514317747297\n",
      "[311]\tcv-test-auc:0.8408039+0.011494657423777355\tcv-train-auc:0.8506723+0.0011447848749874421\n",
      "[312]\tcv-test-auc:0.8408219000000001+0.01151989703469611\tcv-train-auc:0.8507030999999999+0.0011489341539009078\n",
      "[313]\tcv-test-auc:0.8408211999999999+0.011522165011836965\tcv-train-auc:0.8507412999999999+0.0011544926201583184\n",
      "[314]\tcv-test-auc:0.8408207000000001+0.011523288931984675\tcv-train-auc:0.8507812000000001+0.0011472227159535992\n",
      "[315]\tcv-test-auc:0.8408175999999999+0.01153052372791453\tcv-train-auc:0.8508143+0.001154241313590875\n",
      "[316]\tcv-test-auc:0.8407963+0.011522081730746404\tcv-train-auc:0.8508454000000001+0.0011600619121408962\n",
      "[317]\tcv-test-auc:0.8408133999999998+0.011532028175477202\tcv-train-auc:0.8508747+0.001161019383989765\n",
      "[318]\tcv-test-auc:0.8408133+0.011529860554664133\tcv-train-auc:0.8509015999999999+0.0011570074502785337\n",
      "[319]\tcv-test-auc:0.8408106+0.011524780520252879\tcv-train-auc:0.8509309+0.0011593037091288897\n",
      "[320]\tcv-test-auc:0.8408205000000001+0.011519908083400686\tcv-train-auc:0.8509639+0.0011616501581801486\n",
      "[321]\tcv-test-auc:0.8408203000000001+0.01152484144836709\tcv-train-auc:0.8509928999999999+0.0011585000172636966\n",
      "[322]\tcv-test-auc:0.840825+0.011539114125443077\tcv-train-auc:0.8510306+0.0011630503170542668\n",
      "[323]\tcv-test-auc:0.8408249+0.011551171935782093\tcv-train-auc:0.8510641+0.001163374526968837\n",
      "[324]\tcv-test-auc:0.8408278000000001+0.011555273642800496\tcv-train-auc:0.8511001+0.0011624379080191717\n",
      "[325]\tcv-test-auc:0.8408251+0.011567524484089056\tcv-train-auc:0.8511320000000001+0.0011624433749649842\n",
      "[326]\tcv-test-auc:0.8408198+0.01158406908473873\tcv-train-auc:0.8511623+0.0011556192322733578\n",
      "[327]\tcv-test-auc:0.8408092+0.011591325211553701\tcv-train-auc:0.8511929+0.0011533539309336062\n",
      "[328]\tcv-test-auc:0.8408156+0.011597786221516589\tcv-train-auc:0.8512354+0.0011468006103939664\n",
      "[329]\tcv-test-auc:0.8408197+0.011596325616763279\tcv-train-auc:0.8512709+0.0011453611177266322\n",
      "[330]\tcv-test-auc:0.8408218+0.011579721523421882\tcv-train-auc:0.8513078000000001+0.0011456663388613663\n",
      "[331]\tcv-test-auc:0.8408215+0.011596679363076314\tcv-train-auc:0.8513456999999999+0.001147650473794176\n",
      "[332]\tcv-test-auc:0.8408281000000001+0.01160374765711492\tcv-train-auc:0.8513767999999999+0.0011385587204883257\n",
      "[333]\tcv-test-auc:0.8408294+0.011611197803844363\tcv-train-auc:0.8514065000000001+0.0011386451817840342\n",
      "[334]\tcv-test-auc:0.8408466000000001+0.01162464183706319\tcv-train-auc:0.8514360999999999+0.0011410953904034441\n",
      "[335]\tcv-test-auc:0.8408260000000001+0.01162224172008136\tcv-train-auc:0.8514695999999999+0.0011360347001742653\n",
      "[336]\tcv-test-auc:0.8408346+0.011627195028896696\tcv-train-auc:0.8514946+0.001131389694137253\n",
      "[337]\tcv-test-auc:0.8408148000000001+0.011630943545559859\tcv-train-auc:0.8515332000000001+0.0011351950317015885\n",
      "[338]\tcv-test-auc:0.8408113+0.011629636787535568\tcv-train-auc:0.8515688000000001+0.0011269371588513808\n",
      "[339]\tcv-test-auc:0.8407997+0.011628096164463043\tcv-train-auc:0.8516073000000001+0.0011291154103987699\n",
      "[340]\tcv-test-auc:0.8408054999999999+0.011632269178883369\tcv-train-auc:0.851634+0.0011263431981416645\n",
      "[341]\tcv-test-auc:0.8408256+0.011630120439617121\tcv-train-auc:0.8516656000000001+0.0011307664834084915\n",
      "[342]\tcv-test-auc:0.8408254+0.011632964886046895\tcv-train-auc:0.8516963000000001+0.0011263593609501421\n",
      "[343]\tcv-test-auc:0.8408355000000001+0.011649189639198098\tcv-train-auc:0.8517296999999999+0.0011308684317815239\n",
      "[344]\tcv-test-auc:0.8408241000000001+0.011648066899275594\tcv-train-auc:0.8517566999999999+0.0011281811069150233\n",
      "[345]\tcv-test-auc:0.8408068999999999+0.011644104065577579\tcv-train-auc:0.8517913+0.0011273779357429254\n",
      "[346]\tcv-test-auc:0.8408102+0.011662301357793838\tcv-train-auc:0.8518222999999999+0.001125370698925456\n",
      "[347]\tcv-test-auc:0.8407973+0.011659089064330884\tcv-train-auc:0.851854+0.0011218088072394673\n",
      "[348]\tcv-test-auc:0.840798+0.011643342372360263\tcv-train-auc:0.8518806000000001+0.0011190085969285523\n",
      "[349]\tcv-test-auc:0.8407942+0.011652178283908963\tcv-train-auc:0.8519109+0.0011095277779307718\n",
      "[350]\tcv-test-auc:0.8407832+0.011662259101906446\tcv-train-auc:0.8519344+0.0011159886379350024\n",
      "[351]\tcv-test-auc:0.840781+0.011664602590744373\tcv-train-auc:0.8519635999999998+0.0011245745150944828\n",
      "[352]\tcv-test-auc:0.840774+0.011648491447393538\tcv-train-auc:0.8519880000000001+0.0011211726004500717\n",
      "[353]\tcv-test-auc:0.8407764+0.011644891121861123\tcv-train-auc:0.8520163999999999+0.0011220585724462028\n",
      "[354]\tcv-test-auc:0.8407716000000001+0.011657614448934222\tcv-train-auc:0.8520413+0.0011208721648787823\n",
      "[355]\tcv-test-auc:0.8407709999999999+0.011662168194636882\tcv-train-auc:0.8520793000000001+0.0011240471564841036\n",
      "[356]\tcv-test-auc:0.8407606+0.01166118418686539\tcv-train-auc:0.8521167999999999+0.0011224963073435971\n",
      "[357]\tcv-test-auc:0.8407581000000001+0.011675243230442785\tcv-train-auc:0.8521438+0.0011195130012643822\n",
      "[358]\tcv-test-auc:0.8407654000000001+0.011673402025116759\tcv-train-auc:0.8521740000000001+0.001121367647116698\n",
      "[359]\tcv-test-auc:0.8407646999999999+0.011671277899613232\tcv-train-auc:0.8521980000000001+0.001112165545231461\n",
      "[360]\tcv-test-auc:0.8407685+0.011670004509425003\tcv-train-auc:0.8522309+0.001116821153990193\n",
      "[361]\tcv-test-auc:0.8407709000000001+0.01166747053521027\tcv-train-auc:0.8522611+0.0011158438466022217\n",
      "[362]\tcv-test-auc:0.8407587+0.011668920181833431\tcv-train-auc:0.8522916+0.0011117538576501393\n",
      "[363]\tcv-test-auc:0.8407611999999999+0.011664322421812584\tcv-train-auc:0.8523251000000001+0.0011114092360602452\n",
      "[364]\tcv-test-auc:0.8407515+0.011656954715962483\tcv-train-auc:0.852356+0.0011090039675312122\n",
      "[365]\tcv-test-auc:0.8407402000000002+0.011656377523055766\tcv-train-auc:0.8523831999999999+0.00110542361111026\n",
      "[366]\tcv-test-auc:0.8407418999999999+0.011643531109160998\tcv-train-auc:0.8524134999999999+0.0011020524715275506\n",
      "[367]\tcv-test-auc:0.8407438+0.011638249497239716\tcv-train-auc:0.8524474999999999+0.0010999052004604822\n",
      "[368]\tcv-test-auc:0.8407574+0.01163620867121247\tcv-train-auc:0.852479+0.0010957009628543817\n",
      "[369]\tcv-test-auc:0.8407695000000001+0.011637602495789249\tcv-train-auc:0.8525148999999999+0.0010995999681702505\n",
      "[370]\tcv-test-auc:0.8407503999999999+0.011642017962535557\tcv-train-auc:0.8525450000000001+0.0011007884447067837\n",
      "[371]\tcv-test-auc:0.8407575000000002+0.011631572432392785\tcv-train-auc:0.8525818+0.0011001437906019427\n",
      "[372]\tcv-test-auc:0.8407548+0.011633721200028816\tcv-train-auc:0.8526123+0.0010978540932200344\n",
      "[373]\tcv-test-auc:0.8407572+0.011635292053059942\tcv-train-auc:0.8526531+0.0011007565080434502\n",
      "[374]\tcv-test-auc:0.8407633000000001+0.011636247935223791\tcv-train-auc:0.8526847999999999+0.0010990710441095267\n",
      "[375]\tcv-test-auc:0.8407655999999999+0.011634022582065062\tcv-train-auc:0.8527058999999999+0.001096875786039609\n",
      "[376]\tcv-test-auc:0.8407764+0.011637931802515449\tcv-train-auc:0.8527435999999999+0.001094323644997219\n",
      "[377]\tcv-test-auc:0.8407853+0.011638464160274762\tcv-train-auc:0.8527710999999998+0.001093098755831324\n",
      "[378]\tcv-test-auc:0.8408003000000001+0.011644888990883515\tcv-train-auc:0.8527931000000001+0.0010857303947113285\n",
      "[379]\tcv-test-auc:0.8407975999999999+0.011649688778675584\tcv-train-auc:0.8528264000000002+0.0010877827172739898\n",
      "[380]\tcv-test-auc:0.8407956000000001+0.011647386807348678\tcv-train-auc:0.8528549999999999+0.001090959210969865\n",
      "[381]\tcv-test-auc:0.8407935999999999+0.01165589497378903\tcv-train-auc:0.8528849000000001+0.001090374747506575\n",
      "[382]\tcv-test-auc:0.8407775+0.011656347097182738\tcv-train-auc:0.8529135+0.0010978270583293236\n",
      "[383]\tcv-test-auc:0.8408025+0.01164593267411416\tcv-train-auc:0.8529458+0.001096194033919181\n",
      "[384]\tcv-test-auc:0.8408030999999999+0.01163757078990284\tcv-train-auc:0.8529764+0.0010968122172915456\n",
      "[385]\tcv-test-auc:0.8407934000000001+0.011647399230729594\tcv-train-auc:0.8530035999999999+0.0010936933025304625\n",
      "[386]\tcv-test-auc:0.8407932+0.011638284416528064\tcv-train-auc:0.8530308+0.0010999821634917436\n",
      "[387]\tcv-test-auc:0.8407869+0.011638208955419213\tcv-train-auc:0.8530571+0.0010995132059234036\n",
      "[388]\tcv-test-auc:0.8407835+0.01164472070296236\tcv-train-auc:0.8530884999999999+0.0010926473584830637\n",
      "[389]\tcv-test-auc:0.8407864+0.011656537678058599\tcv-train-auc:0.8531124+0.001089085322644644\n",
      "[390]\tcv-test-auc:0.8408006+0.011649274056352176\tcv-train-auc:0.8531445999999999+0.001085864190403211\n",
      "[391]\tcv-test-auc:0.840797+0.011650168496635567\tcv-train-auc:0.8531675+0.0010847398075114858\n",
      "[392]\tcv-test-auc:0.8408096+0.011645223992693323\tcv-train-auc:0.8531973+0.0010836368441502907\n",
      "Stopping. Best iteration:\n",
      "[192] cv-mean:0.8411101000000001\tcv-std:0.011334680511156908\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-auc-mean</th>\n",
       "      <th>test-auc-std</th>\n",
       "      <th>train-auc-mean</th>\n",
       "      <th>train-auc-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.824603</td>\n",
       "      <td>0.013048</td>\n",
       "      <td>0.828817</td>\n",
       "      <td>0.002037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.830138</td>\n",
       "      <td>0.013427</td>\n",
       "      <td>0.834414</td>\n",
       "      <td>0.002889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.832822</td>\n",
       "      <td>0.014340</td>\n",
       "      <td>0.836758</td>\n",
       "      <td>0.001857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.834130</td>\n",
       "      <td>0.014029</td>\n",
       "      <td>0.838006</td>\n",
       "      <td>0.001755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.834737</td>\n",
       "      <td>0.013090</td>\n",
       "      <td>0.839005</td>\n",
       "      <td>0.001210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.835009</td>\n",
       "      <td>0.013003</td>\n",
       "      <td>0.839263</td>\n",
       "      <td>0.001174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.835127</td>\n",
       "      <td>0.012478</td>\n",
       "      <td>0.839445</td>\n",
       "      <td>0.001079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.835479</td>\n",
       "      <td>0.012685</td>\n",
       "      <td>0.839598</td>\n",
       "      <td>0.001061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.836331</td>\n",
       "      <td>0.012916</td>\n",
       "      <td>0.840058</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.836476</td>\n",
       "      <td>0.012853</td>\n",
       "      <td>0.840097</td>\n",
       "      <td>0.001018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.836787</td>\n",
       "      <td>0.012580</td>\n",
       "      <td>0.840398</td>\n",
       "      <td>0.000962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.836865</td>\n",
       "      <td>0.012571</td>\n",
       "      <td>0.840477</td>\n",
       "      <td>0.000918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.837173</td>\n",
       "      <td>0.012249</td>\n",
       "      <td>0.840950</td>\n",
       "      <td>0.000760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.837629</td>\n",
       "      <td>0.012054</td>\n",
       "      <td>0.841238</td>\n",
       "      <td>0.000943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.838089</td>\n",
       "      <td>0.012192</td>\n",
       "      <td>0.841425</td>\n",
       "      <td>0.001089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.838191</td>\n",
       "      <td>0.012110</td>\n",
       "      <td>0.841594</td>\n",
       "      <td>0.001082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.838206</td>\n",
       "      <td>0.012129</td>\n",
       "      <td>0.841589</td>\n",
       "      <td>0.001079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.838279</td>\n",
       "      <td>0.012156</td>\n",
       "      <td>0.841648</td>\n",
       "      <td>0.001094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.838625</td>\n",
       "      <td>0.012087</td>\n",
       "      <td>0.841812</td>\n",
       "      <td>0.001091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.838858</td>\n",
       "      <td>0.012128</td>\n",
       "      <td>0.841973</td>\n",
       "      <td>0.001105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.838841</td>\n",
       "      <td>0.012129</td>\n",
       "      <td>0.842058</td>\n",
       "      <td>0.001186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.838840</td>\n",
       "      <td>0.012119</td>\n",
       "      <td>0.842039</td>\n",
       "      <td>0.001164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.838833</td>\n",
       "      <td>0.012088</td>\n",
       "      <td>0.842076</td>\n",
       "      <td>0.001163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.838942</td>\n",
       "      <td>0.012164</td>\n",
       "      <td>0.842164</td>\n",
       "      <td>0.001109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.839342</td>\n",
       "      <td>0.012053</td>\n",
       "      <td>0.842477</td>\n",
       "      <td>0.000777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.839389</td>\n",
       "      <td>0.012114</td>\n",
       "      <td>0.842603</td>\n",
       "      <td>0.000704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.839234</td>\n",
       "      <td>0.012251</td>\n",
       "      <td>0.842717</td>\n",
       "      <td>0.000786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.839221</td>\n",
       "      <td>0.012269</td>\n",
       "      <td>0.842746</td>\n",
       "      <td>0.000833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.839282</td>\n",
       "      <td>0.012325</td>\n",
       "      <td>0.842787</td>\n",
       "      <td>0.000850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.839320</td>\n",
       "      <td>0.012209</td>\n",
       "      <td>0.842890</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.840974</td>\n",
       "      <td>0.011435</td>\n",
       "      <td>0.846233</td>\n",
       "      <td>0.001219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.840986</td>\n",
       "      <td>0.011441</td>\n",
       "      <td>0.846266</td>\n",
       "      <td>0.001220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.840992</td>\n",
       "      <td>0.011447</td>\n",
       "      <td>0.846296</td>\n",
       "      <td>0.001218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.840983</td>\n",
       "      <td>0.011443</td>\n",
       "      <td>0.846323</td>\n",
       "      <td>0.001226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.841003</td>\n",
       "      <td>0.011422</td>\n",
       "      <td>0.846357</td>\n",
       "      <td>0.001209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.840987</td>\n",
       "      <td>0.011423</td>\n",
       "      <td>0.846390</td>\n",
       "      <td>0.001203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.841014</td>\n",
       "      <td>0.011431</td>\n",
       "      <td>0.846406</td>\n",
       "      <td>0.001197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.840985</td>\n",
       "      <td>0.011417</td>\n",
       "      <td>0.846434</td>\n",
       "      <td>0.001193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.840970</td>\n",
       "      <td>0.011431</td>\n",
       "      <td>0.846453</td>\n",
       "      <td>0.001191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.840974</td>\n",
       "      <td>0.011423</td>\n",
       "      <td>0.846475</td>\n",
       "      <td>0.001199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.841008</td>\n",
       "      <td>0.011392</td>\n",
       "      <td>0.846505</td>\n",
       "      <td>0.001203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.841002</td>\n",
       "      <td>0.011397</td>\n",
       "      <td>0.846526</td>\n",
       "      <td>0.001204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.841023</td>\n",
       "      <td>0.011397</td>\n",
       "      <td>0.846547</td>\n",
       "      <td>0.001204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.841008</td>\n",
       "      <td>0.011384</td>\n",
       "      <td>0.846580</td>\n",
       "      <td>0.001194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.841020</td>\n",
       "      <td>0.011381</td>\n",
       "      <td>0.846604</td>\n",
       "      <td>0.001189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.841024</td>\n",
       "      <td>0.011378</td>\n",
       "      <td>0.846635</td>\n",
       "      <td>0.001181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.841041</td>\n",
       "      <td>0.011381</td>\n",
       "      <td>0.846660</td>\n",
       "      <td>0.001181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.841044</td>\n",
       "      <td>0.011377</td>\n",
       "      <td>0.846703</td>\n",
       "      <td>0.001188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.841040</td>\n",
       "      <td>0.011379</td>\n",
       "      <td>0.846714</td>\n",
       "      <td>0.001193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.841030</td>\n",
       "      <td>0.011370</td>\n",
       "      <td>0.846730</td>\n",
       "      <td>0.001188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.841036</td>\n",
       "      <td>0.011386</td>\n",
       "      <td>0.846758</td>\n",
       "      <td>0.001182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.841052</td>\n",
       "      <td>0.011389</td>\n",
       "      <td>0.846782</td>\n",
       "      <td>0.001186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.841046</td>\n",
       "      <td>0.011370</td>\n",
       "      <td>0.846817</td>\n",
       "      <td>0.001186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.841033</td>\n",
       "      <td>0.011368</td>\n",
       "      <td>0.846843</td>\n",
       "      <td>0.001183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.841048</td>\n",
       "      <td>0.011355</td>\n",
       "      <td>0.846875</td>\n",
       "      <td>0.001178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.841043</td>\n",
       "      <td>0.011357</td>\n",
       "      <td>0.846907</td>\n",
       "      <td>0.001173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.841052</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.846928</td>\n",
       "      <td>0.001171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.841101</td>\n",
       "      <td>0.011336</td>\n",
       "      <td>0.846952</td>\n",
       "      <td>0.001155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.841099</td>\n",
       "      <td>0.011332</td>\n",
       "      <td>0.846982</td>\n",
       "      <td>0.001153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.841110</td>\n",
       "      <td>0.011335</td>\n",
       "      <td>0.847007</td>\n",
       "      <td>0.001155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     test-auc-mean  test-auc-std  train-auc-mean  train-auc-std\n",
       "0         0.824603      0.013048        0.828817       0.002037\n",
       "1         0.830138      0.013427        0.834414       0.002889\n",
       "2         0.832822      0.014340        0.836758       0.001857\n",
       "3         0.834130      0.014029        0.838006       0.001755\n",
       "4         0.834737      0.013090        0.839005       0.001210\n",
       "5         0.835009      0.013003        0.839263       0.001174\n",
       "6         0.835127      0.012478        0.839445       0.001079\n",
       "7         0.835479      0.012685        0.839598       0.001061\n",
       "8         0.836331      0.012916        0.840058       0.001000\n",
       "9         0.836476      0.012853        0.840097       0.001018\n",
       "10        0.836787      0.012580        0.840398       0.000962\n",
       "11        0.836865      0.012571        0.840477       0.000918\n",
       "12        0.837173      0.012249        0.840950       0.000760\n",
       "13        0.837629      0.012054        0.841238       0.000943\n",
       "14        0.838089      0.012192        0.841425       0.001089\n",
       "15        0.838191      0.012110        0.841594       0.001082\n",
       "16        0.838206      0.012129        0.841589       0.001079\n",
       "17        0.838279      0.012156        0.841648       0.001094\n",
       "18        0.838625      0.012087        0.841812       0.001091\n",
       "19        0.838858      0.012128        0.841973       0.001105\n",
       "20        0.838841      0.012129        0.842058       0.001186\n",
       "21        0.838840      0.012119        0.842039       0.001164\n",
       "22        0.838833      0.012088        0.842076       0.001163\n",
       "23        0.838942      0.012164        0.842164       0.001109\n",
       "24        0.839342      0.012053        0.842477       0.000777\n",
       "25        0.839389      0.012114        0.842603       0.000704\n",
       "26        0.839234      0.012251        0.842717       0.000786\n",
       "27        0.839221      0.012269        0.842746       0.000833\n",
       "28        0.839282      0.012325        0.842787       0.000850\n",
       "29        0.839320      0.012209        0.842890       0.001000\n",
       "..             ...           ...             ...            ...\n",
       "163       0.840974      0.011435        0.846233       0.001219\n",
       "164       0.840986      0.011441        0.846266       0.001220\n",
       "165       0.840992      0.011447        0.846296       0.001218\n",
       "166       0.840983      0.011443        0.846323       0.001226\n",
       "167       0.841003      0.011422        0.846357       0.001209\n",
       "168       0.840987      0.011423        0.846390       0.001203\n",
       "169       0.841014      0.011431        0.846406       0.001197\n",
       "170       0.840985      0.011417        0.846434       0.001193\n",
       "171       0.840970      0.011431        0.846453       0.001191\n",
       "172       0.840974      0.011423        0.846475       0.001199\n",
       "173       0.841008      0.011392        0.846505       0.001203\n",
       "174       0.841002      0.011397        0.846526       0.001204\n",
       "175       0.841023      0.011397        0.846547       0.001204\n",
       "176       0.841008      0.011384        0.846580       0.001194\n",
       "177       0.841020      0.011381        0.846604       0.001189\n",
       "178       0.841024      0.011378        0.846635       0.001181\n",
       "179       0.841041      0.011381        0.846660       0.001181\n",
       "180       0.841044      0.011377        0.846703       0.001188\n",
       "181       0.841040      0.011379        0.846714       0.001193\n",
       "182       0.841030      0.011370        0.846730       0.001188\n",
       "183       0.841036      0.011386        0.846758       0.001182\n",
       "184       0.841052      0.011389        0.846782       0.001186\n",
       "185       0.841046      0.011370        0.846817       0.001186\n",
       "186       0.841033      0.011368        0.846843       0.001183\n",
       "187       0.841048      0.011355        0.846875       0.001178\n",
       "188       0.841043      0.011357        0.846907       0.001173\n",
       "189       0.841052      0.011364        0.846928       0.001171\n",
       "190       0.841101      0.011336        0.846952       0.001155\n",
       "191       0.841099      0.011332        0.846982       0.001153\n",
       "192       0.841110      0.011335        0.847007       0.001155\n",
       "\n",
       "[193 rows x 4 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.cv(nparams, dtrain, num_boost_round=1000, early_stopping_rounds=200, \n",
    "       nfold=10, stratified=True, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.82300917,  0.82103342,  0.80044103,  0.83381446,  0.84558662,\n",
       "        0.82734036,  0.83748346,  0.85424765,  0.84115783,  0.82029631])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = train_clfs[train_index, :], train_clfs[test_index, :]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train, y_train)\n",
    "    dtest = xgb.DMatrix(X_test, y_test)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=5000, max_depth=50, max_features=50,\n",
    "                            random_state=42, n_jobs=-1)\n",
    "rf.fit(strain, target)\n",
    "test_clfs[:, 0] = rf.predict_proba(stest)[:, 1]\n",
    "sendMessage('Finished fitting RandomForest')\n",
    "del(rf)\n",
    "gc.collect()\n",
    "\n",
    "et = ExtraTreesClassifier(n_estimators=5000, max_depth=50, max_features=50,\n",
    "                          random_state=42, n_jobs=-1)\n",
    "et.fit(strain, target)\n",
    "test_clfs[:, 1] = et.predict_proba(stest)[:, 1]\n",
    "sendMessage('Finished fitting ExtraTrees')\n",
    "del(et)\n",
    "gc.collect()\n",
    "\n",
    "dtrain = xgb.DMatrix(strain, target)\n",
    "dtest = xgb.DMatrix(stest)\n",
    "fxgb = xgb.train(params, dtrain, num_boost_round=500, verbose_eval=False)\n",
    "test_clfs[:, 2] = fxgb.predict(dtest)\n",
    "sendMessage('Finished fitting XGB1')\n",
    "del(fxgb)\n",
    "gc.collect()\n",
    "\n",
    "dtrains = xgb.DMatrix(strain, target, missing=0)\n",
    "dtests = xgb.DMatrix(stest, missing=0)\n",
    "sxgb = xgb.train(params, dtrains, num_boost_round=500, verbose_eval=False)\n",
    "test_clfs[:, 3] = sxgb.predict(dtests)\n",
    "sendMessage('Finished fitting XGB2')\n",
    "del(sxgb)\n",
    "gc.collect()\n",
    "\n",
    "nb = BernoulliNB()\n",
    "nb.fit(strain, target)\n",
    "test_clfs[:, 4] = nb.predict_proba(stest)[:, 1]\n",
    "sendMessage('Finished fitting NaiveBayes')\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(strain)\n",
    "X_test_sc = sc.transform(stest)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_sc, target)\n",
    "test_clfs[:, 5] = lr.predict_proba(X_test_sc)[:, 1]\n",
    "sendMessage('Finished fitting LogisticRegression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 254/254 [01:16<00:00,  1.58it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found arrays with inconsistent numbers of samples: [ 7601 75818]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-5727f0bb752d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_predict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mtest_clfs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[0msendMessage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Finished fitting FactorizationMachine'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/libfun/vrt/lib/python3.4/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m    255\u001b[0m     return _average_binary_score(\n\u001b[0;32m    256\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/libfun/vrt/lib/python3.4/site-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/libfun/vrt/lib/python3.4/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[1;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         fpr, tpr, tresholds = roc_curve(y_true, y_score,\n\u001b[1;32m--> 252\u001b[1;33m                                         sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    253\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreorder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/libfun/vrt/lib/python3.4/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \"\"\"\n\u001b[0;32m    500\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[1;32m--> 501\u001b[1;33m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m     \u001b[1;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/libfun/vrt/lib/python3.4/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    292\u001b[0m         \u001b[0mDecreasing\u001b[0m \u001b[0mscore\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \"\"\"\n\u001b[1;32m--> 294\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[0my_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/libfun/vrt/lib/python3.4/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         raise ValueError(\"Found arrays with inconsistent numbers of samples: \"\n\u001b[1;32m--> 176\u001b[1;33m                          \"%s\" % str(uniques))\n\u001b[0m\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found arrays with inconsistent numbers of samples: [ 7601 75818]"
     ]
    }
   ],
   "source": [
    "X_train = strain\n",
    "y_train = target\n",
    "X_test = stest\n",
    "\n",
    "fm = mcmc.FMClassification(n_iter=150, rank=20)\n",
    "cn = []\n",
    "for c in X_train.columns:\n",
    "    cn.append((c, len(X_train[c].unique())))\n",
    "mask = X_train.columns[list(map(lambda x: x[1] < 500, cn))]\n",
    "for i in range(len(mask)):\n",
    "    fct, ind = pd.factorize(X_train[mask[i]])\n",
    "    X_train.loc[:, mask[i]] = fct\n",
    "    X_test.loc[:, mask[i]] = ind.get_indexer(X_test[mask[i]])\n",
    "    X_test.loc[X_test[mask[i]] == -1, mask[i]] = X_test[mask[i]].max() + 1\n",
    "ntr = pd.get_dummies(X_train[mask[0]])\n",
    "nts = pd.get_dummies(X_test[mask[0]])\n",
    "ctrain = csr_matrix(ntr.values)\n",
    "ctest = csr_matrix(nts.loc[:, ntr.columns].fillna(0).values)\n",
    "for i in tqdm(range(1, len(mask))):\n",
    "    ntr = pd.get_dummies(X_train[mask[i]])\n",
    "    nts = pd.get_dummies(X_test[mask[i]])\n",
    "    ctrain = hstack((ctrain, csr_matrix(ntr.values)))\n",
    "    ctest = hstack((ctest, csr_matrix(nts.loc[:, ntr.columns].fillna(0).values)))\n",
    "sendMessage('Fitting FactorizationMachine')\n",
    "preds = fm.fit_predict_proba(ctrain, y_train, ctest)\n",
    "test_clfs[:, 6] = preds\n",
    "print(roc_auc_score(y_test, preds))\n",
    "sendMessage('Finished fitting FactorizationMachine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfs_test = pd.DataFrame(data=test_clfs[:, :], columns=['rf', 'et', 'xgb1', 'xgb2', 'nb', 'lr', 'fm'])\n",
    "clfs_test.to_csv('clfs_test.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(test_clfs)\n",
    "dtrain = xgb.DMatrix(train_clfs, target)\n",
    "gbm = xgb.train(nparams, dtrain, num_boost_round=200, verbose_eval=True)\n",
    "predstack = gbm.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('data/sample_submission.csv', index_col='ID')\n",
    "sub.TARGET = predstack\n",
    "sub.to_csv('submission/stack.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('data/sample_submission.csv', index_col='ID')\n",
    "sub.TARGET = test_clfs[:, -1]\n",
    "sub.to_csv('submission/fm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.cross_validation import cross_val_score, StratifiedKFold\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from fastFM import mcmc\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "import xgboost as xgb\n",
    "from tqdm import *\n",
    "from libtelepot import sendMessage\n",
    "import gc\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-7137b46a63ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m         rf = RandomForestClassifier(n_estimators=5000, max_depth=50, max_features=50,\n\u001b[0;32m     13\u001b[0m                                     random_state=st, n_jobs=-1)\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;31m#train_clfs[test_index, 0] = rf.predict_proba(X_test)[:, 1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mrfres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/libfun/vrt/lib/python3.4/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    288\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 290\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/libfun/vrt/lib/python3.4/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    808\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/libfun/vrt/lib/python3.4/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    725\u001b[0m                 \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m                 \u001b[1;31m# Stop dispatching any new job in the async callback thread\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.4/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.4/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.4/threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.4/threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fold = 1\n",
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = strain.iloc[train_index].copy(), strain.iloc[test_index].copy()\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    \n",
    "    sendMessage('Going through fold {:}'.format(fold))\n",
    "    rfres = np.zeros((X_test.shape[0], 10))\n",
    "    for st in range(10):\n",
    "        rf = RandomForestClassifier(n_estimators=5000, max_depth=50, max_features=50,\n",
    "                                    random_state=st, n_jobs=-1)\n",
    "        rf.fit(X_train, y_train)\n",
    "        #train_clfs[test_index, 0] = rf.predict_proba(X_test)[:, 1]\n",
    "        rfres[:, st] = rf.predict_proba(X_test)[:, 1]\n",
    "        sendMessage('Finished fitting RandomForest {:}'.format(st))\n",
    "        del(rf)\n",
    "        gc.collect()\n",
    "    train_clfs[test_index, 0] = rfres.mean(axis=1)\n",
    "    sendMessage('ROC = {:.7f}'.format(roc_auc_score(y_test, rfres.mean(axis=1))))\n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fold = 1\n",
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = strain.iloc[train_index].copy(), strain.iloc[test_index].copy()\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    \n",
    "    sendMessage('Going through fold {:}'.format(fold))\n",
    "    etres = np.zeros((X_test.shape[0], 10))\n",
    "    for st in range(10):\n",
    "        et = ExtraTreesClassifier(n_estimators=5000, max_depth=50, max_features=50,\n",
    "                                  random_state=st, n_jobs=-1)\n",
    "        et.fit(X_train, y_train)\n",
    "        #train_clfs[test_index, 0] = rf.predict_proba(X_test)[:, 1]\n",
    "        etres[:, st] = et.predict_proba(X_test)[:, 1]\n",
    "        sendMessage('Finished fitting ExtraTrees {:}'.format(st))\n",
    "        del(et)\n",
    "        gc.collect()\n",
    "    train_clfs[test_index, 1] = etres.mean(axis=1)\n",
    "    sendMessage('ROC = {:.7f}'.format(roc_auc_score(y_test, etres.mean(axis=1))))\n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cn = []\n",
    "for c in strain.columns:\n",
    "    cn.append((c, len(strain[c].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = strain.columns[list(map(lambda x: x[1] < 500, cn))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fm = mcmc.FMClassification(n_iter=500, rank=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(mask)):\n",
    "    strain.loc[:, mask[i]] = le.fit_transform(strain[mask[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctr = ohe.fit_transform(strain[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(ctr, target, test_size=.2, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = fm.fit_predict_proba(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smooth_target_mean_cv(train, target, C, cv=None):\n",
    "    if cv == None:\n",
    "        cv = [([x for x in range(len(train))], [x for x in range(len(train))])]\n",
    "    if type(cv) == int:\n",
    "        from sklearn.cross_validation import StratifiedKFold\n",
    "        cv = StratifiedKFold(target, cv)\n",
    "    #(среднее значение * размер категории + глобальное среднее значение * C) / (размер категории + С)\n",
    "    res = np.zeros(train.shape)\n",
    "    for trx, tsx in cv:\n",
    "        Xtrain, Ytrain = train.iloc[trx], target[trx]\n",
    "        Xtest, Ytest = train.iloc[tsx], target[tsx]\n",
    "        #print(Xtrain.shape, type(Xtrain), Ytrain.shape, type(Ytrain))\n",
    "        \n",
    "        mean_target = Ytrain.mean()\n",
    "        cv_res = res[tsx]\n",
    "        #print(Xtest)\n",
    "        for val in Xtrain.unique():\n",
    "            cat_size = Xtrain.value_counts()[val]\n",
    "            cat_mean = Ytrain[np.where(Xtrain == val)].mean()\n",
    "            #print(val, cat_size, cat_mean)\n",
    "            cv_res[np.where(Xtest == val)] = float(cat_mean * cat_size + mean_target * C) / float(cat_size + C)\n",
    "            #print(cv_res)\n",
    "        res[tsx] = cv_res\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(target, n_folds=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kektrain = train.loc[:, strain.columns.union([i+'_stm' for i in mask])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kektest = test.loc[:, strain.columns.union([i+'_stm' for i in mask])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'objective': 'binary:logistic', \n",
    "          'eval_metric': 'auc',\n",
    "          'eta': 0.0202048,\n",
    "          'max_depth': 5,\n",
    "          'subsample': 0.6815,\n",
    "          'colsample_bytree': 0.701,\n",
    "          'silent': 1,\n",
    "          'seed': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(kektrain, target)\n",
    "dktrain = xgb.DMatrix(kektrain, target, missing=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 300 rounds.\n",
      "[0]\tcv-test-auc:0.7990869+0.012084441066511936\tcv-train-auc:0.8058143999999998+0.005722398783726992\n",
      "[1]\tcv-test-auc:0.8078372999999999+0.012803365432963334\tcv-train-auc:0.8172885000000001+0.005586635539392206\n",
      "[2]\tcv-test-auc:0.8108215+0.011622471778842923\tcv-train-auc:0.8218501+0.006032536356293262\n",
      "[3]\tcv-test-auc:0.8138019+0.010183201691511374\tcv-train-auc:0.8251742999999999+0.006084132888916897\n",
      "[4]\tcv-test-auc:0.8155060000000001+0.01257017604490883\tcv-train-auc:0.8283891000000001+0.004733374197124071\n",
      "[5]\tcv-test-auc:0.8171422999999999+0.01274978385738361\tcv-train-auc:0.8307667000000001+0.003963999849899093\n",
      "[6]\tcv-test-auc:0.8187840000000002+0.011781132042380307\tcv-train-auc:0.8326300999999999+0.002538578714556633\n",
      "[7]\tcv-test-auc:0.8194072+0.011782686720778075\tcv-train-auc:0.8339165999999999+0.0023872785426087167\n",
      "[8]\tcv-test-auc:0.8203502+0.012128260615603537\tcv-train-auc:0.8347163+0.0023922024182748344\n",
      "[9]\tcv-test-auc:0.8210698000000001+0.011069394895837813\tcv-train-auc:0.8357568000000001+0.0028439274533644523\n",
      "[10]\tcv-test-auc:0.8214325+0.011071423786035822\tcv-train-auc:0.8362352+0.0029957818612175308\n",
      "[11]\tcv-test-auc:0.8221515+0.01081984265366183\tcv-train-auc:0.8371327000000001+0.003054716060454715\n",
      "[12]\tcv-test-auc:0.8222845+0.010822899345831503\tcv-train-auc:0.8376979999999999+0.002782677415727518\n",
      "[13]\tcv-test-auc:0.8223454+0.0107092164437927\tcv-train-auc:0.838137+0.002703439660876494\n",
      "[14]\tcv-test-auc:0.8230443+0.0110975776460451\tcv-train-auc:0.8385757+0.0023079849674553744\n",
      "[15]\tcv-test-auc:0.8230646+0.010869193504579816\tcv-train-auc:0.8391917+0.0021477002607440377\n",
      "[16]\tcv-test-auc:0.8231563+0.010936144147276044\tcv-train-auc:0.8395277+0.0021998229042357233\n",
      "[17]\tcv-test-auc:0.8236948+0.010705545430289842\tcv-train-auc:0.840105+0.0023149815550021083\n",
      "[18]\tcv-test-auc:0.8239643000000001+0.010924843907809399\tcv-train-auc:0.8402811+0.0023999662268457058\n",
      "[19]\tcv-test-auc:0.8246239+0.01083700797683566\tcv-train-auc:0.8409931+0.002300821525021018\n",
      "[20]\tcv-test-auc:0.8245192000000001+0.011059526534169539\tcv-train-auc:0.8412447999999999+0.002169499149573484\n",
      "[21]\tcv-test-auc:0.8249731+0.011064324755266346\tcv-train-auc:0.8417005000000002+0.002150579561420601\n",
      "[22]\tcv-test-auc:0.8250857+0.011360225235883311\tcv-train-auc:0.8419193+0.002028248409342397\n",
      "[23]\tcv-test-auc:0.8249831999999999+0.01138808129405477\tcv-train-auc:0.8422322+0.001999941289138268\n",
      "[24]\tcv-test-auc:0.8254754+0.011828906248677431\tcv-train-auc:0.8424046000000001+0.0019459400401862273\n",
      "[25]\tcv-test-auc:0.8255741999999999+0.011733075895092461\tcv-train-auc:0.8427344999999999+0.0018638400816593838\n",
      "[26]\tcv-test-auc:0.8255122+0.011682541408443646\tcv-train-auc:0.8431474999999999+0.0018381909721244985\n",
      "[27]\tcv-test-auc:0.8258507999999999+0.012044037037472123\tcv-train-auc:0.8434379+0.001728857972766986\n",
      "[28]\tcv-test-auc:0.8260099999999999+0.011960266318105109\tcv-train-auc:0.8438285000000001+0.0015865613918156468\n",
      "[29]\tcv-test-auc:0.8261441999999999+0.011925580185466871\tcv-train-auc:0.8440393+0.0014897664280013705\n",
      "[30]\tcv-test-auc:0.8263659999999999+0.011814613840494311\tcv-train-auc:0.8442484+0.001526911143452699\n",
      "[31]\tcv-test-auc:0.8265741999999999+0.011698744247140371\tcv-train-auc:0.8446693000000002+0.0015164375391027484\n",
      "[32]\tcv-test-auc:0.8267382000000001+0.011623558635805135\tcv-train-auc:0.8448507000000001+0.001639808650422379\n",
      "[33]\tcv-test-auc:0.82691+0.011582639371058735\tcv-train-auc:0.8450257999999999+0.001600135919226859\n",
      "[34]\tcv-test-auc:0.8270807999999998+0.01183466538436975\tcv-train-auc:0.8452586+0.0015032639954445674\n",
      "[35]\tcv-test-auc:0.8271776+0.011636166492449312\tcv-train-auc:0.8455354999999999+0.001567382547433777\n",
      "[36]\tcv-test-auc:0.8274973000000001+0.011616859059573721\tcv-train-auc:0.8458498000000001+0.00158040809919465\n",
      "[37]\tcv-test-auc:0.8275441000000001+0.011728122632800203\tcv-train-auc:0.8460580999999999+0.0015270510436786245\n",
      "[38]\tcv-test-auc:0.8274741999999999+0.011645944099127406\tcv-train-auc:0.8462009+0.0015776130355698726\n",
      "[39]\tcv-test-auc:0.8275996999999998+0.011662879404761066\tcv-train-auc:0.8463213000000002+0.0015277220984197377\n",
      "[40]\tcv-test-auc:0.8278487+0.011571360897059603\tcv-train-auc:0.8465243000000001+0.0014992766289114402\n",
      "[41]\tcv-test-auc:0.8279505+0.011685958037319855\tcv-train-auc:0.8468509+0.0015027812515465925\n",
      "[42]\tcv-test-auc:0.8280381+0.01181773362747697\tcv-train-auc:0.8469372999999999+0.0014004675683499186\n",
      "[43]\tcv-test-auc:0.8281296999999999+0.011794321396756992\tcv-train-auc:0.8470715+0.001432678488007691\n",
      "[44]\tcv-test-auc:0.8283576+0.011885812418173198\tcv-train-auc:0.8473523000000001+0.0013998282073168769\n",
      "[45]\tcv-test-auc:0.8285229000000001+0.012046598552703586\tcv-train-auc:0.8475218+0.001439787539882172\n",
      "[46]\tcv-test-auc:0.8287507999999999+0.012100691920712638\tcv-train-auc:0.8477112+0.001488083989565121\n",
      "[47]\tcv-test-auc:0.8288052+0.012009749404546282\tcv-train-auc:0.8478646+0.0013992740403509256\n",
      "[48]\tcv-test-auc:0.8290357+0.011841612939545014\tcv-train-auc:0.8480618+0.0013057094470057212\n",
      "[49]\tcv-test-auc:0.8292334+0.011730154288840368\tcv-train-auc:0.8482474999999999+0.0012747765490469304\n",
      "[50]\tcv-test-auc:0.8293894999999999+0.0118107916267285\tcv-train-auc:0.8484363+0.0013311438727650789\n",
      "[51]\tcv-test-auc:0.8296123+0.011961233808014947\tcv-train-auc:0.8486302+0.0013185522211880854\n",
      "[52]\tcv-test-auc:0.8298763999999998+0.012024238979661057\tcv-train-auc:0.8490681999999999+0.0011236731553258684\n",
      "[53]\tcv-test-auc:0.8300059000000001+0.012063884270416396\tcv-train-auc:0.8491883+0.0011274879201126837\n",
      "[54]\tcv-test-auc:0.8301139000000001+0.011885497915106444\tcv-train-auc:0.8493276+0.0010987983618480815\n",
      "[55]\tcv-test-auc:0.8302185999999999+0.011908424792557576\tcv-train-auc:0.8494921+0.0011031330336817948\n",
      "[56]\tcv-test-auc:0.8303292000000001+0.01190635383986214\tcv-train-auc:0.8496563+0.0010894036946880463\n",
      "[57]\tcv-test-auc:0.8303974000000001+0.011901608968538655\tcv-train-auc:0.8497951+0.0011364544381540272\n",
      "[58]\tcv-test-auc:0.8305358999999999+0.011959107077453556\tcv-train-auc:0.8499905999999999+0.0012285053683236313\n",
      "[59]\tcv-test-auc:0.8307378+0.012017340486147516\tcv-train-auc:0.8501901000000001+0.0012322981335699463\n",
      "[60]\tcv-test-auc:0.8306822+0.012007115488742505\tcv-train-auc:0.8502278000000001+0.0012324585834826347\n",
      "[61]\tcv-test-auc:0.8308242+0.012004768809102492\tcv-train-auc:0.8504206+0.0011841375933564432\n",
      "[62]\tcv-test-auc:0.8308017+0.011930397085177012\tcv-train-auc:0.8505731999999998+0.0011911950134213917\n",
      "[63]\tcv-test-auc:0.8308924+0.011961914137795819\tcv-train-auc:0.8506371999999999+0.0012189567506683714\n",
      "[64]\tcv-test-auc:0.8308606+0.011807924705044463\tcv-train-auc:0.8506955999999999+0.0011972094386530612\n",
      "[65]\tcv-test-auc:0.8309510999999998+0.011803867658102565\tcv-train-auc:0.8508435999999999+0.001248919869327085\n",
      "[66]\tcv-test-auc:0.8309772000000001+0.011927403219477413\tcv-train-auc:0.8509469999999999+0.0012280210910240923\n",
      "[67]\tcv-test-auc:0.8309077+0.012151304671104262\tcv-train-auc:0.8511165+0.0012073046218746954\n",
      "[68]\tcv-test-auc:0.8311069+0.012091048758895996\tcv-train-auc:0.8512924999999999+0.0012267514214379307\n",
      "[69]\tcv-test-auc:0.8310198+0.012118744157708776\tcv-train-auc:0.8514578+0.0012676085200092433\n",
      "[70]\tcv-test-auc:0.8312231999999999+0.012254148218460551\tcv-train-auc:0.8516101+0.0012826846416793122\n",
      "[71]\tcv-test-auc:0.8313981+0.012174141665431697\tcv-train-auc:0.851783+0.001194097650948178\n",
      "[72]\tcv-test-auc:0.8316863+0.012233609459599408\tcv-train-auc:0.8519364000000001+0.0011918860012601815\n",
      "[73]\tcv-test-auc:0.8318694000000001+0.01235934118147079\tcv-train-auc:0.8520429+0.0011668604415267748\n",
      "[74]\tcv-test-auc:0.8319036000000001+0.012315550967780527\tcv-train-auc:0.8521848000000001+0.0011147575341750472\n",
      "[75]\tcv-test-auc:0.8319993+0.012355150262542334\tcv-train-auc:0.8522998999999999+0.0011321056001981414\n",
      "[76]\tcv-test-auc:0.8320578000000001+0.012383322282812468\tcv-train-auc:0.8524404000000001+0.0011179477805335928\n",
      "[77]\tcv-test-auc:0.8320900999999999+0.012372116572761504\tcv-train-auc:0.8525436000000001+0.001146091724077963\n",
      "[78]\tcv-test-auc:0.8321622999999999+0.012242997835906034\tcv-train-auc:0.8526538+0.0011503607955767729\n",
      "[79]\tcv-test-auc:0.8321769+0.012375843279954708\tcv-train-auc:0.8527818999999999+0.0011627668252921467\n",
      "[80]\tcv-test-auc:0.8323084000000002+0.012362993279946412\tcv-train-auc:0.8529030000000001+0.0010860411594410303\n",
      "[81]\tcv-test-auc:0.8324271+0.012303496766773274\tcv-train-auc:0.8529968+0.0011333243842784051\n",
      "[82]\tcv-test-auc:0.8326442000000001+0.012265917477302716\tcv-train-auc:0.8531040999999998+0.001170994999989308\n",
      "[83]\tcv-test-auc:0.8326191999999999+0.01216270181168641\tcv-train-auc:0.8532759999999999+0.0011931308394304502\n",
      "[84]\tcv-test-auc:0.8326091999999999+0.012114057749573415\tcv-train-auc:0.8533839000000001+0.0011800807133412526\n",
      "[85]\tcv-test-auc:0.8326222+0.01206943527096441\tcv-train-auc:0.8535556999999999+0.001120032593275742\n",
      "[86]\tcv-test-auc:0.8326784+0.011808616389738472\tcv-train-auc:0.8536687000000001+0.001188751870661009\n",
      "[87]\tcv-test-auc:0.8328351000000002+0.01177419578102894\tcv-train-auc:0.8537750999999998+0.0012220248319899153\n",
      "[88]\tcv-test-auc:0.8327560999999999+0.011690358116413703\tcv-train-auc:0.8539394+0.0012220481332582507\n",
      "[89]\tcv-test-auc:0.8328312999999999+0.011652821667304436\tcv-train-auc:0.8540566999999999+0.001191104113837254\n",
      "[90]\tcv-test-auc:0.8329321999999999+0.011617020709286862\tcv-train-auc:0.854175+0.0012004674089703786\n",
      "[91]\tcv-test-auc:0.832981+0.011557276599614624\tcv-train-auc:0.8543326+0.0012640382272700468\n",
      "[92]\tcv-test-auc:0.8330873000000001+0.011630353563413274\tcv-train-auc:0.8544333+0.0012363567486773305\n",
      "[93]\tcv-test-auc:0.8331199+0.01162915723042732\tcv-train-auc:0.8544985+0.0012601766741215242\n",
      "[94]\tcv-test-auc:0.8332371999999999+0.011588814786681167\tcv-train-auc:0.8546526999999999+0.0012504017794293123\n",
      "[95]\tcv-test-auc:0.8333349999999999+0.011645704976513864\tcv-train-auc:0.8547805+0.0012665463473556747\n",
      "[96]\tcv-test-auc:0.8334686000000001+0.011673093687621974\tcv-train-auc:0.8549215+0.0012423187392935889\n",
      "[97]\tcv-test-auc:0.8334835+0.011701697092729762\tcv-train-auc:0.8550337999999998+0.0012455563255027995\n",
      "[98]\tcv-test-auc:0.8335571999999999+0.011725163980090011\tcv-train-auc:0.8551694+0.0012624489058967975\n",
      "[99]\tcv-test-auc:0.8337283+0.011773130951875132\tcv-train-auc:0.8553046+0.0012780238808410387\n",
      "[100]\tcv-test-auc:0.8337788999999999+0.011831034387998348\tcv-train-auc:0.8554114+0.0013152499534308919\n",
      "[101]\tcv-test-auc:0.8338243000000001+0.011900424127315791\tcv-train-auc:0.8555415+0.0013376824174668523\n",
      "[102]\tcv-test-auc:0.8338761+0.011849074828441254\tcv-train-auc:0.8556376+0.001327214617158819\n",
      "[103]\tcv-test-auc:0.8340042999999999+0.01179255963775464\tcv-train-auc:0.8557328+0.0012873242637346837\n",
      "[104]\tcv-test-auc:0.8341203+0.011766592081397239\tcv-train-auc:0.8558713000000001+0.0012982827927689813\n",
      "[105]\tcv-test-auc:0.8341774000000001+0.011791704017655788\tcv-train-auc:0.8559517999999999+0.0013193714260965339\n",
      "[106]\tcv-test-auc:0.8342794000000001+0.01180202564138884\tcv-train-auc:0.8560909999999999+0.0013259374042540694\n",
      "[107]\tcv-test-auc:0.8343569000000001+0.011767959062216348\tcv-train-auc:0.8562023999999999+0.001305411444717737\n",
      "[108]\tcv-test-auc:0.8344712000000001+0.011595752082551612\tcv-train-auc:0.8563552+0.001354148647674983\n",
      "[109]\tcv-test-auc:0.8345524+0.011600448984414364\tcv-train-auc:0.8564586000000001+0.00136083931454084\n",
      "[110]\tcv-test-auc:0.8345895999999999+0.01162690725171573\tcv-train-auc:0.8565787+0.0013663756474703464\n",
      "[111]\tcv-test-auc:0.8346826+0.011598288056433143\tcv-train-auc:0.8566730999999999+0.0013640024523438319\n",
      "[112]\tcv-test-auc:0.8346591+0.01154247179290467\tcv-train-auc:0.8567487+0.0013346200995039768\n",
      "[113]\tcv-test-auc:0.8346626+0.011575569214513824\tcv-train-auc:0.8568334999999999+0.0013048547237144788\n",
      "[114]\tcv-test-auc:0.8346786999999999+0.011522379745955246\tcv-train-auc:0.8569673+0.0013379216755849406\n",
      "[115]\tcv-test-auc:0.8347184999999999+0.011508709921185774\tcv-train-auc:0.8570639999999999+0.0013125428754901492\n",
      "[116]\tcv-test-auc:0.8347165000000001+0.011459861842535446\tcv-train-auc:0.8571456999999999+0.0013468258276406813\n",
      "[117]\tcv-test-auc:0.8348242999999999+0.011570844861547483\tcv-train-auc:0.8572321+0.0013381983746814138\n",
      "[118]\tcv-test-auc:0.8348760000000001+0.011578209170679213\tcv-train-auc:0.8573394000000001+0.0013598543451414195\n",
      "[119]\tcv-test-auc:0.8349491+0.01153325667320382\tcv-train-auc:0.857429+0.0013489123766946575\n",
      "[120]\tcv-test-auc:0.8349853000000002+0.011543932969746488\tcv-train-auc:0.8575411+0.001374567528352097\n",
      "[121]\tcv-test-auc:0.8350626000000002+0.011436060284905802\tcv-train-auc:0.8576568999999999+0.001391269524571009\n",
      "[122]\tcv-test-auc:0.8351287000000001+0.011446411901115571\tcv-train-auc:0.8577635000000001+0.0013741515382227766\n",
      "[123]\tcv-test-auc:0.8351609999999999+0.011445539183454815\tcv-train-auc:0.8578889999999999+0.0013428114536300443\n",
      "[124]\tcv-test-auc:0.83521+0.011342677073777611\tcv-train-auc:0.8580147+0.0013363245152282497\n",
      "[125]\tcv-test-auc:0.8352975+0.01132076745852507\tcv-train-auc:0.8581025+0.0013068836405740322\n",
      "[126]\tcv-test-auc:0.8353057999999999+0.011383947863548915\tcv-train-auc:0.8581947999999999+0.0012931110393156454\n",
      "[127]\tcv-test-auc:0.8354206000000002+0.011423190134108781\tcv-train-auc:0.8583721000000001+0.0012545607558026195\n",
      "[128]\tcv-test-auc:0.8354832+0.011333777744423965\tcv-train-auc:0.8585250999999999+0.0012537115657119862\n",
      "[129]\tcv-test-auc:0.8354908+0.011293009349150495\tcv-train-auc:0.8586175+0.001238219144578214\n",
      "[130]\tcv-test-auc:0.8355987+0.01126857880169454\tcv-train-auc:0.8587342999999998+0.0012267227111291369\n",
      "[131]\tcv-test-auc:0.8356429999999999+0.011244762958817765\tcv-train-auc:0.8588688+0.0012204645672857467\n",
      "[132]\tcv-test-auc:0.8356305+0.011200073510919471\tcv-train-auc:0.8589764000000001+0.0011762270359076035\n",
      "[133]\tcv-test-auc:0.8356131000000001+0.011158173241619794\tcv-train-auc:0.859138+0.0011520947877670456\n",
      "[134]\tcv-test-auc:0.8355843000000001+0.011144798903973104\tcv-train-auc:0.8592071000000001+0.0011531337693433399\n",
      "[135]\tcv-test-auc:0.8356861999999999+0.011093846788197506\tcv-train-auc:0.8593325999999999+0.0011367612942038542\n",
      "[136]\tcv-test-auc:0.8357208+0.011114550164536573\tcv-train-auc:0.8594443999999999+0.00116278348801486\n",
      "[137]\tcv-test-auc:0.8357116+0.011054307750374963\tcv-train-auc:0.8596489999999999+0.0011787259223415688\n",
      "[138]\tcv-test-auc:0.8357495+0.011074013971907387\tcv-train-auc:0.859821+0.0012249521623312557\n",
      "[139]\tcv-test-auc:0.8357954+0.011129644200961679\tcv-train-auc:0.8599823000000001+0.0012424572467493414\n",
      "[140]\tcv-test-auc:0.8357746+0.011244093758058052\tcv-train-auc:0.8601297999999999+0.0012416187659664367\n",
      "[141]\tcv-test-auc:0.83585+0.011248313384681276\tcv-train-auc:0.8602672+0.00126462680661133\n",
      "[142]\tcv-test-auc:0.8358763+0.011243765704158007\tcv-train-auc:0.8604197000000001+0.0012629549516906824\n",
      "[143]\tcv-test-auc:0.8359335+0.011289769734144285\tcv-train-auc:0.8605775+0.0012570810833037033\n",
      "[144]\tcv-test-auc:0.8359658+0.011302704019835255\tcv-train-auc:0.8607222999999999+0.0012593923177469464\n",
      "[145]\tcv-test-auc:0.8359991999999998+0.011282124948785147\tcv-train-auc:0.8608437+0.0012588126985377994\n",
      "[146]\tcv-test-auc:0.8360949+0.011294824181455861\tcv-train-auc:0.8609959000000001+0.0012379794384398948\n",
      "[147]\tcv-test-auc:0.8361798+0.01131764906506646\tcv-train-auc:0.8611321999999999+0.0012576925538461215\n",
      "[148]\tcv-test-auc:0.8362902999999999+0.011323408656848881\tcv-train-auc:0.8612552000000001+0.0012724177615861918\n",
      "[149]\tcv-test-auc:0.8363868+0.011304544730328605\tcv-train-auc:0.8613675000000001+0.0012821649854835302\n",
      "[150]\tcv-test-auc:0.8364231999999999+0.011303981553417356\tcv-train-auc:0.8615033000000001+0.0012306576331376495\n",
      "[151]\tcv-test-auc:0.8364858999999999+0.01130470440524651\tcv-train-auc:0.8616183000000002+0.0012033799940168533\n",
      "[152]\tcv-test-auc:0.8365004+0.011269275107122004\tcv-train-auc:0.8617466+0.0011858388760704348\n",
      "[153]\tcv-test-auc:0.8365593+0.011245219055669822\tcv-train-auc:0.8619261999999999+0.0011480339542017048\n",
      "[154]\tcv-test-auc:0.8367065+0.011216904931842825\tcv-train-auc:0.8620607999999998+0.0011409289022546799\n",
      "[155]\tcv-test-auc:0.8367842000000001+0.011160728943935513\tcv-train-auc:0.8622097999999999+0.0011452717406799178\n",
      "[156]\tcv-test-auc:0.8368622+0.011028308472290757\tcv-train-auc:0.8623578999999999+0.0011770468512340786\n",
      "[157]\tcv-test-auc:0.8369688999999999+0.011088208885568478\tcv-train-auc:0.862519+0.0011220186272963672\n",
      "[158]\tcv-test-auc:0.8369817999999999+0.011073691586819643\tcv-train-auc:0.8626547+0.001103484394996142\n",
      "[159]\tcv-test-auc:0.8370777+0.010985002294492272\tcv-train-auc:0.8627800999999999+0.0010920993040928265\n",
      "[160]\tcv-test-auc:0.8371257999999999+0.010933130885524046\tcv-train-auc:0.8629419+0.0010774007100424637\n",
      "[161]\tcv-test-auc:0.8371662000000001+0.01091815885394603\tcv-train-auc:0.8630918+0.0011153252261112134\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-0370fa4aa7a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m res = xgb.cv(params, dtrain, num_boost_round=1000, nfold=10, stratified=True, early_stopping_rounds=300,\n\u001b[1;32m----> 2\u001b[1;33m              verbose_eval=True)\n\u001b[0m",
      "\u001b[1;32m/home/libfun/vrt/lib/python3.4/site-packages/xgboost-0.4-py3.4.egg/xgboost/training.py\u001b[0m in \u001b[0;36mcv\u001b[1;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed)\u001b[0m\n\u001b[0;32m    455\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mfold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m         res = aggcv([f.eval(i, feval) for f in cvfolds],\n\u001b[0m\u001b[0;32m    458\u001b[0m                     \u001b[0mshow_stdv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_stdv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose_eval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m                     as_pandas=as_pandas, trial=i)\n",
      "\u001b[1;32m/home/libfun/vrt/lib/python3.4/site-packages/xgboost-0.4-py3.4.egg/xgboost/training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    455\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mfold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m         res = aggcv([f.eval(i, feval) for f in cvfolds],\n\u001b[0m\u001b[0;32m    458\u001b[0m                     \u001b[0mshow_stdv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_stdv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose_eval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m                     as_pandas=as_pandas, trial=i)\n",
      "\u001b[1;32m/home/libfun/vrt/lib/python3.4/site-packages/xgboost-0.4-py3.4.egg/xgboost/training.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, iteration, feval)\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[1;34m\"\"\"\"Evaluate the CVPack for one iteration.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwatchlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/libfun/vrt/lib/python3.4/site-packages/xgboost-0.4-py3.4.egg/xgboost/core.py\u001b[0m in \u001b[0;36meval_set\u001b[1;34m(self, evals, iteration, feval)\u001b[0m\n\u001b[0;32m    809\u001b[0m             _check_call(_LIB.XGBoosterEvalOneIter(self.handle, iteration,\n\u001b[0;32m    810\u001b[0m                                                   \u001b[0mdmats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m                                                   ctypes.byref(msg)))\n\u001b[0m\u001b[0;32m    812\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res = xgb.cv(params, dtrain, num_boost_round=1000, nfold=10, stratified=True, early_stopping_rounds=300,\n",
    "             verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 300 rounds.\n",
      "[0]\tcv-test-auc:0.7977873999999999+0.012805475072795999\tcv-train-auc:0.804816+0.003742168943273412\n",
      "[1]\tcv-test-auc:0.8058588999999999+0.012669438112639408\tcv-train-auc:0.8147399+0.007954593647069587\n",
      "[2]\tcv-test-auc:0.8120993999999999+0.014021454954461747\tcv-train-auc:0.8230249000000001+0.0047190470319758366\n",
      "[3]\tcv-test-auc:0.8141594+0.014000972424799646\tcv-train-auc:0.826634+0.0027881818807244025\n",
      "[4]\tcv-test-auc:0.8151575+0.014008076857656085\tcv-train-auc:0.8282733999999999+0.0024758512556290555\n",
      "[5]\tcv-test-auc:0.8167145+0.014267816870495647\tcv-train-auc:0.8306479000000001+0.0024007262422025507\n",
      "[6]\tcv-test-auc:0.8167595000000001+0.015046153682918428\tcv-train-auc:0.8317422999999999+0.0022131822812411933\n",
      "[7]\tcv-test-auc:0.8182509000000001+0.014384741564936094\tcv-train-auc:0.832456+0.002538041370821204\n",
      "[8]\tcv-test-auc:0.81924+0.014299045520593318\tcv-train-auc:0.8337230999999999+0.002688838055740788\n",
      "[9]\tcv-test-auc:0.8196821+0.013684693847141762\tcv-train-auc:0.8354782999999999+0.0023506824562241685\n",
      "[10]\tcv-test-auc:0.8205081+0.014605068602714613\tcv-train-auc:0.8358244000000001+0.0019256131075581948\n",
      "[11]\tcv-test-auc:0.821356+0.015250915375806128\tcv-train-auc:0.8367568999999999+0.0016209939204080786\n",
      "[12]\tcv-test-auc:0.8219930999999999+0.014614715368080212\tcv-train-auc:0.8374227000000001+0.0018731521054094781\n",
      "[13]\tcv-test-auc:0.8222839000000001+0.013943095427128075\tcv-train-auc:0.8379351000000002+0.0018479072731065341\n",
      "[14]\tcv-test-auc:0.8229169000000001+0.013687348000617213\tcv-train-auc:0.8388221+0.0020935230808376572\n",
      "[15]\tcv-test-auc:0.8229281+0.01384115764269738\tcv-train-auc:0.8394131+0.0018156581423825235\n",
      "[16]\tcv-test-auc:0.8227834999999999+0.013643238011923728\tcv-train-auc:0.8399108999999999+0.0018698051476023006\n",
      "[17]\tcv-test-auc:0.8229947+0.013632273684532598\tcv-train-auc:0.840409+0.00166475818063766\n",
      "[18]\tcv-test-auc:0.8232091+0.01310572424133821\tcv-train-auc:0.8407055+0.0017329402903735601\n",
      "[19]\tcv-test-auc:0.8234872000000001+0.013036008774160905\tcv-train-auc:0.8409555000000001+0.001640956687423541\n",
      "[20]\tcv-test-auc:0.8241131999999999+0.012779046973855282\tcv-train-auc:0.841105+0.0016741680919190839\n",
      "[21]\tcv-test-auc:0.8246420999999999+0.012873912330367943\tcv-train-auc:0.8416658+0.0016419509006057416\n",
      "[22]\tcv-test-auc:0.8252008999999999+0.013147902756333419\tcv-train-auc:0.8421807000000001+0.0016239365166163214\n",
      "[23]\tcv-test-auc:0.8252865+0.013153780059359351\tcv-train-auc:0.8424351+0.0017308430575878274\n",
      "[24]\tcv-test-auc:0.825357+0.013328758794426427\tcv-train-auc:0.8425587999999999+0.0017852315704132119\n",
      "[25]\tcv-test-auc:0.8255922+0.01340825766309702\tcv-train-auc:0.8429506+0.0015992753484000406\n",
      "[26]\tcv-test-auc:0.825871+0.01352256314461129\tcv-train-auc:0.8434046000000001+0.001501022464855216\n",
      "[27]\tcv-test-auc:0.8258547999999999+0.013367192703032296\tcv-train-auc:0.8436682999999998+0.0014706612152361861\n",
      "[28]\tcv-test-auc:0.8259640999999999+0.013473146844371573\tcv-train-auc:0.8438855999999999+0.001323582577703412\n",
      "[29]\tcv-test-auc:0.8257823999999999+0.013555131376714862\tcv-train-auc:0.8439099999999999+0.0014493774525636785\n",
      "[30]\tcv-test-auc:0.8260622999999999+0.013574321707179317\tcv-train-auc:0.8441265+0.0013935708988063688\n",
      "[31]\tcv-test-auc:0.8261201+0.013678333490962985\tcv-train-auc:0.8442386000000001+0.0013554945370601733\n",
      "[32]\tcv-test-auc:0.8262829999999999+0.01339706508904095\tcv-train-auc:0.8443654+0.0015199165240236102\n",
      "[33]\tcv-test-auc:0.8266067999999999+0.013264453730176753\tcv-train-auc:0.8446207000000001+0.001603725353668764\n",
      "[34]\tcv-test-auc:0.8267013000000001+0.013349294483604742\tcv-train-auc:0.8447901+0.0015365140057936506\n",
      "[35]\tcv-test-auc:0.8266317000000001+0.013274935179126132\tcv-train-auc:0.8450335000000001+0.0015605960559991177\n",
      "[36]\tcv-test-auc:0.8265699+0.013378709926222334\tcv-train-auc:0.8453023+0.001540013964222424\n",
      "[37]\tcv-test-auc:0.8266619000000001+0.013427433153436277\tcv-train-auc:0.8454105999999999+0.0014482675995823474\n",
      "[38]\tcv-test-auc:0.8269886999999999+0.013631062152671757\tcv-train-auc:0.8457425000000001+0.0013837412511015273\n",
      "[39]\tcv-test-auc:0.8271191+0.013438695617134852\tcv-train-auc:0.8460003+0.001241969729904869\n",
      "[40]\tcv-test-auc:0.8269289000000001+0.013364442513251334\tcv-train-auc:0.8461829+0.0012396771716862399\n",
      "[41]\tcv-test-auc:0.8271143999999999+0.013304646731123679\tcv-train-auc:0.8462987+0.0012574986322060192\n",
      "[42]\tcv-test-auc:0.8273917+0.013321276508278013\tcv-train-auc:0.8465941000000001+0.0010744845694564496\n",
      "[43]\tcv-test-auc:0.8277381+0.013220823306057759\tcv-train-auc:0.8467874999999999+0.001114120841740228\n",
      "[44]\tcv-test-auc:0.827996+0.013182138582187636\tcv-train-auc:0.8469549000000001+0.0011361312820268633\n",
      "[45]\tcv-test-auc:0.8281177+0.013245396695078624\tcv-train-auc:0.8470983000000001+0.0010896047953271818\n",
      "[46]\tcv-test-auc:0.8282252+0.012982119039663766\tcv-train-auc:0.8472167+0.0012184158608619696\n",
      "[47]\tcv-test-auc:0.8281426999999999+0.013193989730555349\tcv-train-auc:0.8472866+0.0011658999270949505\n",
      "[48]\tcv-test-auc:0.8283048+0.013193297925840983\tcv-train-auc:0.8475436999999999+0.001208150408682623\n",
      "[49]\tcv-test-auc:0.8283479+0.013240706517780684\tcv-train-auc:0.8476661999999999+0.0011592183400895623\n",
      "[50]\tcv-test-auc:0.8285301+0.013194496227215344\tcv-train-auc:0.8477574999999999+0.0011854614502378284\n",
      "[51]\tcv-test-auc:0.8287656+0.013195564203170694\tcv-train-auc:0.8479638999999999+0.0011130184589664208\n",
      "[52]\tcv-test-auc:0.8288032+0.013118391683434366\tcv-train-auc:0.848232+0.0011683902601442608\n",
      "[53]\tcv-test-auc:0.8289681+0.013154835296954501\tcv-train-auc:0.8484389+0.0011863230967995154\n",
      "[54]\tcv-test-auc:0.8291723+0.01302883379316813\tcv-train-auc:0.8486411+0.0012155824488696597\n",
      "[55]\tcv-test-auc:0.8293196+0.013104064103933553\tcv-train-auc:0.8487317000000001+0.0011628821995369775\n",
      "[56]\tcv-test-auc:0.8295096000000001+0.012989361463905759\tcv-train-auc:0.8488857+0.0011819531335886418\n",
      "[57]\tcv-test-auc:0.8295470999999999+0.012997497424119774\tcv-train-auc:0.8490613+0.001153541507705735\n",
      "[58]\tcv-test-auc:0.8298648+0.01305706165107603\tcv-train-auc:0.8493849000000001+0.0011316386746660781\n",
      "[59]\tcv-test-auc:0.8298938999999999+0.01327174704739357\tcv-train-auc:0.8495436+0.0011526305739481219\n",
      "[60]\tcv-test-auc:0.8299939000000001+0.013245149462727847\tcv-train-auc:0.8496722+0.0011792595812627638\n",
      "[61]\tcv-test-auc:0.8301401+0.013129255504026124\tcv-train-auc:0.8498657+0.0011406709472937555\n",
      "[62]\tcv-test-auc:0.8300895+0.013124650481060431\tcv-train-auc:0.8500601+0.0011286036018018006\n",
      "[63]\tcv-test-auc:0.8302409+0.0130381873774693\tcv-train-auc:0.8502837+0.0011830779391062882\n",
      "[64]\tcv-test-auc:0.8304531+0.012975922090163778\tcv-train-auc:0.8503799000000001+0.0012208333588168384\n",
      "[65]\tcv-test-auc:0.8303782+0.012909836596951956\tcv-train-auc:0.8505686000000001+0.0011970236589140637\n",
      "[66]\tcv-test-auc:0.8303261000000001+0.012785120073350899\tcv-train-auc:0.8506583999999998+0.0011899827897915074\n",
      "[67]\tcv-test-auc:0.8304528999999998+0.01298527622694256\tcv-train-auc:0.8508131999999999+0.0011601133392905873\n",
      "[68]\tcv-test-auc:0.8306848+0.012797151509613386\tcv-train-auc:0.8509784999999999+0.001201608775766896\n",
      "[69]\tcv-test-auc:0.8307990000000001+0.012816115308470015\tcv-train-auc:0.8510741+0.0012704501131488761\n",
      "[70]\tcv-test-auc:0.8309046+0.012846635491053669\tcv-train-auc:0.8512166999999999+0.0012386170554291654\n",
      "[71]\tcv-test-auc:0.8310782+0.012809131662997294\tcv-train-auc:0.8513558+0.0012820256471693468\n",
      "[72]\tcv-test-auc:0.8311447+0.012796766451334495\tcv-train-auc:0.8515098+0.0012321906346016423\n",
      "[73]\tcv-test-auc:0.8311865999999999+0.012800595659577712\tcv-train-auc:0.8516609+0.0012507146317206166\n",
      "[74]\tcv-test-auc:0.8312668000000001+0.01287958209570479\tcv-train-auc:0.8518293+0.001201663434577236\n",
      "[75]\tcv-test-auc:0.8313453000000001+0.012659580601662924\tcv-train-auc:0.8520433000000001+0.001242270586466563\n",
      "[76]\tcv-test-auc:0.8314448999999999+0.012818022776153874\tcv-train-auc:0.8521902000000001+0.0012104093357207832\n",
      "[77]\tcv-test-auc:0.8315151000000001+0.012733767898387363\tcv-train-auc:0.8523324999999999+0.001159011928325158\n",
      "[78]\tcv-test-auc:0.8316268000000001+0.012732636386860337\tcv-train-auc:0.8524682+0.0011091946447761118\n",
      "[79]\tcv-test-auc:0.8317668000000001+0.01266684104897507\tcv-train-auc:0.8526102000000002+0.0010832799084262526\n",
      "[80]\tcv-test-auc:0.8318733999999999+0.012721672242280125\tcv-train-auc:0.8527823+0.0010129906268075614\n",
      "[81]\tcv-test-auc:0.8320857+0.012658806302728557\tcv-train-auc:0.852949+0.001017737981997337\n",
      "[82]\tcv-test-auc:0.8322805000000001+0.01249612237656147\tcv-train-auc:0.8531267999999999+0.0010573780591633254\n",
      "[83]\tcv-test-auc:0.832293+0.012447480500085142\tcv-train-auc:0.8532569999999999+0.0010500194283916857\n",
      "[84]\tcv-test-auc:0.8324073999999999+0.012438025150320282\tcv-train-auc:0.8534377000000001+0.000958587194781989\n",
      "[85]\tcv-test-auc:0.8324821+0.012316380770745917\tcv-train-auc:0.8535505999999999+0.0009881619502895343\n",
      "[86]\tcv-test-auc:0.8326437+0.012318555013068703\tcv-train-auc:0.8537337+0.000951415477065618\n",
      "[87]\tcv-test-auc:0.8326509+0.012295154244254114\tcv-train-auc:0.8538419000000002+0.000979934635575279\n",
      "[88]\tcv-test-auc:0.8328064999999999+0.012270087214441467\tcv-train-auc:0.8539596999999999+0.0009591925823316073\n",
      "[89]\tcv-test-auc:0.8329022+0.012269208742213154\tcv-train-auc:0.8540861+0.0009754328731388832\n",
      "[90]\tcv-test-auc:0.8329174+0.012253583248992922\tcv-train-auc:0.8542235999999999+0.0009846642270337689\n",
      "[91]\tcv-test-auc:0.8329596+0.012260207618144154\tcv-train-auc:0.8543087+0.0009947308228862748\n",
      "[92]\tcv-test-auc:0.8330050999999999+0.012278286512783454\tcv-train-auc:0.8544518+0.0009835198828696998\n",
      "[93]\tcv-test-auc:0.8329983999999999+0.012292967584761613\tcv-train-auc:0.8545477+0.0009394233390756262\n",
      "[94]\tcv-test-auc:0.8332164000000001+0.012322585590694839\tcv-train-auc:0.8546862000000001+0.0009565336167642039\n",
      "[95]\tcv-test-auc:0.8332872+0.012379684897443862\tcv-train-auc:0.8548142999999999+0.000891862102569694\n",
      "[96]\tcv-test-auc:0.8333295999999999+0.01233082349399262\tcv-train-auc:0.8549719999999998+0.0008724033470820614\n",
      "[97]\tcv-test-auc:0.8333883+0.012330404949149066\tcv-train-auc:0.8550541+0.0008971605709124905\n",
      "[98]\tcv-test-auc:0.8334873999999999+0.012327593627306179\tcv-train-auc:0.8551544+0.000908681704448814\n",
      "[99]\tcv-test-auc:0.8335319+0.0123129328955371\tcv-train-auc:0.8552246+0.0009179251821363152\n",
      "[100]\tcv-test-auc:0.8336357000000001+0.012338342198610002\tcv-train-auc:0.8553483+0.0008862834817370883\n",
      "[101]\tcv-test-auc:0.8337118+0.0122993322241494\tcv-train-auc:0.8554736999999999+0.0009028180381450228\n",
      "[102]\tcv-test-auc:0.8337664+0.012303527203204783\tcv-train-auc:0.8556077+0.0009382360097544687\n",
      "[103]\tcv-test-auc:0.8338491999999998+0.012239348829084\tcv-train-auc:0.8557214999999999+0.0009102969021149055\n",
      "[104]\tcv-test-auc:0.8338183999999998+0.012152110534388664\tcv-train-auc:0.855823+0.0009318418320723723\n",
      "[105]\tcv-test-auc:0.8338458+0.01206699497638082\tcv-train-auc:0.8559467+0.0009211207358430393\n",
      "[106]\tcv-test-auc:0.8339138+0.012082201114035483\tcv-train-auc:0.8561116+0.000963773956900696\n",
      "[107]\tcv-test-auc:0.8338884999999999+0.01208287277306187\tcv-train-auc:0.8562630999999999+0.0009416983009435505\n",
      "[108]\tcv-test-auc:0.8339483+0.012016932812078131\tcv-train-auc:0.8563919999999999+0.0009303230621671386\n",
      "[109]\tcv-test-auc:0.8340854+0.01204479999169766\tcv-train-auc:0.8565074000000001+0.0008825526839798343\n",
      "[110]\tcv-test-auc:0.8341310999999999+0.011986158045428904\tcv-train-auc:0.8566554999999999+0.0008747655971744676\n",
      "[111]\tcv-test-auc:0.8342639999999999+0.01193534301140943\tcv-train-auc:0.8567597000000001+0.0008975539036737592\n",
      "[112]\tcv-test-auc:0.8344286000000001+0.011870702887360984\tcv-train-auc:0.8568602999999999+0.0008727342149818777\n",
      "[113]\tcv-test-auc:0.8343884000000001+0.011891720045477021\tcv-train-auc:0.8569530000000001+0.0008770573527426893\n",
      "[114]\tcv-test-auc:0.8344781000000001+0.011887480283474703\tcv-train-auc:0.8570945999999999+0.0008766111110406898\n",
      "[115]\tcv-test-auc:0.8345676000000001+0.011946406264647094\tcv-train-auc:0.8572521+0.0008993610454094675\n",
      "[116]\tcv-test-auc:0.8346235+0.011881829633941058\tcv-train-auc:0.8573742+0.0009362807057714998\n",
      "[117]\tcv-test-auc:0.8347139+0.011830530177891433\tcv-train-auc:0.8575225999999999+0.000886015259462285\n",
      "[118]\tcv-test-auc:0.8347802+0.01181098480059983\tcv-train-auc:0.8576713999999999+0.0008744341255920859\n",
      "[119]\tcv-test-auc:0.8348385+0.011786980684212552\tcv-train-auc:0.8577624+0.000905634716649049\n",
      "[120]\tcv-test-auc:0.8349987999999999+0.011846678655218112\tcv-train-auc:0.8579031+0.0008890663023644694\n",
      "[121]\tcv-test-auc:0.8350039+0.011873644861204168\tcv-train-auc:0.8580152+0.0009046154763212923\n",
      "[122]\tcv-test-auc:0.8349681+0.011902344831586755\tcv-train-auc:0.8581520000000001+0.0008769973774191138\n",
      "[123]\tcv-test-auc:0.8350686999999999+0.01178472874571154\tcv-train-auc:0.8582777+0.000913083243740676\n",
      "[124]\tcv-test-auc:0.8350700999999999+0.011732978227628315\tcv-train-auc:0.8583912999999999+0.0009346601574904135\n",
      "[125]\tcv-test-auc:0.8351008+0.011735270749326563\tcv-train-auc:0.8585288999999999+0.0008918429738468617\n",
      "[126]\tcv-test-auc:0.8351419+0.011737680694668769\tcv-train-auc:0.8586808999999999+0.0008961109808500297\n",
      "[127]\tcv-test-auc:0.8351172+0.011741086319416958\tcv-train-auc:0.8587939+0.000867386470957434\n",
      "[128]\tcv-test-auc:0.8351133000000001+0.011733198635069648\tcv-train-auc:0.8589294000000001+0.0008716125515387911\n",
      "[129]\tcv-test-auc:0.8351990999999999+0.011708029103568211\tcv-train-auc:0.8590499000000001+0.0008653109787816285\n",
      "[130]\tcv-test-auc:0.8352257+0.011632303547019376\tcv-train-auc:0.8591595+0.0008896482731956655\n",
      "[131]\tcv-test-auc:0.8352541+0.01163210087172562\tcv-train-auc:0.8592901+0.0008769742812648425\n",
      "[132]\tcv-test-auc:0.8352627+0.011639691319360664\tcv-train-auc:0.8594193000000001+0.0009035550951657617\n",
      "[133]\tcv-test-auc:0.8354067000000001+0.011655669127510433\tcv-train-auc:0.8595480999999999+0.0008979228753072371\n",
      "[134]\tcv-test-auc:0.8355078+0.011642803509464552\tcv-train-auc:0.8596622+0.0008965107695951161\n",
      "[135]\tcv-test-auc:0.8355832+0.011581074110806819\tcv-train-auc:0.8598221+0.000952597233882196\n",
      "[136]\tcv-test-auc:0.835613+0.011577216539393219\tcv-train-auc:0.8599469000000001+0.000972969418841098\n",
      "[137]\tcv-test-auc:0.8356017999999998+0.011603113485612371\tcv-train-auc:0.8600673999999999+0.000963906447742731\n",
      "[138]\tcv-test-auc:0.8355555000000001+0.011592881956183297\tcv-train-auc:0.8601661999999999+0.0009751722719601993\n",
      "[139]\tcv-test-auc:0.8355836999999999+0.011638641269924963\tcv-train-auc:0.8603297+0.000974635731953217\n",
      "[140]\tcv-test-auc:0.8356166999999999+0.011577524701334043\tcv-train-auc:0.8604637+0.0009664117186789473\n",
      "[141]\tcv-test-auc:0.8356638999999999+0.011583445682956345\tcv-train-auc:0.8605748+0.0009554816377094806\n",
      "[142]\tcv-test-auc:0.8356931999999999+0.011564678567085202\tcv-train-auc:0.8606837+0.0009788085665746876\n",
      "[143]\tcv-test-auc:0.8357502+0.011587863822120108\tcv-train-auc:0.8607975+0.000968392921287634\n",
      "[144]\tcv-test-auc:0.8358436999999999+0.011593532481948731\tcv-train-auc:0.8609392+0.000978170721295609\n",
      "[145]\tcv-test-auc:0.8359126+0.011621378259053426\tcv-train-auc:0.8610654999999999+0.0009737744348667388\n",
      "[146]\tcv-test-auc:0.835933+0.011645075654541714\tcv-train-auc:0.8611948+0.0009806776024769853\n",
      "[147]\tcv-test-auc:0.8360032000000001+0.011579795143265695\tcv-train-auc:0.8613377+0.0009703400486427359\n",
      "[148]\tcv-test-auc:0.8359297+0.01158457412294469\tcv-train-auc:0.8614748999999999+0.0009779075058511514\n",
      "[149]\tcv-test-auc:0.8360178000000001+0.0115606133038001\tcv-train-auc:0.8616199+0.000964693365790394\n",
      "[150]\tcv-test-auc:0.8360426999999999+0.011522756233210875\tcv-train-auc:0.8617496000000001+0.0009551405341623845\n",
      "[151]\tcv-test-auc:0.8360603+0.011519907630272056\tcv-train-auc:0.8619096+0.0009560812936147216\n",
      "[152]\tcv-test-auc:0.8360502999999999+0.011467091087542639\tcv-train-auc:0.8620224000000001+0.0009377165030007673\n",
      "[153]\tcv-test-auc:0.8362510000000001+0.011561084447403716\tcv-train-auc:0.8621732+0.0009440393847716496\n",
      "[154]\tcv-test-auc:0.8362997999999999+0.011564632590791638\tcv-train-auc:0.8623102000000001+0.0009313089498120281\n",
      "[155]\tcv-test-auc:0.8363354+0.011518854554164674\tcv-train-auc:0.8624559999999999+0.000917359362518307\n",
      "[156]\tcv-test-auc:0.836384+0.011547265832221916\tcv-train-auc:0.8626355+0.000935991052307671\n",
      "[157]\tcv-test-auc:0.8363913000000001+0.011449771334397897\tcv-train-auc:0.8627656+0.0009188871747935255\n",
      "[158]\tcv-test-auc:0.8364339000000001+0.01147560272447595\tcv-train-auc:0.8628800999999999+0.0009154166756182663\n",
      "[159]\tcv-test-auc:0.8365438000000001+0.011382942789981858\tcv-train-auc:0.8630454999999999+0.0008861903012333149\n",
      "[160]\tcv-test-auc:0.8366358999999999+0.011355228552961852\tcv-train-auc:0.8631683000000001+0.0008693109972846178\n",
      "[161]\tcv-test-auc:0.8367150000000001+0.011343500561995835\tcv-train-auc:0.8633402+0.0008686778229009918\n",
      "[162]\tcv-test-auc:0.8367458000000001+0.011316766197107725\tcv-train-auc:0.8635128000000002+0.0008742197435427638\n",
      "[163]\tcv-test-auc:0.8367260000000002+0.01131785059099119\tcv-train-auc:0.8636503000000001+0.0008776852567976638\n",
      "[164]\tcv-test-auc:0.8367728+0.011297399371536804\tcv-train-auc:0.8637779999999999+0.0008619020826056754\n",
      "[165]\tcv-test-auc:0.8368358+0.011280605762103369\tcv-train-auc:0.8639235+0.0008218966175864175\n",
      "[166]\tcv-test-auc:0.8369254999999999+0.011280362425471962\tcv-train-auc:0.8640721000000001+0.0008376682457870754\n",
      "[167]\tcv-test-auc:0.8370279+0.011348600516803822\tcv-train-auc:0.8642443+0.0008561853829633015\n",
      "[168]\tcv-test-auc:0.8371057000000001+0.011348545863237284\tcv-train-auc:0.8643981999999999+0.0008741508794252868\n",
      "[169]\tcv-test-auc:0.8371649+0.011323885061673856\tcv-train-auc:0.8645723000000001+0.000876115979765247\n",
      "[170]\tcv-test-auc:0.8371995999999999+0.011298362414084598\tcv-train-auc:0.8646795+0.000875415130095434\n",
      "[171]\tcv-test-auc:0.8372835000000001+0.011343608572672104\tcv-train-auc:0.8648047+0.0008853818441779743\n",
      "[172]\tcv-test-auc:0.8372488+0.011289580078993191\tcv-train-auc:0.8649557000000001+0.0008828535609035061\n",
      "[173]\tcv-test-auc:0.8372915000000001+0.01129257066615037\tcv-train-auc:0.8651086000000001+0.0008582143322037902\n",
      "[174]\tcv-test-auc:0.8373191999999999+0.01128535892030022\tcv-train-auc:0.8652555+0.0008640022280063808\n",
      "[175]\tcv-test-auc:0.8373506+0.011294689258231055\tcv-train-auc:0.8653802+0.0008728674355250189\n",
      "[176]\tcv-test-auc:0.8373386+0.011264447471580667\tcv-train-auc:0.8655034+0.0009027162566388356\n",
      "[177]\tcv-test-auc:0.8373859999999999+0.011242186228665657\tcv-train-auc:0.8656554+0.0008959093927401317\n",
      "[178]\tcv-test-auc:0.837466+0.011280017109916107\tcv-train-auc:0.8657654000000001+0.0009069178794135614\n",
      "[179]\tcv-test-auc:0.8375116+0.011325971968886385\tcv-train-auc:0.8659203+0.0009041338451800129\n",
      "[180]\tcv-test-auc:0.8375371999999999+0.011353743213583798\tcv-train-auc:0.8660506+0.000883026862558584\n",
      "[181]\tcv-test-auc:0.8375090999999999+0.011386570383131168\tcv-train-auc:0.866206+0.0008598663849691832\n",
      "[182]\tcv-test-auc:0.8376132000000001+0.011382192238756124\tcv-train-auc:0.8663399+0.0008818951695071382\n",
      "[183]\tcv-test-auc:0.8376096000000001+0.011407775122257621\tcv-train-auc:0.8665068+0.0008463457685839701\n",
      "[184]\tcv-test-auc:0.8377083000000001+0.011393663248051536\tcv-train-auc:0.8666246000000001+0.0008530928671604443\n",
      "[185]\tcv-test-auc:0.8377524000000001+0.011401168678692538\tcv-train-auc:0.8667925000000001+0.0008423067434136063\n",
      "[186]\tcv-test-auc:0.8378004000000001+0.01139128349397029\tcv-train-auc:0.8669242+0.0008468241612046779\n",
      "[187]\tcv-test-auc:0.8378353000000001+0.011389324071690991\tcv-train-auc:0.8670408000000001+0.0008281800287377163\n",
      "[188]\tcv-test-auc:0.8379562999999999+0.011331606603213857\tcv-train-auc:0.8671854+0.0008543294680625107\n",
      "[189]\tcv-test-auc:0.8379303+0.011258943192413749\tcv-train-auc:0.8673212999999999+0.000871451782946145\n",
      "[190]\tcv-test-auc:0.8379958999999999+0.011223794763358776\tcv-train-auc:0.8674868+0.000889759720373979\n",
      "[191]\tcv-test-auc:0.8379442000000001+0.011224406664051332\tcv-train-auc:0.8676313999999999+0.0008764671357215893\n",
      "[192]\tcv-test-auc:0.8379849+0.011255598850794236\tcv-train-auc:0.8677912000000001+0.0008789810919468068\n",
      "[193]\tcv-test-auc:0.8380286+0.011213123910846617\tcv-train-auc:0.8679661+0.0008956372535798201\n",
      "[194]\tcv-test-auc:0.8380889+0.011216705375911422\tcv-train-auc:0.8681091999999999+0.0008831989356877581\n",
      "[195]\tcv-test-auc:0.8381072999999999+0.011217717450979053\tcv-train-auc:0.868266+0.0008754988292396438\n",
      "[196]\tcv-test-auc:0.8381249999999998+0.011194516461196517\tcv-train-auc:0.8683799000000001+0.0008626532849297099\n",
      "[197]\tcv-test-auc:0.8382437999999999+0.011219713898313097\tcv-train-auc:0.8685141999999999+0.0008709922846960424\n",
      "[198]\tcv-test-auc:0.8383435+0.011204225544409597\tcv-train-auc:0.8686510999999999+0.0008711572131366491\n",
      "[199]\tcv-test-auc:0.8383936000000001+0.01116258316161632\tcv-train-auc:0.8687818+0.0008787894855993723\n",
      "[200]\tcv-test-auc:0.8384288+0.011158059372489452\tcv-train-auc:0.8689389000000001+0.0008873144256688243\n",
      "[201]\tcv-test-auc:0.8384974+0.011186677122362987\tcv-train-auc:0.8690597+0.0008804677222930898\n",
      "[202]\tcv-test-auc:0.8384807000000001+0.011199655584436502\tcv-train-auc:0.8692071+0.0008803094285533864\n",
      "[203]\tcv-test-auc:0.838516+0.011212446780252756\tcv-train-auc:0.8693236000000001+0.0009078903237726318\n",
      "[204]\tcv-test-auc:0.8385221999999999+0.01123129530196762\tcv-train-auc:0.8694722+0.0009022302145239885\n",
      "[205]\tcv-test-auc:0.8385938999999999+0.01121157677090961\tcv-train-auc:0.8695929+0.0009061096456831286\n",
      "[206]\tcv-test-auc:0.8385891000000001+0.01122532153169787\tcv-train-auc:0.8697287999999999+0.0008831017834881713\n",
      "[207]\tcv-test-auc:0.838627+0.011240689222641109\tcv-train-auc:0.8698427000000001+0.000877460318191087\n",
      "[208]\tcv-test-auc:0.8386962+0.011269322968128999\tcv-train-auc:0.8699937+0.0008649803523780281\n",
      "[209]\tcv-test-auc:0.8387298+0.011205250812007723\tcv-train-auc:0.8701367+0.0008707987195672696\n",
      "[210]\tcv-test-auc:0.8387701999999999+0.011182149031380319\tcv-train-auc:0.8702766000000001+0.0008600278135037275\n",
      "[211]\tcv-test-auc:0.8388390000000001+0.011231979620707997\tcv-train-auc:0.8704129999999999+0.0008455910359032998\n",
      "[212]\tcv-test-auc:0.8389405+0.011228721514491294\tcv-train-auc:0.8705598+0.000833611396275252\n",
      "[213]\tcv-test-auc:0.8389241999999999+0.01126837745906659\tcv-train-auc:0.8706748+0.000833336762659601\n",
      "[214]\tcv-test-auc:0.8389369+0.011281023813909812\tcv-train-auc:0.8708062999999999+0.0008092515122012423\n",
      "[215]\tcv-test-auc:0.8390243+0.011262761775426117\tcv-train-auc:0.8709508000000001+0.0007886010144553385\n",
      "[216]\tcv-test-auc:0.8390963000000001+0.011208573736653554\tcv-train-auc:0.8710815000000001+0.0008036193439682607\n",
      "[217]\tcv-test-auc:0.839133+0.01121024189747928\tcv-train-auc:0.8712148+0.0008089643749881769\n",
      "[218]\tcv-test-auc:0.8391714+0.011205446454291777\tcv-train-auc:0.8713787000000002+0.0008312870803759775\n",
      "[219]\tcv-test-auc:0.8391586999999999+0.011209306838961996\tcv-train-auc:0.8715250000000001+0.0008173821627610795\n",
      "[220]\tcv-test-auc:0.8392218+0.011194460860622098\tcv-train-auc:0.8716549999999998+0.0008143345749751626\n",
      "[221]\tcv-test-auc:0.8392793999999999+0.011120053571813414\tcv-train-auc:0.8717914+0.0007946254715272926\n",
      "[222]\tcv-test-auc:0.8393358+0.01114409844536558\tcv-train-auc:0.8719349+0.0007993894482666179\n",
      "[223]\tcv-test-auc:0.8393773999999998+0.011137056641680519\tcv-train-auc:0.8720678000000002+0.0007731464026948751\n",
      "[224]\tcv-test-auc:0.8394324+0.011107673601614325\tcv-train-auc:0.8722046000000001+0.0007962357942217852\n",
      "[225]\tcv-test-auc:0.8394600000000001+0.011111852068849733\tcv-train-auc:0.8723436+0.0007919918181395649\n",
      "[226]\tcv-test-auc:0.8394752999999999+0.011050596952653745\tcv-train-auc:0.8724753+0.0007902633801461447\n",
      "[227]\tcv-test-auc:0.8395195000000001+0.01106450203353048\tcv-train-auc:0.8725925999999999+0.0007929647154823434\n",
      "[228]\tcv-test-auc:0.8395547999999999+0.01105131575695854\tcv-train-auc:0.8727222999999998+0.0007847622633638628\n",
      "[229]\tcv-test-auc:0.8395929000000001+0.011076876793121799\tcv-train-auc:0.8728476000000001+0.0007883352332605679\n",
      "[230]\tcv-test-auc:0.8395828+0.011088694673404982\tcv-train-auc:0.8729899+0.00080091515780387\n",
      "[231]\tcv-test-auc:0.8395934+0.011048672456001237\tcv-train-auc:0.8731278+0.0008046114341717995\n",
      "[232]\tcv-test-auc:0.8396106+0.01105994231630528\tcv-train-auc:0.8732393999999999+0.0007992694414275925\n",
      "[233]\tcv-test-auc:0.8396091+0.011077761131654712\tcv-train-auc:0.8733755000000001+0.0008093024465550415\n",
      "[234]\tcv-test-auc:0.839691+0.011066675878510214\tcv-train-auc:0.8735037+0.0007979471223082549\n",
      "[235]\tcv-test-auc:0.8397352999999999+0.011046721921457062\tcv-train-auc:0.8736370000000001+0.0007911668597710502\n",
      "[236]\tcv-test-auc:0.8397387999999999+0.011038116640079476\tcv-train-auc:0.8737704+0.0007757905903012672\n",
      "[237]\tcv-test-auc:0.8397879999999999+0.011055859749472213\tcv-train-auc:0.8738925999999999+0.0007648994966660827\n",
      "[238]\tcv-test-auc:0.8397781+0.01105895208824054\tcv-train-auc:0.8740017+0.0007745783433584979\n",
      "[239]\tcv-test-auc:0.8397795+0.01107884214392461\tcv-train-auc:0.8741412000000001+0.0007456139483673803\n",
      "[240]\tcv-test-auc:0.8398711999999999+0.011125560532395672\tcv-train-auc:0.8742729+0.0007497161396155324\n",
      "[241]\tcv-test-auc:0.8399677000000001+0.011114037916527016\tcv-train-auc:0.8744023999999999+0.0007374066991830192\n",
      "[242]\tcv-test-auc:0.839992+0.011106254553178582\tcv-train-auc:0.8745512+0.0007261776366702512\n",
      "[243]\tcv-test-auc:0.8400394999999999+0.011114144494741813\tcv-train-auc:0.8746957+0.0007323603006717473\n",
      "[244]\tcv-test-auc:0.8400598+0.011132751455053675\tcv-train-auc:0.8748410999999999+0.000740266364223035\n",
      "[245]\tcv-test-auc:0.8401031+0.01113079310247029\tcv-train-auc:0.8749723000000001+0.0007541895053632168\n",
      "[246]\tcv-test-auc:0.8401548+0.01115416375888395\tcv-train-auc:0.8750978+0.0007410327658072818\n",
      "[247]\tcv-test-auc:0.8401926+0.011179470508033914\tcv-train-auc:0.8752289+0.0007414822250061008\n",
      "[248]\tcv-test-auc:0.840217+0.011223955906898416\tcv-train-auc:0.8753446000000003+0.0007461262895783797\n",
      "[249]\tcv-test-auc:0.8402232999999999+0.011216682870171538\tcv-train-auc:0.8754523000000001+0.0007442650132849246\n",
      "[250]\tcv-test-auc:0.8402436+0.011225817994248814\tcv-train-auc:0.8755965+0.0007412336001558448\n",
      "[251]\tcv-test-auc:0.8403099+0.01121176964131889\tcv-train-auc:0.8757242999999999+0.000735639456527454\n",
      "[252]\tcv-test-auc:0.8403180000000001+0.0112075514810328\tcv-train-auc:0.8758342000000001+0.0007535495736844387\n",
      "[253]\tcv-test-auc:0.8403141999999999+0.011202400589159464\tcv-train-auc:0.8759688999999999+0.0007612364218821856\n",
      "[254]\tcv-test-auc:0.8402942999999998+0.011222948392022477\tcv-train-auc:0.8760987+0.0007785029287035532\n",
      "[255]\tcv-test-auc:0.8403046999999999+0.011238574856715616\tcv-train-auc:0.8762410999999999+0.0007727640584292224\n",
      "[256]\tcv-test-auc:0.8403191+0.01117516029817918\tcv-train-auc:0.8763698+0.0007883709532954627\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-67e76193e93f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m res2 = xgb.cv(params, dktrain, num_boost_round=1000, nfold=10, stratified=True, early_stopping_rounds=300,\n\u001b[1;32m----> 2\u001b[1;33m               verbose_eval=True)\n\u001b[0m",
      "\u001b[1;32m/home/libfun/vrt/lib/python3.4/site-packages/xgboost-0.4-py3.4.egg/xgboost/training.py\u001b[0m in \u001b[0;36mcv\u001b[1;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 456\u001b[1;33m             \u001b[0mfold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    457\u001b[0m         res = aggcv([f.eval(i, feval) for f in cvfolds],\n\u001b[0;32m    458\u001b[0m                     \u001b[0mshow_stdv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_stdv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose_eval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/libfun/vrt/lib/python3.4/site-packages/xgboost-0.4-py3.4.egg/xgboost/training.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, iteration, fobj)\u001b[0m\n\u001b[0;32m    251\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[1;34m\"\"\"\"Update the boosters for one iteration\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/libfun/vrt/lib/python3.4/site-packages/xgboost-0.4-py3.4.egg/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m    748\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 750\u001b[1;33m             \u001b[0m_check_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    751\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res2 = xgb.cv(params, dktrain, num_boost_round=1000, nfold=10, stratified=True, early_stopping_rounds=300,\n",
    "              verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(target, n_folds=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = cross_val_score(RandomForestClassifier(n_estimators=1500, max_depth=50, \n",
    "                                             max_features=50, n_jobs=-1,\n",
    "                                             random_state=0),\n",
    "                      train, target, scoring='roc_auc', cv=skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.81980316  0.82652889  0.80696928  0.82204208  0.82376237  0.83331324\n",
      "  0.83998096  0.85333348  0.84990458  0.81490572] 0.829054374932 0.0142084848769\n"
     ]
    }
   ],
   "source": [
    "print(res, np.mean(res), np.std(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rese = cross_val_score(ExtraTreesClassifier(n_estimators=500, max_depth=50, \n",
    "                                             max_features=50, n_jobs=-1,\n",
    "                                             random_state=0),\n",
    "                      train, target, scoring='roc_auc', cv=skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.81169816  0.80918963  0.79401584  0.80832986  0.81212559  0.81999075\n",
      "  0.82329254  0.83714605  0.82650436  0.80781605] 0.815010881689 0.0114272932867\n"
     ]
    }
   ],
   "source": [
    "print(rese, np.mean(rese), np.std(rese))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st = train.ix[:, :292]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rest = cross_val_score(RandomForestClassifier(n_estimators=1500, max_depth=50, \n",
    "                                             max_features=50, n_jobs=-1,\n",
    "                                             random_state=0),\n",
    "                      st, target, scoring='roc_auc', cv=skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.78238588  0.7767728   0.76983743  0.76453665  0.75228351  0.78557231\n",
      "  0.79920877  0.79396601  0.80247204  0.76939027] 0.779642567504 0.0152907241562\n"
     ]
    }
   ],
   "source": [
    "print(rest, np.mean(rest), np.std(rest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset = cross_val_score(ExtraTreesClassifier(n_estimators=500, max_depth=50, \n",
    "                                             max_features=50, n_jobs=-1,\n",
    "                                             random_state=0),\n",
    "                      st, target, scoring='roc_auc', cv=skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.77235473  0.75757199  0.74889618  0.73359859  0.72838177  0.74897627\n",
      "  0.76357969  0.76439285  0.77726978  0.75705314] 0.75520750053 0.0148642490642\n"
     ]
    }
   ],
   "source": [
    "print(reset, np.mean(reset), np.std(reset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('stm_test.csv.gz', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=5000, max_depth=50, \n",
    "                                             max_features=50, n_jobs=-1,\n",
    "                                             random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features=50, max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=5000, n_jobs=-1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = clf.predict_proba(test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('data/sample_submission.csv', index_col='ID')\n",
    "sub.TARGET = preds\n",
    "sub.to_csv('submission/rf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=5000, max_depth=50, \n",
    "                                             max_features=50, n_jobs=-1,\n",
    "                                             random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=50, max_features=50, max_leaf_nodes=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=5000, n_jobs=-1,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = clf.predict_proba(test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('data/sample_submission.csv', index_col='ID')\n",
    "sub.TARGET = preds\n",
    "sub.to_csv('submission/et.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
